[0m10:39:47.886650 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fb024f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110e9c8b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110ed03a0>]}


============================== 10:39:47.934359 | 96d45aa7-9835-4bf9-b6cb-a7a1e7344b3a ==============================
[0m10:39:47.934359 [info ] [MainThread]: Running with dbt=1.5.4
[0m10:39:47.936089 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/denisechan/Documents/Makers/Data_Engineering/Week_6/dbt_project', 'debug': 'False', 'warn_error': 'None', 'log_path': '/Users/denisechan/Documents/Makers/Data_Engineering/Week_6/dbt_project/logs', 'version_check': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'send_anonymous_usage_stats': 'True'}
[0m10:39:47.937809 [info ] [MainThread]: dbt version: 1.5.4
[0m10:39:47.938913 [info ] [MainThread]: python version: 3.9.18
[0m10:39:47.940431 [info ] [MainThread]: python path: /usr/local/Cellar/dbt-postgres/1.5.4/libexec/bin/python
[0m10:39:47.941284 [info ] [MainThread]: os info: macOS-13.6-x86_64-i386-64bit
[0m10:39:47.942026 [info ] [MainThread]: Using profiles.yml file at /Users/denisechan/Documents/Makers/Data_Engineering/Week_6/dbt_project/profiles.yml
[0m10:39:47.942679 [info ] [MainThread]: Using dbt_project.yml file at /Users/denisechan/Documents/Makers/Data_Engineering/Week_6/dbt_project/dbt_project.yml
[0m10:39:47.943362 [info ] [MainThread]: Configuration:
[0m10:39:48.073016 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m10:39:48.140960 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m10:39:48.142215 [info ] [MainThread]: Required dependencies:
[0m10:39:48.143567 [debug] [MainThread]: Executing "git --help"
[0m10:39:48.237655 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           [--config-env=<name>=<envvar>] <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m10:39:48.241139 [debug] [MainThread]: STDERR: "b''"
[0m10:39:48.242420 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m10:39:48.243468 [info ] [MainThread]: Connection:
[0m10:39:48.244662 [info ] [MainThread]:   host: localhost
[0m10:39:48.245871 [info ] [MainThread]:   port: 5433
[0m10:39:48.247694 [info ] [MainThread]:   user: postgres
[0m10:39:48.248934 [info ] [MainThread]:   database: mydb
[0m10:39:48.249998 [info ] [MainThread]:   schema: dbt_warehouse
[0m10:39:48.253998 [info ] [MainThread]:   search_path: None
[0m10:39:48.256142 [info ] [MainThread]:   keepalives_idle: 0
[0m10:39:48.257727 [info ] [MainThread]:   sslmode: None
[0m10:39:48.260309 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m10:39:48.276948 [debug] [MainThread]: Acquiring new postgres connection 'debug'
[0m10:39:48.282516 [debug] [MainThread]: Using postgres connection "debug"
[0m10:39:48.284727 [debug] [MainThread]: On debug: select 1 as id
[0m10:39:48.286499 [debug] [MainThread]: Opening a new connection, currently in state init
[0m10:39:48.719534 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
[0m10:39:48.730167 [debug] [MainThread]: On debug: Close
[0m10:39:48.731811 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m10:39:48.735437 [info ] [MainThread]: [32mAll checks passed![0m
[0m10:39:48.738295 [debug] [MainThread]: Command `dbt debug` succeeded at 10:39:48.737511 after 0.93 seconds
[0m10:39:48.740643 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m10:39:48.749202 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fb024f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110fcbfd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110ffc160>]}
[0m10:39:48.750251 [debug] [MainThread]: Flushing usage events
[0m10:46:17.789649 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1032bd4f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1046582b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x100e50790>]}


============================== 10:46:17.847695 | 398e6a09-d52f-46ea-8e8a-fb4ae3091d87 ==============================
[0m10:46:17.847695 [info ] [MainThread]: Running with dbt=1.5.4
[0m10:46:17.853682 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/denisechan/Documents/Makers/Data_Engineering/Week_6/dbt_warehouse', 'debug': 'False', 'version_check': 'True', 'log_path': '/Users/denisechan/Documents/Makers/Data_Engineering/Week_6/dbt_warehouse/logs', 'warn_error': 'None', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'send_anonymous_usage_stats': 'True'}
[0m10:46:19.541170 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '398e6a09-d52f-46ea-8e8a-fb4ae3091d87', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104658a00>]}
[0m10:46:19.623508 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '398e6a09-d52f-46ea-8e8a-fb4ae3091d87', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1048bc700>]}
[0m10:46:19.628247 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m10:46:19.745215 [debug] [MainThread]: checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, vars: {}, profile: , target: , version: 1.5.4
[0m10:46:19.750402 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m10:46:19.751797 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '398e6a09-d52f-46ea-8e8a-fb4ae3091d87', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1048da160>]}
[0m10:46:22.067365 [debug] [MainThread]: 1603: static parser failed on facts/movies.sql
[0m10:46:22.076626 [error] [MainThread]: Encountered an error:
Compilation Error in model movies (models/facts/movies.sql)
  source() takes exactly two arguments (1 given)
[0m10:46:22.078172 [debug] [MainThread]: Command `dbt run` failed at 10:46:22.077832 after 4.38 seconds
[0m10:46:22.078814 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1032bd4f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104ae90d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104ae9130>]}
[0m10:46:22.079396 [debug] [MainThread]: Flushing usage events
[0m10:47:12.112884 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106723e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107abf2b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1042b6a00>]}


============================== 10:47:12.121017 | 5faa526c-97e9-49ee-af63-e8a1ac37f2ff ==============================
[0m10:47:12.121017 [info ] [MainThread]: Running with dbt=1.5.4
[0m10:47:12.122494 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/Users/denisechan/Documents/Makers/Data_Engineering/Week_6/dbt_warehouse/logs', 'debug': 'False', 'profiles_dir': '/Users/denisechan/Documents/Makers/Data_Engineering/Week_6/dbt_warehouse', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'log_format': 'default', 'introspect': 'True', 'target_path': 'None', 'send_anonymous_usage_stats': 'True'}
[0m10:47:12.284098 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '5faa526c-97e9-49ee-af63-e8a1ac37f2ff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107abf970>]}
[0m10:47:12.326487 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '5faa526c-97e9-49ee-af63-e8a1ac37f2ff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107d22670>]}
[0m10:47:12.329467 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m10:47:12.395407 [debug] [MainThread]: checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, vars: {}, profile: , target: , version: 1.5.4
[0m10:47:12.397018 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m10:47:12.398016 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '5faa526c-97e9-49ee-af63-e8a1ac37f2ff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107d39be0>]}
[0m10:47:13.729655 [debug] [MainThread]: 1699: static parser successfully parsed facts/movies.sql
[0m10:47:13.878962 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5faa526c-97e9-49ee-af63-e8a1ac37f2ff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107f64d00>]}
[0m10:47:13.891723 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5faa526c-97e9-49ee-af63-e8a1ac37f2ff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107d39850>]}
[0m10:47:13.892514 [info ] [MainThread]: Found 1 model, 0 tests, 0 snapshots, 0 analyses, 307 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics, 0 groups
[0m10:47:13.894936 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5faa526c-97e9-49ee-af63-e8a1ac37f2ff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107d392b0>]}
[0m10:47:13.898453 [info ] [MainThread]: 
[0m10:47:13.900263 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m10:47:13.902149 [debug] [ThreadPool]: Acquiring new postgres connection 'list_mydb'
[0m10:47:13.923322 [debug] [ThreadPool]: Using postgres connection "list_mydb"
[0m10:47:13.925618 [debug] [ThreadPool]: On list_mydb: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "connection_name": "list_mydb"} */

    select distinct nspname from pg_namespace
  
[0m10:47:13.926510 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:47:14.170575 [debug] [ThreadPool]: SQL status: SELECT 4 in 0.0 seconds
[0m10:47:14.172900 [debug] [ThreadPool]: On list_mydb: Close
[0m10:47:14.175850 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_mydb, now create_mydb_dbt_warehouse)
[0m10:47:14.179306 [debug] [ThreadPool]: Creating schema "database: "mydb"
schema: "dbt_warehouse"
"
[0m10:47:14.193078 [debug] [ThreadPool]: Using postgres connection "create_mydb_dbt_warehouse"
[0m10:47:14.193708 [debug] [ThreadPool]: On create_mydb_dbt_warehouse: BEGIN
[0m10:47:14.194605 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m10:47:14.251296 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m10:47:14.252283 [debug] [ThreadPool]: Using postgres connection "create_mydb_dbt_warehouse"
[0m10:47:14.253083 [debug] [ThreadPool]: On create_mydb_dbt_warehouse: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "connection_name": "create_mydb_dbt_warehouse"} */
create schema if not exists "dbt_warehouse"
[0m10:47:14.281799 [debug] [ThreadPool]: SQL status: CREATE SCHEMA in 0.0 seconds
[0m10:47:14.283625 [debug] [ThreadPool]: On create_mydb_dbt_warehouse: COMMIT
[0m10:47:14.284552 [debug] [ThreadPool]: Using postgres connection "create_mydb_dbt_warehouse"
[0m10:47:14.285966 [debug] [ThreadPool]: On create_mydb_dbt_warehouse: COMMIT
[0m10:47:14.290825 [debug] [ThreadPool]: SQL status: COMMIT in 0.0 seconds
[0m10:47:14.291717 [debug] [ThreadPool]: On create_mydb_dbt_warehouse: Close
[0m10:47:14.296421 [debug] [ThreadPool]: Acquiring new postgres connection 'list_mydb_dbt_warehouse'
[0m10:47:14.312035 [debug] [ThreadPool]: Using postgres connection "list_mydb_dbt_warehouse"
[0m10:47:14.312647 [debug] [ThreadPool]: On list_mydb_dbt_warehouse: BEGIN
[0m10:47:14.313109 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:47:14.359196 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m10:47:14.360459 [debug] [ThreadPool]: Using postgres connection "list_mydb_dbt_warehouse"
[0m10:47:14.361396 [debug] [ThreadPool]: On list_mydb_dbt_warehouse: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "connection_name": "list_mydb_dbt_warehouse"} */
select
      'mydb' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_warehouse'
    union all
    select
      'mydb' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_warehouse'
  
[0m10:47:14.423146 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.0 seconds
[0m10:47:14.425911 [debug] [ThreadPool]: On list_mydb_dbt_warehouse: ROLLBACK
[0m10:47:14.428546 [debug] [ThreadPool]: On list_mydb_dbt_warehouse: Close
[0m10:47:14.438829 [debug] [MainThread]: Using postgres connection "master"
[0m10:47:14.439676 [debug] [MainThread]: On master: BEGIN
[0m10:47:14.440417 [debug] [MainThread]: Opening a new connection, currently in state init
[0m10:47:14.471750 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m10:47:14.472682 [debug] [MainThread]: Using postgres connection "master"
[0m10:47:14.473301 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m10:47:14.602758 [debug] [MainThread]: SQL status: SELECT 5 in 0.0 seconds
[0m10:47:14.605725 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5faa526c-97e9-49ee-af63-e8a1ac37f2ff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108001610>]}
[0m10:47:14.606554 [debug] [MainThread]: On master: ROLLBACK
[0m10:47:14.608759 [debug] [MainThread]: Using postgres connection "master"
[0m10:47:14.609353 [debug] [MainThread]: On master: BEGIN
[0m10:47:14.614587 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m10:47:14.615198 [debug] [MainThread]: On master: COMMIT
[0m10:47:14.615968 [debug] [MainThread]: Using postgres connection "master"
[0m10:47:14.616600 [debug] [MainThread]: On master: COMMIT
[0m10:47:14.618815 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m10:47:14.619524 [debug] [MainThread]: On master: Close
[0m10:47:14.621045 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m10:47:14.622039 [info ] [MainThread]: 
[0m10:47:14.656222 [debug] [Thread-1  ]: Began running node model.maker_warehouse.movies
[0m10:47:14.657450 [info ] [Thread-1  ]: 1 of 1 START sql view model dbt_warehouse.movies ............................... [RUN]
[0m10:47:14.659185 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly create_mydb_dbt_warehouse, now model.maker_warehouse.movies)
[0m10:47:14.660322 [debug] [Thread-1  ]: Began compiling node model.maker_warehouse.movies
[0m10:47:14.675800 [debug] [Thread-1  ]: Writing injected SQL for node "model.maker_warehouse.movies"
[0m10:47:14.680079 [debug] [Thread-1  ]: Timing info for model.maker_warehouse.movies (compile): 10:47:14.660933 => 10:47:14.679346
[0m10:47:14.680956 [debug] [Thread-1  ]: Began executing node model.maker_warehouse.movies
[0m10:47:14.773433 [debug] [Thread-1  ]: Writing runtime sql for node "model.maker_warehouse.movies"
[0m10:47:14.775719 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.movies"
[0m10:47:14.776342 [debug] [Thread-1  ]: On model.maker_warehouse.movies: BEGIN
[0m10:47:14.776883 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m10:47:14.820605 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
[0m10:47:14.821593 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.movies"
[0m10:47:14.822567 [debug] [Thread-1  ]: On model.maker_warehouse.movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.movies"} */

  create view "mydb"."dbt_warehouse"."movies__dbt_tmp"
    
    
  as (
    SELECT
    DISTINCT
    title,
    genres,
    release_date,
    movie_id
FROM mydb.public.raw_netflix;
  );
[0m10:47:14.833086 [debug] [Thread-1  ]: Postgres adapter: Postgres error: syntax error at or near ";"
LINE 13: FROM mydb.public.raw_netflix;
                                     ^

[0m10:47:14.834669 [debug] [Thread-1  ]: On model.maker_warehouse.movies: ROLLBACK
[0m10:47:14.840123 [debug] [Thread-1  ]: Timing info for model.maker_warehouse.movies (execute): 10:47:14.681555 => 10:47:14.839639
[0m10:47:14.840970 [debug] [Thread-1  ]: On model.maker_warehouse.movies: Close
[0m10:47:14.855569 [debug] [Thread-1  ]: Database Error in model movies (models/facts/movies.sql)
  syntax error at or near ";"
  LINE 13: FROM mydb.public.raw_netflix;
                                       ^
  compiled Code at target/run/maker_warehouse/models/facts/movies.sql
[0m10:47:14.856509 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5faa526c-97e9-49ee-af63-e8a1ac37f2ff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1080c6400>]}
[0m10:47:14.857658 [error] [Thread-1  ]: 1 of 1 ERROR creating sql view model dbt_warehouse.movies ...................... [[31mERROR[0m in 0.20s]
[0m10:47:14.858833 [debug] [Thread-1  ]: Finished running node model.maker_warehouse.movies
[0m10:47:14.862387 [debug] [MainThread]: Using postgres connection "master"
[0m10:47:14.863031 [debug] [MainThread]: On master: BEGIN
[0m10:47:14.863941 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m10:47:14.912469 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m10:47:14.914496 [debug] [MainThread]: On master: COMMIT
[0m10:47:14.915396 [debug] [MainThread]: Using postgres connection "master"
[0m10:47:14.915895 [debug] [MainThread]: On master: COMMIT
[0m10:47:14.919957 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m10:47:14.920794 [debug] [MainThread]: On master: Close
[0m10:47:14.922299 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:47:14.923204 [debug] [MainThread]: Connection 'model.maker_warehouse.movies' was properly closed.
[0m10:47:14.927551 [debug] [MainThread]: Connection 'list_mydb_dbt_warehouse' was properly closed.
[0m10:47:14.928642 [info ] [MainThread]: 
[0m10:47:14.929827 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 1.03 seconds (1.03s).
[0m10:47:14.931024 [debug] [MainThread]: Command end result
[0m10:47:14.943051 [info ] [MainThread]: 
[0m10:47:14.949601 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m10:47:14.952476 [info ] [MainThread]: 
[0m10:47:14.953459 [error] [MainThread]: [33mDatabase Error in model movies (models/facts/movies.sql)[0m
[0m10:47:14.954478 [error] [MainThread]:   syntax error at or near ";"
[0m10:47:14.955547 [error] [MainThread]:   LINE 13: FROM mydb.public.raw_netflix;
[0m10:47:14.956533 [error] [MainThread]:                                        ^
[0m10:47:14.957652 [error] [MainThread]:   compiled Code at target/run/maker_warehouse/models/facts/movies.sql
[0m10:47:14.961756 [info ] [MainThread]: 
[0m10:47:14.962783 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m10:47:14.964787 [debug] [MainThread]: Command `dbt run` failed at 10:47:14.964507 after 2.89 seconds
[0m10:47:14.965817 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106723e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107fa73d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107d399d0>]}
[0m10:47:14.966685 [debug] [MainThread]: Flushing usage events
[0m10:47:56.438501 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102b7e4f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103f192b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x100711790>]}


============================== 10:47:56.449103 | 91703984-8afd-4bdf-ba96-4a0a3c277714 ==============================
[0m10:47:56.449103 [info ] [MainThread]: Running with dbt=1.5.4
[0m10:47:56.450576 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': '/Users/denisechan/Documents/Makers/Data_Engineering/Week_6/dbt_warehouse', 'log_path': '/Users/denisechan/Documents/Makers/Data_Engineering/Week_6/dbt_warehouse/logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'log_format': 'default', 'target_path': 'None', 'send_anonymous_usage_stats': 'True'}
[0m10:47:56.623606 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '91703984-8afd-4bdf-ba96-4a0a3c277714', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103f199d0>]}
[0m10:47:56.662356 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '91703984-8afd-4bdf-ba96-4a0a3c277714', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10417d6d0>]}
[0m10:47:56.665086 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m10:47:56.711671 [debug] [MainThread]: checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, vars: {}, profile: , target: , version: 1.5.4
[0m10:47:56.935601 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m10:47:56.936574 [debug] [MainThread]: Partial parsing: updated file: maker_warehouse://models/facts/movies.sql
[0m10:47:56.995009 [debug] [MainThread]: 1699: static parser successfully parsed facts/movies.sql
[0m10:47:57.039692 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '91703984-8afd-4bdf-ba96-4a0a3c277714', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1044070d0>]}
[0m10:47:57.053123 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '91703984-8afd-4bdf-ba96-4a0a3c277714', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104319070>]}
[0m10:47:57.053918 [info ] [MainThread]: Found 1 model, 0 tests, 0 snapshots, 0 analyses, 307 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics, 0 groups
[0m10:47:57.055220 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '91703984-8afd-4bdf-ba96-4a0a3c277714', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104319040>]}
[0m10:47:57.057550 [info ] [MainThread]: 
[0m10:47:57.058938 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m10:47:57.060612 [debug] [ThreadPool]: Acquiring new postgres connection 'list_mydb'
[0m10:47:57.089565 [debug] [ThreadPool]: Using postgres connection "list_mydb"
[0m10:47:57.090502 [debug] [ThreadPool]: On list_mydb: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "connection_name": "list_mydb"} */

    select distinct nspname from pg_namespace
  
[0m10:47:57.091719 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:47:57.285933 [debug] [ThreadPool]: SQL status: SELECT 5 in 0.0 seconds
[0m10:47:57.291624 [debug] [ThreadPool]: On list_mydb: Close
[0m10:47:57.294297 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_mydb, now list_mydb_dbt_warehouse)
[0m10:47:57.308640 [debug] [ThreadPool]: Using postgres connection "list_mydb_dbt_warehouse"
[0m10:47:57.309283 [debug] [ThreadPool]: On list_mydb_dbt_warehouse: BEGIN
[0m10:47:57.309757 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m10:47:57.345411 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m10:47:57.346745 [debug] [ThreadPool]: Using postgres connection "list_mydb_dbt_warehouse"
[0m10:47:57.347575 [debug] [ThreadPool]: On list_mydb_dbt_warehouse: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "connection_name": "list_mydb_dbt_warehouse"} */
select
      'mydb' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_warehouse'
    union all
    select
      'mydb' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_warehouse'
  
[0m10:47:57.369928 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.0 seconds
[0m10:47:57.372095 [debug] [ThreadPool]: On list_mydb_dbt_warehouse: ROLLBACK
[0m10:47:57.374865 [debug] [ThreadPool]: On list_mydb_dbt_warehouse: Close
[0m10:47:57.386371 [debug] [MainThread]: Using postgres connection "master"
[0m10:47:57.387894 [debug] [MainThread]: On master: BEGIN
[0m10:47:57.389025 [debug] [MainThread]: Opening a new connection, currently in state init
[0m10:47:57.415800 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m10:47:57.416798 [debug] [MainThread]: Using postgres connection "master"
[0m10:47:57.417732 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m10:47:57.441808 [debug] [MainThread]: SQL status: SELECT 5 in 0.0 seconds
[0m10:47:57.443972 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '91703984-8afd-4bdf-ba96-4a0a3c277714', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1043811c0>]}
[0m10:47:57.445122 [debug] [MainThread]: On master: ROLLBACK
[0m10:47:57.447472 [debug] [MainThread]: Using postgres connection "master"
[0m10:47:57.448059 [debug] [MainThread]: On master: BEGIN
[0m10:47:57.451802 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m10:47:57.452793 [debug] [MainThread]: On master: COMMIT
[0m10:47:57.453746 [debug] [MainThread]: Using postgres connection "master"
[0m10:47:57.454272 [debug] [MainThread]: On master: COMMIT
[0m10:47:57.456806 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m10:47:57.457508 [debug] [MainThread]: On master: Close
[0m10:47:57.458801 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m10:47:57.460372 [info ] [MainThread]: 
[0m10:47:57.473367 [debug] [Thread-1  ]: Began running node model.maker_warehouse.movies
[0m10:47:57.474295 [info ] [Thread-1  ]: 1 of 1 START sql view model dbt_warehouse.movies ............................... [RUN]
[0m10:47:57.475605 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_mydb_dbt_warehouse, now model.maker_warehouse.movies)
[0m10:47:57.476238 [debug] [Thread-1  ]: Began compiling node model.maker_warehouse.movies
[0m10:47:57.494787 [debug] [Thread-1  ]: Writing injected SQL for node "model.maker_warehouse.movies"
[0m10:47:57.496220 [debug] [Thread-1  ]: Timing info for model.maker_warehouse.movies (compile): 10:47:57.476627 => 10:47:57.495803
[0m10:47:57.497013 [debug] [Thread-1  ]: Began executing node model.maker_warehouse.movies
[0m10:47:57.574813 [debug] [Thread-1  ]: Writing runtime sql for node "model.maker_warehouse.movies"
[0m10:47:57.576028 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.movies"
[0m10:47:57.576616 [debug] [Thread-1  ]: On model.maker_warehouse.movies: BEGIN
[0m10:47:57.577221 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m10:47:57.610838 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
[0m10:47:57.611667 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.movies"
[0m10:47:57.612350 [debug] [Thread-1  ]: On model.maker_warehouse.movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.movies"} */

  create view "mydb"."dbt_warehouse"."movies__dbt_tmp"
    
    
  as (
    SELECT
    DISTINCT
    title,
    genres,
    release_date,
    movie_id
FROM mydb.public.raw_netflix
  );
[0m10:47:57.671759 [debug] [Thread-1  ]: SQL status: CREATE VIEW in 0.0 seconds
[0m10:47:57.682376 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.movies"
[0m10:47:57.683366 [debug] [Thread-1  ]: On model.maker_warehouse.movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.movies"} */
alter table "mydb"."dbt_warehouse"."movies__dbt_tmp" rename to "movies"
[0m10:47:57.690819 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m10:47:57.720551 [debug] [Thread-1  ]: On model.maker_warehouse.movies: COMMIT
[0m10:47:57.721355 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.movies"
[0m10:47:57.722108 [debug] [Thread-1  ]: On model.maker_warehouse.movies: COMMIT
[0m10:47:57.728535 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
[0m10:47:57.742422 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.movies"
[0m10:47:57.743291 [debug] [Thread-1  ]: On model.maker_warehouse.movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.movies"} */
drop view if exists "mydb"."dbt_warehouse"."movies__dbt_backup" cascade
[0m10:47:57.748523 [debug] [Thread-1  ]: SQL status: DROP VIEW in 0.0 seconds
[0m10:47:57.752862 [debug] [Thread-1  ]: Timing info for model.maker_warehouse.movies (execute): 10:47:57.497493 => 10:47:57.751650
[0m10:47:57.753614 [debug] [Thread-1  ]: On model.maker_warehouse.movies: Close
[0m10:47:57.755045 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '91703984-8afd-4bdf-ba96-4a0a3c277714', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1044cca00>]}
[0m10:47:57.758316 [info ] [Thread-1  ]: 1 of 1 OK created sql view model dbt_warehouse.movies .......................... [[32mCREATE VIEW[0m in 0.28s]
[0m10:47:57.761634 [debug] [Thread-1  ]: Finished running node model.maker_warehouse.movies
[0m10:47:57.767310 [debug] [MainThread]: Using postgres connection "master"
[0m10:47:57.768770 [debug] [MainThread]: On master: BEGIN
[0m10:47:57.769508 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m10:47:57.813297 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m10:47:57.813979 [debug] [MainThread]: On master: COMMIT
[0m10:47:57.814487 [debug] [MainThread]: Using postgres connection "master"
[0m10:47:57.814953 [debug] [MainThread]: On master: COMMIT
[0m10:47:57.823382 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m10:47:57.825160 [debug] [MainThread]: On master: Close
[0m10:47:57.827285 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:47:57.828706 [debug] [MainThread]: Connection 'model.maker_warehouse.movies' was properly closed.
[0m10:47:57.829597 [info ] [MainThread]: 
[0m10:47:57.830584 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 0.77 seconds (0.77s).
[0m10:47:57.832256 [debug] [MainThread]: Command end result
[0m10:47:57.846541 [info ] [MainThread]: 
[0m10:47:57.847592 [info ] [MainThread]: [32mCompleted successfully[0m
[0m10:47:57.848250 [info ] [MainThread]: 
[0m10:47:57.848959 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m10:47:57.850617 [debug] [MainThread]: Command `dbt run` succeeded at 10:47:57.850324 after 1.47 seconds
[0m10:47:57.855428 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102b7e4f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1043aad60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104367ac0>]}
[0m10:47:57.856783 [debug] [MainThread]: Flushing usage events
[0m10:52:08.630887 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107e2df40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1091c7a30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1091be700>]}


============================== 10:52:08.639574 | b248d54a-d332-4e98-8eda-e0899467a655 ==============================
[0m10:52:08.639574 [info ] [MainThread]: Running with dbt=1.5.4
[0m10:52:08.641451 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/denisechan/Documents/Makers/Data_Engineering/Week_6/dbt_warehouse', 'debug': 'False', 'warn_error': 'None', 'log_path': '/Users/denisechan/Documents/Makers/Data_Engineering/Week_6/dbt_warehouse/logs', 'version_check': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'send_anonymous_usage_stats': 'True'}
[0m10:52:08.855088 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'b248d54a-d332-4e98-8eda-e0899467a655', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1091be700>]}
[0m10:52:08.892369 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'b248d54a-d332-4e98-8eda-e0899467a655', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10942c730>]}
[0m10:52:08.895007 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m10:52:08.938257 [debug] [MainThread]: checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, vars: {}, profile: , target: , version: 1.5.4
[0m10:52:09.078093 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m10:52:09.078996 [debug] [MainThread]: Partial parsing: updated file: maker_warehouse://models/facts/movies.sql
[0m10:52:09.135705 [debug] [MainThread]: 1699: static parser successfully parsed facts/movies.sql
[0m10:52:09.172997 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b248d54a-d332-4e98-8eda-e0899467a655', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1096b70d0>]}
[0m10:52:09.184991 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b248d54a-d332-4e98-8eda-e0899467a655', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1095be160>]}
[0m10:52:09.186095 [info ] [MainThread]: Found 1 model, 0 tests, 0 snapshots, 0 analyses, 307 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics, 0 groups
[0m10:52:09.186994 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b248d54a-d332-4e98-8eda-e0899467a655', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1095be0d0>]}
[0m10:52:09.189146 [info ] [MainThread]: 
[0m10:52:09.190392 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m10:52:09.191795 [debug] [ThreadPool]: Acquiring new postgres connection 'list_mydb'
[0m10:52:09.209785 [debug] [ThreadPool]: Using postgres connection "list_mydb"
[0m10:52:09.210390 [debug] [ThreadPool]: On list_mydb: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "connection_name": "list_mydb"} */

    select distinct nspname from pg_namespace
  
[0m10:52:09.210881 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:52:09.377210 [debug] [ThreadPool]: SQL status: SELECT 5 in 0.0 seconds
[0m10:52:09.380623 [debug] [ThreadPool]: On list_mydb: Close
[0m10:52:09.383969 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_mydb, now list_mydb_dbt_warehouse)
[0m10:52:09.397012 [debug] [ThreadPool]: Using postgres connection "list_mydb_dbt_warehouse"
[0m10:52:09.397632 [debug] [ThreadPool]: On list_mydb_dbt_warehouse: BEGIN
[0m10:52:09.398203 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m10:52:09.427484 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m10:52:09.428940 [debug] [ThreadPool]: Using postgres connection "list_mydb_dbt_warehouse"
[0m10:52:09.429547 [debug] [ThreadPool]: On list_mydb_dbt_warehouse: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "connection_name": "list_mydb_dbt_warehouse"} */
select
      'mydb' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_warehouse'
    union all
    select
      'mydb' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_warehouse'
  
[0m10:52:09.444290 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.0 seconds
[0m10:52:09.448784 [debug] [ThreadPool]: On list_mydb_dbt_warehouse: ROLLBACK
[0m10:52:09.451363 [debug] [ThreadPool]: On list_mydb_dbt_warehouse: Close
[0m10:52:09.462287 [debug] [MainThread]: Using postgres connection "master"
[0m10:52:09.463272 [debug] [MainThread]: On master: BEGIN
[0m10:52:09.463840 [debug] [MainThread]: Opening a new connection, currently in state init
[0m10:52:09.493231 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m10:52:09.493852 [debug] [MainThread]: Using postgres connection "master"
[0m10:52:09.494455 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m10:52:09.518437 [debug] [MainThread]: SQL status: SELECT 6 in 0.0 seconds
[0m10:52:09.520638 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b248d54a-d332-4e98-8eda-e0899467a655', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10962ef70>]}
[0m10:52:09.521541 [debug] [MainThread]: On master: ROLLBACK
[0m10:52:09.523412 [debug] [MainThread]: Using postgres connection "master"
[0m10:52:09.524154 [debug] [MainThread]: On master: BEGIN
[0m10:52:09.529093 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m10:52:09.530000 [debug] [MainThread]: On master: COMMIT
[0m10:52:09.531071 [debug] [MainThread]: Using postgres connection "master"
[0m10:52:09.531795 [debug] [MainThread]: On master: COMMIT
[0m10:52:09.534236 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m10:52:09.534957 [debug] [MainThread]: On master: Close
[0m10:52:09.536717 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m10:52:09.537533 [info ] [MainThread]: 
[0m10:52:09.551584 [debug] [Thread-1  ]: Began running node model.maker_warehouse.movies
[0m10:52:09.552519 [info ] [Thread-1  ]: 1 of 1 START sql table model dbt_warehouse.movies .............................. [RUN]
[0m10:52:09.553708 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_mydb_dbt_warehouse, now model.maker_warehouse.movies)
[0m10:52:09.554338 [debug] [Thread-1  ]: Began compiling node model.maker_warehouse.movies
[0m10:52:09.569234 [debug] [Thread-1  ]: Writing injected SQL for node "model.maker_warehouse.movies"
[0m10:52:09.571535 [debug] [Thread-1  ]: Timing info for model.maker_warehouse.movies (compile): 10:52:09.554839 => 10:52:09.571002
[0m10:52:09.572184 [debug] [Thread-1  ]: Began executing node model.maker_warehouse.movies
[0m10:52:09.673594 [debug] [Thread-1  ]: Writing runtime sql for node "model.maker_warehouse.movies"
[0m10:52:09.675621 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.movies"
[0m10:52:09.676324 [debug] [Thread-1  ]: On model.maker_warehouse.movies: BEGIN
[0m10:52:09.676880 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m10:52:09.710921 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
[0m10:52:09.712511 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.movies"
[0m10:52:09.713611 [debug] [Thread-1  ]: On model.maker_warehouse.movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.movies"} */

  
    

  create  table "mydb"."dbt_warehouse"."movies__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    DISTINCT
    title,
    genres,
    release_date,
    movie_id
FROM mydb.public.raw_netflix
  );
  
[0m10:52:17.171831 [debug] [Thread-1  ]: SQL status: SELECT 8472 in 7.0 seconds
[0m10:52:17.187293 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.movies"
[0m10:52:17.188119 [debug] [Thread-1  ]: On model.maker_warehouse.movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.movies"} */
alter table "mydb"."dbt_warehouse"."movies" rename to "movies__dbt_backup"
[0m10:52:17.191339 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m10:52:17.200772 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.movies"
[0m10:52:17.202522 [debug] [Thread-1  ]: On model.maker_warehouse.movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.movies"} */
alter table "mydb"."dbt_warehouse"."movies__dbt_tmp" rename to "movies"
[0m10:52:17.206088 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m10:52:17.259372 [debug] [Thread-1  ]: On model.maker_warehouse.movies: COMMIT
[0m10:52:17.260336 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.movies"
[0m10:52:17.262327 [debug] [Thread-1  ]: On model.maker_warehouse.movies: COMMIT
[0m10:52:17.267213 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
[0m10:52:17.280870 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.movies"
[0m10:52:17.281634 [debug] [Thread-1  ]: On model.maker_warehouse.movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.movies"} */
drop view if exists "mydb"."dbt_warehouse"."movies__dbt_backup" cascade
[0m10:52:17.308243 [debug] [Thread-1  ]: SQL status: DROP VIEW in 0.0 seconds
[0m10:52:17.311698 [debug] [Thread-1  ]: Timing info for model.maker_warehouse.movies (execute): 10:52:09.572596 => 10:52:17.311222
[0m10:52:17.312475 [debug] [Thread-1  ]: On model.maker_warehouse.movies: Close
[0m10:52:17.316358 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b248d54a-d332-4e98-8eda-e0899467a655', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109786d90>]}
[0m10:52:17.325148 [info ] [Thread-1  ]: 1 of 1 OK created sql table model dbt_warehouse.movies ......................... [[32mSELECT 8472[0m in 7.76s]
[0m10:52:17.328702 [debug] [Thread-1  ]: Finished running node model.maker_warehouse.movies
[0m10:52:17.333737 [debug] [MainThread]: Using postgres connection "master"
[0m10:52:17.334443 [debug] [MainThread]: On master: BEGIN
[0m10:52:17.335314 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m10:52:17.453585 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m10:52:17.454692 [debug] [MainThread]: On master: COMMIT
[0m10:52:17.455375 [debug] [MainThread]: Using postgres connection "master"
[0m10:52:17.456703 [debug] [MainThread]: On master: COMMIT
[0m10:52:17.459431 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m10:52:17.460378 [debug] [MainThread]: On master: Close
[0m10:52:17.470158 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:52:17.471512 [debug] [MainThread]: Connection 'model.maker_warehouse.movies' was properly closed.
[0m10:52:17.472910 [info ] [MainThread]: 
[0m10:52:17.480767 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 8.28 seconds (8.28s).
[0m10:52:17.510502 [debug] [MainThread]: Command end result
[0m10:52:18.211553 [info ] [MainThread]: 
[0m10:52:18.216803 [info ] [MainThread]: [32mCompleted successfully[0m
[0m10:52:18.220705 [info ] [MainThread]: 
[0m10:52:18.222836 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m10:52:18.227026 [debug] [MainThread]: Command `dbt run` succeeded at 10:52:18.226681 after 9.65 seconds
[0m10:52:18.229158 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107e2df40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109615b20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10981d880>]}
[0m10:52:18.230328 [debug] [MainThread]: Flushing usage events
[0m10:55:09.494225 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1109727f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111d0e2b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e505a00>]}


============================== 10:55:09.502572 | 22d1facf-71b6-4dc5-89ff-5f61bb08d42c ==============================
[0m10:55:09.502572 [info ] [MainThread]: Running with dbt=1.5.4
[0m10:55:09.507612 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': '/Users/denisechan/Documents/Makers/Data_Engineering/Week_6/dbt_warehouse', 'log_path': '/Users/denisechan/Documents/Makers/Data_Engineering/Week_6/dbt_warehouse/logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'send_anonymous_usage_stats': 'True'}
[0m10:55:09.715957 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '22d1facf-71b6-4dc5-89ff-5f61bb08d42c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111d0e9a0>]}
[0m10:55:09.767110 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '22d1facf-71b6-4dc5-89ff-5f61bb08d42c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111f716a0>]}
[0m10:55:09.769946 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m10:55:09.825981 [debug] [MainThread]: checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, vars: {}, profile: , target: , version: 1.5.4
[0m10:55:09.996318 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
[0m10:55:09.997124 [debug] [MainThread]: Partial parsing: added file: maker_warehouse://models/facts/select_movies.sql
[0m10:55:10.067673 [debug] [MainThread]: 1699: static parser successfully parsed facts/select_movies.sql
[0m10:55:10.114735 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '22d1facf-71b6-4dc5-89ff-5f61bb08d42c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1121fb0d0>]}
[0m10:55:10.128724 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '22d1facf-71b6-4dc5-89ff-5f61bb08d42c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112175fd0>]}
[0m10:55:10.129548 [info ] [MainThread]: Found 2 models, 0 tests, 0 snapshots, 0 analyses, 307 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics, 0 groups
[0m10:55:10.130314 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '22d1facf-71b6-4dc5-89ff-5f61bb08d42c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1121757c0>]}
[0m10:55:10.132366 [info ] [MainThread]: 
[0m10:55:10.134693 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m10:55:10.136356 [debug] [ThreadPool]: Acquiring new postgres connection 'list_mydb'
[0m10:55:10.162231 [debug] [ThreadPool]: Using postgres connection "list_mydb"
[0m10:55:10.163618 [debug] [ThreadPool]: On list_mydb: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "connection_name": "list_mydb"} */

    select distinct nspname from pg_namespace
  
[0m10:55:10.165006 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:55:10.600960 [debug] [ThreadPool]: SQL status: SELECT 5 in 0.0 seconds
[0m10:55:10.668486 [debug] [ThreadPool]: On list_mydb: Close
[0m10:55:10.677013 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_mydb, now list_mydb_dbt_warehouse)
[0m10:55:10.696663 [debug] [ThreadPool]: Using postgres connection "list_mydb_dbt_warehouse"
[0m10:55:10.734331 [debug] [ThreadPool]: On list_mydb_dbt_warehouse: BEGIN
[0m10:55:10.735277 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m10:55:10.877666 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m10:55:10.878678 [debug] [ThreadPool]: Using postgres connection "list_mydb_dbt_warehouse"
[0m10:55:10.879471 [debug] [ThreadPool]: On list_mydb_dbt_warehouse: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "connection_name": "list_mydb_dbt_warehouse"} */
select
      'mydb' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_warehouse'
    union all
    select
      'mydb' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_warehouse'
  
[0m10:55:10.916374 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.0 seconds
[0m10:55:10.921472 [debug] [ThreadPool]: On list_mydb_dbt_warehouse: ROLLBACK
[0m10:55:10.934355 [debug] [ThreadPool]: On list_mydb_dbt_warehouse: Close
[0m10:55:10.956643 [debug] [MainThread]: Using postgres connection "master"
[0m10:55:10.958036 [debug] [MainThread]: On master: BEGIN
[0m10:55:10.958791 [debug] [MainThread]: Opening a new connection, currently in state init
[0m10:55:11.022561 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m10:55:11.025321 [debug] [MainThread]: Using postgres connection "master"
[0m10:55:11.027696 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m10:55:11.249818 [debug] [MainThread]: SQL status: SELECT 5 in 0.0 seconds
[0m10:55:11.255576 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '22d1facf-71b6-4dc5-89ff-5f61bb08d42c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111f8fb80>]}
[0m10:55:11.258028 [debug] [MainThread]: On master: ROLLBACK
[0m10:55:11.280065 [debug] [MainThread]: Using postgres connection "master"
[0m10:55:11.281186 [debug] [MainThread]: On master: BEGIN
[0m10:55:11.358636 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m10:55:11.359570 [debug] [MainThread]: On master: COMMIT
[0m10:55:11.360346 [debug] [MainThread]: Using postgres connection "master"
[0m10:55:11.361504 [debug] [MainThread]: On master: COMMIT
[0m10:55:11.365061 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m10:55:11.366153 [debug] [MainThread]: On master: Close
[0m10:55:11.369443 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m10:55:11.370799 [info ] [MainThread]: 
[0m10:55:11.393340 [debug] [Thread-1  ]: Began running node model.maker_warehouse.movies
[0m10:55:11.396668 [info ] [Thread-1  ]: 1 of 2 START sql table model dbt_warehouse.movies .............................. [RUN]
[0m10:55:11.400201 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_mydb_dbt_warehouse, now model.maker_warehouse.movies)
[0m10:55:11.401824 [debug] [Thread-1  ]: Began compiling node model.maker_warehouse.movies
[0m10:55:11.507726 [debug] [Thread-1  ]: Writing injected SQL for node "model.maker_warehouse.movies"
[0m10:55:11.511616 [debug] [Thread-1  ]: Timing info for model.maker_warehouse.movies (compile): 10:55:11.402470 => 10:55:11.510940
[0m10:55:11.512801 [debug] [Thread-1  ]: Began executing node model.maker_warehouse.movies
[0m10:55:12.100664 [debug] [Thread-1  ]: Writing runtime sql for node "model.maker_warehouse.movies"
[0m10:55:12.103610 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.movies"
[0m10:55:12.131421 [debug] [Thread-1  ]: On model.maker_warehouse.movies: BEGIN
[0m10:55:12.132336 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m10:55:12.233824 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
[0m10:55:12.236168 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.movies"
[0m10:55:12.238464 [debug] [Thread-1  ]: On model.maker_warehouse.movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.movies"} */

  
    

  create  table "mydb"."dbt_warehouse"."movies__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    DISTINCT
    title,
    genres,
    release_date,
    movie_id
FROM mydb.public.raw_netflix
  );
  
[0m10:55:14.903573 [debug] [Thread-1  ]: SQL status: SELECT 8472 in 3.0 seconds
[0m10:55:14.920549 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.movies"
[0m10:55:14.922019 [debug] [Thread-1  ]: On model.maker_warehouse.movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.movies"} */
alter table "mydb"."dbt_warehouse"."movies" rename to "movies__dbt_backup"
[0m10:55:14.928915 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m10:55:14.937741 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.movies"
[0m10:55:14.939064 [debug] [Thread-1  ]: On model.maker_warehouse.movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.movies"} */
alter table "mydb"."dbt_warehouse"."movies__dbt_tmp" rename to "movies"
[0m10:55:14.943865 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m10:55:15.017221 [debug] [Thread-1  ]: On model.maker_warehouse.movies: COMMIT
[0m10:55:15.018633 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.movies"
[0m10:55:15.019683 [debug] [Thread-1  ]: On model.maker_warehouse.movies: COMMIT
[0m10:55:15.028752 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
[0m10:55:15.052878 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.movies"
[0m10:55:15.053846 [debug] [Thread-1  ]: On model.maker_warehouse.movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.movies"} */
drop table if exists "mydb"."dbt_warehouse"."movies__dbt_backup" cascade
[0m10:55:15.076128 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
[0m10:55:15.089605 [debug] [Thread-1  ]: Timing info for model.maker_warehouse.movies (execute): 10:55:11.513668 => 10:55:15.088276
[0m10:55:15.095779 [debug] [Thread-1  ]: On model.maker_warehouse.movies: Close
[0m10:55:15.098528 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '22d1facf-71b6-4dc5-89ff-5f61bb08d42c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1122c7eb0>]}
[0m10:55:15.101407 [info ] [Thread-1  ]: 1 of 2 OK created sql table model dbt_warehouse.movies ......................... [[32mSELECT 8472[0m in 3.70s]
[0m10:55:15.116057 [debug] [Thread-1  ]: Finished running node model.maker_warehouse.movies
[0m10:55:15.125540 [debug] [Thread-3  ]: Began running node model.maker_warehouse.select_movies
[0m10:55:15.126823 [info ] [Thread-3  ]: 2 of 2 START sql table model dbt_warehouse.select_movies ....................... [RUN]
[0m10:55:15.128911 [debug] [Thread-3  ]: Acquiring new postgres connection 'model.maker_warehouse.select_movies'
[0m10:55:15.130184 [debug] [Thread-3  ]: Began compiling node model.maker_warehouse.select_movies
[0m10:55:15.144918 [debug] [Thread-3  ]: Writing injected SQL for node "model.maker_warehouse.select_movies"
[0m10:55:15.148137 [debug] [Thread-3  ]: Timing info for model.maker_warehouse.select_movies (compile): 10:55:15.131362 => 10:55:15.147383
[0m10:55:15.148948 [debug] [Thread-3  ]: Began executing node model.maker_warehouse.select_movies
[0m10:55:15.181132 [debug] [Thread-3  ]: Writing runtime sql for node "model.maker_warehouse.select_movies"
[0m10:55:15.188858 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.select_movies"
[0m10:55:15.190013 [debug] [Thread-3  ]: On model.maker_warehouse.select_movies: BEGIN
[0m10:55:15.190788 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m10:55:15.245203 [debug] [Thread-3  ]: SQL status: BEGIN in 0.0 seconds
[0m10:55:15.247225 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.select_movies"
[0m10:55:15.248416 [debug] [Thread-3  ]: On model.maker_warehouse.select_movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.select_movies"} */

  
    

  create  table "mydb"."dbt_warehouse"."select_movies__dbt_tmp"
  
  
    as
  
  (
    
  
SELECT
*
"mydb"."dbt_warehouse"."movies"
  );
  
[0m10:55:15.253783 [debug] [Thread-3  ]: Postgres adapter: Postgres error: syntax error at or near ""mydb""
LINE 16: "mydb"."dbt_warehouse"."movies"
         ^

[0m10:55:15.255153 [debug] [Thread-3  ]: On model.maker_warehouse.select_movies: ROLLBACK
[0m10:55:15.258581 [debug] [Thread-3  ]: Timing info for model.maker_warehouse.select_movies (execute): 10:55:15.149363 => 10:55:15.258107
[0m10:55:15.259733 [debug] [Thread-3  ]: On model.maker_warehouse.select_movies: Close
[0m10:55:15.275605 [debug] [Thread-3  ]: Database Error in model select_movies (models/facts/select_movies.sql)
  syntax error at or near ""mydb""
  LINE 16: "mydb"."dbt_warehouse"."movies"
           ^
  compiled Code at target/run/maker_warehouse/models/facts/select_movies.sql
[0m10:55:15.277131 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '22d1facf-71b6-4dc5-89ff-5f61bb08d42c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1123838b0>]}
[0m10:55:15.278547 [error] [Thread-3  ]: 2 of 2 ERROR creating sql table model dbt_warehouse.select_movies .............. [[31mERROR[0m in 0.15s]
[0m10:55:15.280528 [debug] [Thread-3  ]: Finished running node model.maker_warehouse.select_movies
[0m10:55:15.284352 [debug] [MainThread]: Using postgres connection "master"
[0m10:55:15.285591 [debug] [MainThread]: On master: BEGIN
[0m10:55:15.286874 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m10:55:15.448494 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m10:55:15.449809 [debug] [MainThread]: On master: COMMIT
[0m10:55:15.451006 [debug] [MainThread]: Using postgres connection "master"
[0m10:55:15.452185 [debug] [MainThread]: On master: COMMIT
[0m10:55:15.455973 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m10:55:15.456934 [debug] [MainThread]: On master: Close
[0m10:55:15.460528 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:55:15.461220 [debug] [MainThread]: Connection 'model.maker_warehouse.movies' was properly closed.
[0m10:55:15.461679 [debug] [MainThread]: Connection 'model.maker_warehouse.select_movies' was properly closed.
[0m10:55:15.462226 [info ] [MainThread]: 
[0m10:55:15.465064 [info ] [MainThread]: Finished running 2 table models in 0 hours 0 minutes and 5.33 seconds (5.33s).
[0m10:55:15.471362 [debug] [MainThread]: Command end result
[0m10:55:15.497179 [info ] [MainThread]: 
[0m10:55:15.498911 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m10:55:15.500740 [info ] [MainThread]: 
[0m10:55:15.502304 [error] [MainThread]: [33mDatabase Error in model select_movies (models/facts/select_movies.sql)[0m
[0m10:55:15.503358 [error] [MainThread]:   syntax error at or near ""mydb""
[0m10:55:15.505792 [error] [MainThread]:   LINE 16: "mydb"."dbt_warehouse"."movies"
[0m10:55:15.514916 [error] [MainThread]:            ^
[0m10:55:15.516858 [error] [MainThread]:   compiled Code at target/run/maker_warehouse/models/facts/select_movies.sql
[0m10:55:15.528270 [info ] [MainThread]: 
[0m10:55:15.534013 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=1 SKIP=0 TOTAL=2
[0m10:55:15.556015 [debug] [MainThread]: Command `dbt run` failed at 10:55:15.555494 after 6.12 seconds
[0m10:55:15.558255 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1109727f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111f716a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112383a00>]}
[0m10:55:15.559477 [debug] [MainThread]: Flushing usage events
[0m10:56:14.400369 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10db60fa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10eefb2b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b6f2a00>]}


============================== 10:56:14.409066 | 2b61c754-ad0e-4e60-806f-870992a13fe6 ==============================
[0m10:56:14.409066 [info ] [MainThread]: Running with dbt=1.5.4
[0m10:56:14.410893 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/Users/denisechan/Documents/Makers/Data_Engineering/Week_6/dbt_warehouse/logs', 'version_check': 'True', 'profiles_dir': '/Users/denisechan/Documents/Makers/Data_Engineering/Week_6/dbt_warehouse', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'send_anonymous_usage_stats': 'True'}
[0m10:56:14.581524 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '2b61c754-ad0e-4e60-806f-870992a13fe6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10eefb8e0>]}
[0m10:56:14.619575 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '2b61c754-ad0e-4e60-806f-870992a13fe6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f15e5e0>]}
[0m10:56:14.621368 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m10:56:14.660491 [debug] [MainThread]: checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, vars: {}, profile: , target: , version: 1.5.4
[0m10:56:14.803908 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m10:56:14.805727 [debug] [MainThread]: Partial parsing: updated file: maker_warehouse://models/facts/select_movies.sql
[0m10:56:14.862507 [debug] [MainThread]: 1699: static parser successfully parsed facts/select_movies.sql
[0m10:56:14.903317 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2b61c754-ad0e-4e60-806f-870992a13fe6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f3e80d0>]}
[0m10:56:14.917088 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '2b61c754-ad0e-4e60-806f-870992a13fe6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f3124f0>]}
[0m10:56:14.917979 [info ] [MainThread]: Found 2 models, 0 tests, 0 snapshots, 0 analyses, 307 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics, 0 groups
[0m10:56:14.918855 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2b61c754-ad0e-4e60-806f-870992a13fe6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f312460>]}
[0m10:56:14.921536 [info ] [MainThread]: 
[0m10:56:14.922993 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m10:56:14.925551 [debug] [ThreadPool]: Acquiring new postgres connection 'list_mydb'
[0m10:56:14.944516 [debug] [ThreadPool]: Using postgres connection "list_mydb"
[0m10:56:14.945823 [debug] [ThreadPool]: On list_mydb: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "connection_name": "list_mydb"} */

    select distinct nspname from pg_namespace
  
[0m10:56:14.946818 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:56:15.109074 [debug] [ThreadPool]: SQL status: SELECT 5 in 0.0 seconds
[0m10:56:15.112498 [debug] [ThreadPool]: On list_mydb: Close
[0m10:56:15.115937 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_mydb, now list_mydb_dbt_warehouse)
[0m10:56:15.130975 [debug] [ThreadPool]: Using postgres connection "list_mydb_dbt_warehouse"
[0m10:56:15.131583 [debug] [ThreadPool]: On list_mydb_dbt_warehouse: BEGIN
[0m10:56:15.132040 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m10:56:15.160587 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m10:56:15.161499 [debug] [ThreadPool]: Using postgres connection "list_mydb_dbt_warehouse"
[0m10:56:15.162224 [debug] [ThreadPool]: On list_mydb_dbt_warehouse: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "connection_name": "list_mydb_dbt_warehouse"} */
select
      'mydb' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_warehouse'
    union all
    select
      'mydb' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_warehouse'
  
[0m10:56:15.180882 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.0 seconds
[0m10:56:15.184424 [debug] [ThreadPool]: On list_mydb_dbt_warehouse: ROLLBACK
[0m10:56:15.187666 [debug] [ThreadPool]: On list_mydb_dbt_warehouse: Close
[0m10:56:15.199934 [debug] [MainThread]: Using postgres connection "master"
[0m10:56:15.200839 [debug] [MainThread]: On master: BEGIN
[0m10:56:15.201476 [debug] [MainThread]: Opening a new connection, currently in state init
[0m10:56:15.229571 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m10:56:15.230233 [debug] [MainThread]: Using postgres connection "master"
[0m10:56:15.230904 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m10:56:15.259566 [debug] [MainThread]: SQL status: SELECT 5 in 0.0 seconds
[0m10:56:15.261726 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2b61c754-ad0e-4e60-806f-870992a13fe6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f402340>]}
[0m10:56:15.262438 [debug] [MainThread]: On master: ROLLBACK
[0m10:56:15.265224 [debug] [MainThread]: Using postgres connection "master"
[0m10:56:15.266124 [debug] [MainThread]: On master: BEGIN
[0m10:56:15.269710 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m10:56:15.270913 [debug] [MainThread]: On master: COMMIT
[0m10:56:15.271909 [debug] [MainThread]: Using postgres connection "master"
[0m10:56:15.272529 [debug] [MainThread]: On master: COMMIT
[0m10:56:15.274362 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m10:56:15.275026 [debug] [MainThread]: On master: Close
[0m10:56:15.276519 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m10:56:15.277530 [info ] [MainThread]: 
[0m10:56:15.290353 [debug] [Thread-1  ]: Began running node model.maker_warehouse.movies
[0m10:56:15.291271 [info ] [Thread-1  ]: 1 of 2 START sql table model dbt_warehouse.movies .............................. [RUN]
[0m10:56:15.292608 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_mydb_dbt_warehouse, now model.maker_warehouse.movies)
[0m10:56:15.293282 [debug] [Thread-1  ]: Began compiling node model.maker_warehouse.movies
[0m10:56:15.313037 [debug] [Thread-1  ]: Writing injected SQL for node "model.maker_warehouse.movies"
[0m10:56:15.315901 [debug] [Thread-1  ]: Timing info for model.maker_warehouse.movies (compile): 10:56:15.293686 => 10:56:15.315287
[0m10:56:15.316639 [debug] [Thread-1  ]: Began executing node model.maker_warehouse.movies
[0m10:56:15.417730 [debug] [Thread-1  ]: Writing runtime sql for node "model.maker_warehouse.movies"
[0m10:56:15.419268 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.movies"
[0m10:56:15.420770 [debug] [Thread-1  ]: On model.maker_warehouse.movies: BEGIN
[0m10:56:15.421767 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m10:56:15.453605 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
[0m10:56:15.454714 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.movies"
[0m10:56:15.456716 [debug] [Thread-1  ]: On model.maker_warehouse.movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.movies"} */

  
    

  create  table "mydb"."dbt_warehouse"."movies__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    DISTINCT
    title,
    genres,
    release_date,
    movie_id
FROM mydb.public.raw_netflix
  );
  
[0m10:56:16.336429 [debug] [Thread-1  ]: SQL status: SELECT 8472 in 1.0 seconds
[0m10:56:16.349817 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.movies"
[0m10:56:16.350496 [debug] [Thread-1  ]: On model.maker_warehouse.movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.movies"} */
alter table "mydb"."dbt_warehouse"."movies" rename to "movies__dbt_backup"
[0m10:56:16.353732 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m10:56:16.358998 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.movies"
[0m10:56:16.359645 [debug] [Thread-1  ]: On model.maker_warehouse.movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.movies"} */
alter table "mydb"."dbt_warehouse"."movies__dbt_tmp" rename to "movies"
[0m10:56:16.362956 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m10:56:16.405096 [debug] [Thread-1  ]: On model.maker_warehouse.movies: COMMIT
[0m10:56:16.406290 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.movies"
[0m10:56:16.407708 [debug] [Thread-1  ]: On model.maker_warehouse.movies: COMMIT
[0m10:56:16.417666 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
[0m10:56:16.428228 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.movies"
[0m10:56:16.429121 [debug] [Thread-1  ]: On model.maker_warehouse.movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.movies"} */
drop table if exists "mydb"."dbt_warehouse"."movies__dbt_backup" cascade
[0m10:56:16.437807 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
[0m10:56:16.441183 [debug] [Thread-1  ]: Timing info for model.maker_warehouse.movies (execute): 10:56:15.317028 => 10:56:16.440796
[0m10:56:16.442083 [debug] [Thread-1  ]: On model.maker_warehouse.movies: Close
[0m10:56:16.443623 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2b61c754-ad0e-4e60-806f-870992a13fe6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f4bcd00>]}
[0m10:56:16.445123 [info ] [Thread-1  ]: 1 of 2 OK created sql table model dbt_warehouse.movies ......................... [[32mSELECT 8472[0m in 1.15s]
[0m10:56:16.448595 [debug] [Thread-1  ]: Finished running node model.maker_warehouse.movies
[0m10:56:16.451052 [debug] [Thread-3  ]: Began running node model.maker_warehouse.select_movies
[0m10:56:16.452139 [info ] [Thread-3  ]: 2 of 2 START sql table model dbt_warehouse.select_movies ....................... [RUN]
[0m10:56:16.454474 [debug] [Thread-3  ]: Acquiring new postgres connection 'model.maker_warehouse.select_movies'
[0m10:56:16.455498 [debug] [Thread-3  ]: Began compiling node model.maker_warehouse.select_movies
[0m10:56:16.462030 [debug] [Thread-3  ]: Writing injected SQL for node "model.maker_warehouse.select_movies"
[0m10:56:16.463376 [debug] [Thread-3  ]: Timing info for model.maker_warehouse.select_movies (compile): 10:56:16.456072 => 10:56:16.462942
[0m10:56:16.464478 [debug] [Thread-3  ]: Began executing node model.maker_warehouse.select_movies
[0m10:56:16.480893 [debug] [Thread-3  ]: Writing runtime sql for node "model.maker_warehouse.select_movies"
[0m10:56:16.482665 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.select_movies"
[0m10:56:16.483323 [debug] [Thread-3  ]: On model.maker_warehouse.select_movies: BEGIN
[0m10:56:16.483864 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m10:56:16.519373 [debug] [Thread-3  ]: SQL status: BEGIN in 0.0 seconds
[0m10:56:16.520757 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.select_movies"
[0m10:56:16.521861 [debug] [Thread-3  ]: On model.maker_warehouse.select_movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.select_movies"} */

  
    

  create  table "mydb"."dbt_warehouse"."select_movies__dbt_tmp"
  
  
    as
  
  (
    
  
SELECT
*
FROM "mydb"."dbt_warehouse"."movies"
  );
  
[0m10:56:16.558175 [debug] [Thread-3  ]: SQL status: SELECT 8472 in 0.0 seconds
[0m10:56:16.563845 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.select_movies"
[0m10:56:16.564938 [debug] [Thread-3  ]: On model.maker_warehouse.select_movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.select_movies"} */
alter table "mydb"."dbt_warehouse"."select_movies__dbt_tmp" rename to "select_movies"
[0m10:56:16.568172 [debug] [Thread-3  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m10:56:16.572498 [debug] [Thread-3  ]: On model.maker_warehouse.select_movies: COMMIT
[0m10:56:16.573213 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.select_movies"
[0m10:56:16.573769 [debug] [Thread-3  ]: On model.maker_warehouse.select_movies: COMMIT
[0m10:56:16.587699 [debug] [Thread-3  ]: SQL status: COMMIT in 0.0 seconds
[0m10:56:16.592761 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.select_movies"
[0m10:56:16.593504 [debug] [Thread-3  ]: On model.maker_warehouse.select_movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.select_movies"} */
drop table if exists "mydb"."dbt_warehouse"."select_movies__dbt_backup" cascade
[0m10:56:16.597509 [debug] [Thread-3  ]: SQL status: DROP TABLE in 0.0 seconds
[0m10:56:16.600600 [debug] [Thread-3  ]: Timing info for model.maker_warehouse.select_movies (execute): 10:56:16.465486 => 10:56:16.600017
[0m10:56:16.601284 [debug] [Thread-3  ]: On model.maker_warehouse.select_movies: Close
[0m10:56:16.602607 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2b61c754-ad0e-4e60-806f-870992a13fe6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f43fa90>]}
[0m10:56:16.604577 [info ] [Thread-3  ]: 2 of 2 OK created sql table model dbt_warehouse.select_movies .................. [[32mSELECT 8472[0m in 0.15s]
[0m10:56:16.607499 [debug] [Thread-3  ]: Finished running node model.maker_warehouse.select_movies
[0m10:56:16.610114 [debug] [MainThread]: Using postgres connection "master"
[0m10:56:16.610698 [debug] [MainThread]: On master: BEGIN
[0m10:56:16.611185 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m10:56:16.651799 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m10:56:16.652464 [debug] [MainThread]: On master: COMMIT
[0m10:56:16.652945 [debug] [MainThread]: Using postgres connection "master"
[0m10:56:16.653513 [debug] [MainThread]: On master: COMMIT
[0m10:56:16.657940 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m10:56:16.658758 [debug] [MainThread]: On master: Close
[0m10:56:16.660565 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:56:16.661210 [debug] [MainThread]: Connection 'model.maker_warehouse.movies' was properly closed.
[0m10:56:16.661931 [debug] [MainThread]: Connection 'model.maker_warehouse.select_movies' was properly closed.
[0m10:56:16.662670 [info ] [MainThread]: 
[0m10:56:16.663978 [info ] [MainThread]: Finished running 2 table models in 0 hours 0 minutes and 1.74 seconds (1.74s).
[0m10:56:16.667682 [debug] [MainThread]: Command end result
[0m10:56:16.679566 [info ] [MainThread]: 
[0m10:56:16.680878 [info ] [MainThread]: [32mCompleted successfully[0m
[0m10:56:16.681503 [info ] [MainThread]: 
[0m10:56:16.682137 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m10:56:16.683191 [debug] [MainThread]: Command `dbt run` succeeded at 10:56:16.683026 after 2.33 seconds
[0m10:56:16.683986 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10db60fa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f15e5e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f572ca0>]}
[0m10:56:16.684938 [debug] [MainThread]: Flushing usage events
[0m11:00:43.244555 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d70a550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10eaa62b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b29d790>]}


============================== 11:00:43.253677 | 5b58d9ac-455b-48ee-9a40-1abe48fa266a ==============================
[0m11:00:43.253677 [info ] [MainThread]: Running with dbt=1.5.4
[0m11:00:43.255257 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/denisechan/Documents/Makers/Data_Engineering/Week_6/dbt_warehouse', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/Users/denisechan/Documents/Makers/Data_Engineering/Week_6/dbt_warehouse/logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'send_anonymous_usage_stats': 'True'}
[0m11:00:43.429396 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '5b58d9ac-455b-48ee-9a40-1abe48fa266a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10eaa69d0>]}
[0m11:00:43.473617 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '5b58d9ac-455b-48ee-9a40-1abe48fa266a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ed0a6d0>]}
[0m11:00:43.475370 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m11:00:43.524620 [debug] [MainThread]: checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, vars: {}, profile: , target: , version: 1.5.4
[0m11:00:43.696632 [debug] [MainThread]: Partial parsing enabled: 1 files deleted, 1 files added, 0 files changed.
[0m11:00:43.697751 [debug] [MainThread]: Partial parsing: added file: maker_warehouse://models/facts/all_movies.sql
[0m11:00:43.698345 [debug] [MainThread]: Partial parsing: deleted file: maker_warehouse://models/facts/select_movies.sql
[0m11:00:43.764244 [debug] [MainThread]: 1699: static parser successfully parsed facts/all_movies.sql
[0m11:00:43.809358 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5b58d9ac-455b-48ee-9a40-1abe48fa266a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ef930d0>]}
[0m11:00:43.823567 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5b58d9ac-455b-48ee-9a40-1abe48fa266a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ed715e0>]}
[0m11:00:43.824604 [info ] [MainThread]: Found 2 models, 0 tests, 0 snapshots, 0 analyses, 307 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics, 0 groups
[0m11:00:43.825434 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5b58d9ac-455b-48ee-9a40-1abe48fa266a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ed71550>]}
[0m11:00:43.828355 [info ] [MainThread]: 
[0m11:00:43.830153 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m11:00:43.832717 [debug] [ThreadPool]: Acquiring new postgres connection 'list_mydb'
[0m11:00:43.858471 [debug] [ThreadPool]: Using postgres connection "list_mydb"
[0m11:00:43.860131 [debug] [ThreadPool]: On list_mydb: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "connection_name": "list_mydb"} */

    select distinct nspname from pg_namespace
  
[0m11:00:43.861143 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:00:44.047038 [debug] [ThreadPool]: SQL status: SELECT 5 in 0.0 seconds
[0m11:00:44.050787 [debug] [ThreadPool]: On list_mydb: Close
[0m11:00:44.054413 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_mydb, now list_mydb_dbt_warehouse)
[0m11:00:44.070251 [debug] [ThreadPool]: Using postgres connection "list_mydb_dbt_warehouse"
[0m11:00:44.070989 [debug] [ThreadPool]: On list_mydb_dbt_warehouse: BEGIN
[0m11:00:44.071536 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:00:44.105535 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m11:00:44.106632 [debug] [ThreadPool]: Using postgres connection "list_mydb_dbt_warehouse"
[0m11:00:44.107563 [debug] [ThreadPool]: On list_mydb_dbt_warehouse: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "connection_name": "list_mydb_dbt_warehouse"} */
select
      'mydb' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_warehouse'
    union all
    select
      'mydb' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_warehouse'
  
[0m11:00:44.124744 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.0 seconds
[0m11:00:44.128536 [debug] [ThreadPool]: On list_mydb_dbt_warehouse: ROLLBACK
[0m11:00:44.131226 [debug] [ThreadPool]: On list_mydb_dbt_warehouse: Close
[0m11:00:44.146695 [debug] [MainThread]: Using postgres connection "master"
[0m11:00:44.147458 [debug] [MainThread]: On master: BEGIN
[0m11:00:44.148155 [debug] [MainThread]: Opening a new connection, currently in state init
[0m11:00:44.181824 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m11:00:44.182821 [debug] [MainThread]: Using postgres connection "master"
[0m11:00:44.183931 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m11:00:44.213236 [debug] [MainThread]: SQL status: SELECT 5 in 0.0 seconds
[0m11:00:44.215581 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5b58d9ac-455b-48ee-9a40-1abe48fa266a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10efa3fd0>]}
[0m11:00:44.216803 [debug] [MainThread]: On master: ROLLBACK
[0m11:00:44.219334 [debug] [MainThread]: Using postgres connection "master"
[0m11:00:44.220358 [debug] [MainThread]: On master: BEGIN
[0m11:00:44.225644 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m11:00:44.226550 [debug] [MainThread]: On master: COMMIT
[0m11:00:44.227695 [debug] [MainThread]: Using postgres connection "master"
[0m11:00:44.228432 [debug] [MainThread]: On master: COMMIT
[0m11:00:44.230997 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m11:00:44.232066 [debug] [MainThread]: On master: Close
[0m11:00:44.233887 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m11:00:44.235270 [info ] [MainThread]: 
[0m11:00:44.248410 [debug] [Thread-1  ]: Began running node model.maker_warehouse.movies
[0m11:00:44.249520 [info ] [Thread-1  ]: 1 of 2 START sql table model dbt_warehouse.movies .............................. [RUN]
[0m11:00:44.251454 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_mydb_dbt_warehouse, now model.maker_warehouse.movies)
[0m11:00:44.252461 [debug] [Thread-1  ]: Began compiling node model.maker_warehouse.movies
[0m11:00:44.277433 [debug] [Thread-1  ]: Writing injected SQL for node "model.maker_warehouse.movies"
[0m11:00:44.278923 [debug] [Thread-1  ]: Timing info for model.maker_warehouse.movies (compile): 11:00:44.253196 => 11:00:44.278421
[0m11:00:44.279625 [debug] [Thread-1  ]: Began executing node model.maker_warehouse.movies
[0m11:00:44.373575 [debug] [Thread-1  ]: Writing runtime sql for node "model.maker_warehouse.movies"
[0m11:00:44.375447 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.movies"
[0m11:00:44.376668 [debug] [Thread-1  ]: On model.maker_warehouse.movies: BEGIN
[0m11:00:44.377470 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m11:00:44.412480 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
[0m11:00:44.413398 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.movies"
[0m11:00:44.414261 [debug] [Thread-1  ]: On model.maker_warehouse.movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.movies"} */

  
    

  create  table "mydb"."dbt_warehouse"."movies__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    DISTINCT
    title,
    genres,
    release_date,
    movie_id
FROM mydb.public.raw_netflix
  );
  
[0m11:00:45.413524 [debug] [Thread-1  ]: SQL status: SELECT 8472 in 1.0 seconds
[0m11:00:45.441372 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.movies"
[0m11:00:45.442382 [debug] [Thread-1  ]: On model.maker_warehouse.movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.movies"} */
alter table "mydb"."dbt_warehouse"."movies" rename to "movies__dbt_backup"
[0m11:00:45.447575 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:00:45.454146 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.movies"
[0m11:00:45.454850 [debug] [Thread-1  ]: On model.maker_warehouse.movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.movies"} */
alter table "mydb"."dbt_warehouse"."movies__dbt_tmp" rename to "movies"
[0m11:00:45.458267 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:00:45.505012 [debug] [Thread-1  ]: On model.maker_warehouse.movies: COMMIT
[0m11:00:45.505735 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.movies"
[0m11:00:45.506366 [debug] [Thread-1  ]: On model.maker_warehouse.movies: COMMIT
[0m11:00:45.515145 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
[0m11:00:45.527507 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.movies"
[0m11:00:45.528257 [debug] [Thread-1  ]: On model.maker_warehouse.movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.movies"} */
drop table if exists "mydb"."dbt_warehouse"."movies__dbt_backup" cascade
[0m11:00:45.541467 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
[0m11:00:45.545067 [debug] [Thread-1  ]: Timing info for model.maker_warehouse.movies (execute): 11:00:44.280204 => 11:00:45.544585
[0m11:00:45.545923 [debug] [Thread-1  ]: On model.maker_warehouse.movies: Close
[0m11:00:45.547786 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5b58d9ac-455b-48ee-9a40-1abe48fa266a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f066ee0>]}
[0m11:00:45.549786 [info ] [Thread-1  ]: 1 of 2 OK created sql table model dbt_warehouse.movies ......................... [[32mSELECT 8472[0m in 1.30s]
[0m11:00:45.552512 [debug] [Thread-1  ]: Finished running node model.maker_warehouse.movies
[0m11:00:45.554629 [debug] [Thread-3  ]: Began running node model.maker_warehouse.all_movies
[0m11:00:45.555714 [info ] [Thread-3  ]: 2 of 2 START sql table model dbt_warehouse.all_movies .......................... [RUN]
[0m11:00:45.558762 [debug] [Thread-3  ]: Acquiring new postgres connection 'model.maker_warehouse.all_movies'
[0m11:00:45.559890 [debug] [Thread-3  ]: Began compiling node model.maker_warehouse.all_movies
[0m11:00:45.571807 [debug] [Thread-3  ]: Writing injected SQL for node "model.maker_warehouse.all_movies"
[0m11:00:45.573698 [debug] [Thread-3  ]: Timing info for model.maker_warehouse.all_movies (compile): 11:00:45.561012 => 11:00:45.573078
[0m11:00:45.574752 [debug] [Thread-3  ]: Began executing node model.maker_warehouse.all_movies
[0m11:00:45.587447 [debug] [Thread-3  ]: Writing runtime sql for node "model.maker_warehouse.all_movies"
[0m11:00:45.588683 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.all_movies"
[0m11:00:45.589741 [debug] [Thread-3  ]: On model.maker_warehouse.all_movies: BEGIN
[0m11:00:45.590710 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m11:00:45.628696 [debug] [Thread-3  ]: SQL status: BEGIN in 0.0 seconds
[0m11:00:45.629587 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.all_movies"
[0m11:00:45.630352 [debug] [Thread-3  ]: On model.maker_warehouse.all_movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.all_movies"} */

  
    

  create  table "mydb"."dbt_warehouse"."all_movies__dbt_tmp"
  
  
    as
  
  (
    
  
SELECT
*
FROM "mydb"."dbt_warehouse"."movies"
  );
  
[0m11:00:45.667271 [debug] [Thread-3  ]: SQL status: SELECT 8472 in 0.0 seconds
[0m11:00:45.674306 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.all_movies"
[0m11:00:45.675235 [debug] [Thread-3  ]: On model.maker_warehouse.all_movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.all_movies"} */
alter table "mydb"."dbt_warehouse"."all_movies__dbt_tmp" rename to "all_movies"
[0m11:00:45.678755 [debug] [Thread-3  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:00:45.685736 [debug] [Thread-3  ]: On model.maker_warehouse.all_movies: COMMIT
[0m11:00:45.686800 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.all_movies"
[0m11:00:45.687505 [debug] [Thread-3  ]: On model.maker_warehouse.all_movies: COMMIT
[0m11:00:45.697720 [debug] [Thread-3  ]: SQL status: COMMIT in 0.0 seconds
[0m11:00:45.705033 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.all_movies"
[0m11:00:45.705946 [debug] [Thread-3  ]: On model.maker_warehouse.all_movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.all_movies"} */
drop table if exists "mydb"."dbt_warehouse"."all_movies__dbt_backup" cascade
[0m11:00:45.708920 [debug] [Thread-3  ]: SQL status: DROP TABLE in 0.0 seconds
[0m11:00:45.713200 [debug] [Thread-3  ]: Timing info for model.maker_warehouse.all_movies (execute): 11:00:45.575524 => 11:00:45.712559
[0m11:00:45.714325 [debug] [Thread-3  ]: On model.maker_warehouse.all_movies: Close
[0m11:00:45.716600 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5b58d9ac-455b-48ee-9a40-1abe48fa266a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10efe6ac0>]}
[0m11:00:45.718562 [info ] [Thread-3  ]: 2 of 2 OK created sql table model dbt_warehouse.all_movies ..................... [[32mSELECT 8472[0m in 0.16s]
[0m11:00:45.721053 [debug] [Thread-3  ]: Finished running node model.maker_warehouse.all_movies
[0m11:00:45.724421 [debug] [MainThread]: Using postgres connection "master"
[0m11:00:45.725100 [debug] [MainThread]: On master: BEGIN
[0m11:00:45.725601 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m11:00:45.797580 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m11:00:45.798469 [debug] [MainThread]: On master: COMMIT
[0m11:00:45.799249 [debug] [MainThread]: Using postgres connection "master"
[0m11:00:45.800012 [debug] [MainThread]: On master: COMMIT
[0m11:00:45.804074 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m11:00:45.805016 [debug] [MainThread]: On master: Close
[0m11:00:45.806027 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:00:45.806502 [debug] [MainThread]: Connection 'model.maker_warehouse.movies' was properly closed.
[0m11:00:45.806933 [debug] [MainThread]: Connection 'model.maker_warehouse.all_movies' was properly closed.
[0m11:00:45.807577 [info ] [MainThread]: 
[0m11:00:45.808394 [info ] [MainThread]: Finished running 2 table models in 0 hours 0 minutes and 1.98 seconds (1.98s).
[0m11:00:45.811000 [debug] [MainThread]: Command end result
[0m11:00:45.827943 [info ] [MainThread]: 
[0m11:00:45.829060 [info ] [MainThread]: [32mCompleted successfully[0m
[0m11:00:45.830404 [info ] [MainThread]: 
[0m11:00:45.831434 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m11:00:45.833408 [debug] [MainThread]: Command `dbt run` succeeded at 11:00:45.833012 after 2.64 seconds
[0m11:00:45.835304 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d70a550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ed0a6d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f11a1c0>]}
[0m11:00:45.836675 [debug] [MainThread]: Flushing usage events
[0m11:33:11.767173 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106d41550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1080dc2b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1048d4790>]}


============================== 11:33:11.778110 | 01acf569-cb2c-48d8-9cb6-bfe60a57f5f8 ==============================
[0m11:33:11.778110 [info ] [MainThread]: Running with dbt=1.5.4
[0m11:33:11.785480 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/Users/denisechan/Documents/Makers/Data_Engineering/Week_6/dbt_warehouse/logs', 'profiles_dir': '/Users/denisechan/Documents/Makers/Data_Engineering/Week_6/dbt_warehouse', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'send_anonymous_usage_stats': 'True'}
[0m11:33:12.097503 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '01acf569-cb2c-48d8-9cb6-bfe60a57f5f8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1080dc9d0>]}
[0m11:33:12.172832 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '01acf569-cb2c-48d8-9cb6-bfe60a57f5f8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1083406d0>]}
[0m11:33:12.175317 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m11:33:12.250919 [debug] [MainThread]: checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, vars: {}, profile: , target: , version: 1.5.4
[0m11:33:12.472300 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
[0m11:33:12.473579 [debug] [MainThread]: Partial parsing: added file: maker_warehouse://models/facts/no_of_viewings.sql
[0m11:33:12.593080 [debug] [MainThread]: 1699: static parser successfully parsed facts/no_of_viewings.sql
[0m11:33:12.685760 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '01acf569-cb2c-48d8-9cb6-bfe60a57f5f8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1085cb0d0>]}
[0m11:33:12.704327 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '01acf569-cb2c-48d8-9cb6-bfe60a57f5f8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108542cd0>]}
[0m11:33:12.705591 [info ] [MainThread]: Found 3 models, 0 tests, 0 snapshots, 0 analyses, 307 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics, 0 groups
[0m11:33:12.706708 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '01acf569-cb2c-48d8-9cb6-bfe60a57f5f8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108542c70>]}
[0m11:33:12.709919 [info ] [MainThread]: 
[0m11:33:12.711861 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m11:33:12.714492 [debug] [ThreadPool]: Acquiring new postgres connection 'list_mydb'
[0m11:33:12.747227 [debug] [ThreadPool]: Using postgres connection "list_mydb"
[0m11:33:12.748498 [debug] [ThreadPool]: On list_mydb: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "connection_name": "list_mydb"} */

    select distinct nspname from pg_namespace
  
[0m11:33:12.749654 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:33:13.014728 [debug] [ThreadPool]: SQL status: SELECT 5 in 0.0 seconds
[0m11:33:13.019803 [debug] [ThreadPool]: On list_mydb: Close
[0m11:33:13.025549 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_mydb, now list_mydb_dbt_warehouse)
[0m11:33:13.043914 [debug] [ThreadPool]: Using postgres connection "list_mydb_dbt_warehouse"
[0m11:33:13.044826 [debug] [ThreadPool]: On list_mydb_dbt_warehouse: BEGIN
[0m11:33:13.045584 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:33:13.084738 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m11:33:13.085752 [debug] [ThreadPool]: Using postgres connection "list_mydb_dbt_warehouse"
[0m11:33:13.086668 [debug] [ThreadPool]: On list_mydb_dbt_warehouse: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "connection_name": "list_mydb_dbt_warehouse"} */
select
      'mydb' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_warehouse'
    union all
    select
      'mydb' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_warehouse'
  
[0m11:33:13.108475 [debug] [ThreadPool]: SQL status: SELECT 3 in 0.0 seconds
[0m11:33:13.112128 [debug] [ThreadPool]: On list_mydb_dbt_warehouse: ROLLBACK
[0m11:33:13.114434 [debug] [ThreadPool]: On list_mydb_dbt_warehouse: Close
[0m11:33:13.130466 [debug] [MainThread]: Using postgres connection "master"
[0m11:33:13.131379 [debug] [MainThread]: On master: BEGIN
[0m11:33:13.132395 [debug] [MainThread]: Opening a new connection, currently in state init
[0m11:33:13.169591 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m11:33:13.170640 [debug] [MainThread]: Using postgres connection "master"
[0m11:33:13.171694 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m11:33:13.209953 [debug] [MainThread]: SQL status: SELECT 5 in 0.0 seconds
[0m11:33:13.213654 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '01acf569-cb2c-48d8-9cb6-bfe60a57f5f8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1085cce50>]}
[0m11:33:13.214777 [debug] [MainThread]: On master: ROLLBACK
[0m11:33:13.218318 [debug] [MainThread]: Using postgres connection "master"
[0m11:33:13.219179 [debug] [MainThread]: On master: BEGIN
[0m11:33:13.224068 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m11:33:13.225275 [debug] [MainThread]: On master: COMMIT
[0m11:33:13.226621 [debug] [MainThread]: Using postgres connection "master"
[0m11:33:13.227449 [debug] [MainThread]: On master: COMMIT
[0m11:33:13.229981 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m11:33:13.230968 [debug] [MainThread]: On master: Close
[0m11:33:13.232974 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m11:33:13.235248 [info ] [MainThread]: 
[0m11:33:13.251444 [debug] [Thread-1  ]: Began running node model.maker_warehouse.movies
[0m11:33:13.252637 [debug] [Thread-2  ]: Began running node model.maker_warehouse.no_of_viewings
[0m11:33:13.253944 [info ] [Thread-1  ]: 1 of 3 START sql table model dbt_warehouse.movies .............................. [RUN]
[0m11:33:13.255736 [info ] [Thread-2  ]: 2 of 3 START sql table model dbt_warehouse.no_of_viewings ...................... [RUN]
[0m11:33:13.257980 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_mydb_dbt_warehouse, now model.maker_warehouse.movies)
[0m11:33:13.260160 [debug] [Thread-2  ]: Acquiring new postgres connection 'model.maker_warehouse.no_of_viewings'
[0m11:33:13.261436 [debug] [Thread-1  ]: Began compiling node model.maker_warehouse.movies
[0m11:33:13.262875 [debug] [Thread-2  ]: Began compiling node model.maker_warehouse.no_of_viewings
[0m11:33:13.294267 [debug] [Thread-2  ]: Writing injected SQL for node "model.maker_warehouse.no_of_viewings"
[0m11:33:13.297502 [debug] [Thread-2  ]: Timing info for model.maker_warehouse.no_of_viewings (compile): 11:33:13.275834 => 11:33:13.295981
[0m11:33:13.307331 [debug] [Thread-2  ]: Began executing node model.maker_warehouse.no_of_viewings
[0m11:33:13.336460 [debug] [Thread-1  ]: Writing injected SQL for node "model.maker_warehouse.movies"
[0m11:33:13.357592 [debug] [Thread-1  ]: Timing info for model.maker_warehouse.movies (compile): 11:33:13.264120 => 11:33:13.356923
[0m11:33:13.358661 [debug] [Thread-1  ]: Began executing node model.maker_warehouse.movies
[0m11:33:13.582389 [debug] [Thread-1  ]: Writing runtime sql for node "model.maker_warehouse.movies"
[0m11:33:13.590693 [debug] [Thread-2  ]: Writing runtime sql for node "model.maker_warehouse.no_of_viewings"
[0m11:33:13.593120 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.movies"
[0m11:33:13.594755 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.no_of_viewings"
[0m11:33:13.595772 [debug] [Thread-1  ]: On model.maker_warehouse.movies: BEGIN
[0m11:33:13.597900 [debug] [Thread-2  ]: On model.maker_warehouse.no_of_viewings: BEGIN
[0m11:33:13.598972 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m11:33:13.600314 [debug] [Thread-2  ]: Opening a new connection, currently in state init
[0m11:33:13.647583 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
[0m11:33:13.649018 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.movies"
[0m11:33:13.650292 [debug] [Thread-1  ]: On model.maker_warehouse.movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.movies"} */

  
    

  create  table "mydb"."dbt_warehouse"."movies__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    DISTINCT
    title,
    genres,
    release_date,
    movie_id
FROM mydb.public.raw_netflix
  );
  
[0m11:33:13.667948 [debug] [Thread-2  ]: SQL status: BEGIN in 0.0 seconds
[0m11:33:13.669575 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.no_of_viewings"
[0m11:33:13.670649 [debug] [Thread-2  ]: On model.maker_warehouse.no_of_viewings: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.no_of_viewings"} */

  
    

  create  table "mydb"."dbt_warehouse"."no_of_viewings__dbt_tmp"
  
  
    as
  
  (
    
SELECT
title
COUNT(*) as total_views
GROUP BY title
ORDER BY total_views DESC
FROM mydb.public.raw_netflix
  );
  
[0m11:33:13.673946 [debug] [Thread-2  ]: Postgres adapter: Postgres error: syntax error at or near "("
LINE 15: COUNT(*) as total_views
              ^

[0m11:33:13.676606 [debug] [Thread-2  ]: On model.maker_warehouse.no_of_viewings: ROLLBACK
[0m11:33:13.680232 [debug] [Thread-2  ]: Timing info for model.maker_warehouse.no_of_viewings (execute): 11:33:13.308127 => 11:33:13.679557
[0m11:33:13.681926 [debug] [Thread-2  ]: On model.maker_warehouse.no_of_viewings: Close
[0m11:33:13.699841 [debug] [Thread-2  ]: Database Error in model no_of_viewings (models/facts/no_of_viewings.sql)
  syntax error at or near "("
  LINE 15: COUNT(*) as total_views
                ^
  compiled Code at target/run/maker_warehouse/models/facts/no_of_viewings.sql
[0m11:33:13.701086 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '01acf569-cb2c-48d8-9cb6-bfe60a57f5f8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1086cd730>]}
[0m11:33:13.702749 [error] [Thread-2  ]: 2 of 3 ERROR creating sql table model dbt_warehouse.no_of_viewings ............. [[31mERROR[0m in 0.44s]
[0m11:33:13.704846 [debug] [Thread-2  ]: Finished running node model.maker_warehouse.no_of_viewings
[0m11:33:15.515486 [debug] [Thread-1  ]: SQL status: SELECT 8472 in 2.0 seconds
[0m11:33:15.534849 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.movies"
[0m11:33:15.536230 [debug] [Thread-1  ]: On model.maker_warehouse.movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.movies"} */
alter table "mydb"."dbt_warehouse"."movies" rename to "movies__dbt_backup"
[0m11:33:15.542128 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:33:15.553555 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.movies"
[0m11:33:15.554625 [debug] [Thread-1  ]: On model.maker_warehouse.movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.movies"} */
alter table "mydb"."dbt_warehouse"."movies__dbt_tmp" rename to "movies"
[0m11:33:15.558362 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:33:15.620718 [debug] [Thread-1  ]: On model.maker_warehouse.movies: COMMIT
[0m11:33:15.621771 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.movies"
[0m11:33:15.622702 [debug] [Thread-1  ]: On model.maker_warehouse.movies: COMMIT
[0m11:33:15.632386 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
[0m11:33:15.646788 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.movies"
[0m11:33:15.647846 [debug] [Thread-1  ]: On model.maker_warehouse.movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.movies"} */
drop table if exists "mydb"."dbt_warehouse"."movies__dbt_backup" cascade
[0m11:33:15.665959 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
[0m11:33:15.670106 [debug] [Thread-1  ]: Timing info for model.maker_warehouse.movies (execute): 11:33:13.359394 => 11:33:15.669595
[0m11:33:15.671126 [debug] [Thread-1  ]: On model.maker_warehouse.movies: Close
[0m11:33:15.672970 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '01acf569-cb2c-48d8-9cb6-bfe60a57f5f8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10870eb50>]}
[0m11:33:15.674508 [info ] [Thread-1  ]: 1 of 3 OK created sql table model dbt_warehouse.movies ......................... [[32mSELECT 8472[0m in 2.42s]
[0m11:33:15.678140 [debug] [Thread-1  ]: Finished running node model.maker_warehouse.movies
[0m11:33:15.680987 [debug] [Thread-4  ]: Began running node model.maker_warehouse.all_movies
[0m11:33:15.682626 [info ] [Thread-4  ]: 3 of 3 START sql table model dbt_warehouse.all_movies .......................... [RUN]
[0m11:33:15.684984 [debug] [Thread-4  ]: Acquiring new postgres connection 'model.maker_warehouse.all_movies'
[0m11:33:15.686005 [debug] [Thread-4  ]: Began compiling node model.maker_warehouse.all_movies
[0m11:33:15.694190 [debug] [Thread-4  ]: Writing injected SQL for node "model.maker_warehouse.all_movies"
[0m11:33:15.696798 [debug] [Thread-4  ]: Timing info for model.maker_warehouse.all_movies (compile): 11:33:15.686700 => 11:33:15.696117
[0m11:33:15.698112 [debug] [Thread-4  ]: Began executing node model.maker_warehouse.all_movies
[0m11:33:15.714352 [debug] [Thread-4  ]: Writing runtime sql for node "model.maker_warehouse.all_movies"
[0m11:33:15.718442 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.all_movies"
[0m11:33:15.719727 [debug] [Thread-4  ]: On model.maker_warehouse.all_movies: BEGIN
[0m11:33:15.720767 [debug] [Thread-4  ]: Opening a new connection, currently in state init
[0m11:33:15.767519 [debug] [Thread-4  ]: SQL status: BEGIN in 0.0 seconds
[0m11:33:15.769089 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.all_movies"
[0m11:33:15.770139 [debug] [Thread-4  ]: On model.maker_warehouse.all_movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.all_movies"} */

  
    

  create  table "mydb"."dbt_warehouse"."all_movies__dbt_tmp"
  
  
    as
  
  (
    
  
SELECT
*
FROM "mydb"."dbt_warehouse"."movies"
  );
  
[0m11:33:15.819448 [debug] [Thread-4  ]: SQL status: SELECT 8472 in 0.0 seconds
[0m11:33:15.828571 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.all_movies"
[0m11:33:15.829488 [debug] [Thread-4  ]: On model.maker_warehouse.all_movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.all_movies"} */
alter table "mydb"."dbt_warehouse"."all_movies" rename to "all_movies__dbt_backup"
[0m11:33:15.833991 [debug] [Thread-4  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:33:15.843343 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.all_movies"
[0m11:33:15.845340 [debug] [Thread-4  ]: On model.maker_warehouse.all_movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.all_movies"} */
alter table "mydb"."dbt_warehouse"."all_movies__dbt_tmp" rename to "all_movies"
[0m11:33:15.851254 [debug] [Thread-4  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:33:15.856430 [debug] [Thread-4  ]: On model.maker_warehouse.all_movies: COMMIT
[0m11:33:15.857400 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.all_movies"
[0m11:33:15.858213 [debug] [Thread-4  ]: On model.maker_warehouse.all_movies: COMMIT
[0m11:33:15.865608 [debug] [Thread-4  ]: SQL status: COMMIT in 0.0 seconds
[0m11:33:15.871927 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.all_movies"
[0m11:33:15.874797 [debug] [Thread-4  ]: On model.maker_warehouse.all_movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.all_movies"} */
drop table if exists "mydb"."dbt_warehouse"."all_movies__dbt_backup" cascade
[0m11:33:15.889934 [debug] [Thread-4  ]: SQL status: DROP TABLE in 0.0 seconds
[0m11:33:15.894252 [debug] [Thread-4  ]: Timing info for model.maker_warehouse.all_movies (execute): 11:33:15.699066 => 11:33:15.893839
[0m11:33:15.895156 [debug] [Thread-4  ]: On model.maker_warehouse.all_movies: Close
[0m11:33:15.896835 [debug] [Thread-4  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '01acf569-cb2c-48d8-9cb6-bfe60a57f5f8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1087afe20>]}
[0m11:33:15.898809 [info ] [Thread-4  ]: 3 of 3 OK created sql table model dbt_warehouse.all_movies ..................... [[32mSELECT 8472[0m in 0.21s]
[0m11:33:15.901044 [debug] [Thread-4  ]: Finished running node model.maker_warehouse.all_movies
[0m11:33:15.906327 [debug] [MainThread]: Using postgres connection "master"
[0m11:33:15.907333 [debug] [MainThread]: On master: BEGIN
[0m11:33:15.908200 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m11:33:15.948373 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m11:33:15.949339 [debug] [MainThread]: On master: COMMIT
[0m11:33:15.950309 [debug] [MainThread]: Using postgres connection "master"
[0m11:33:15.950938 [debug] [MainThread]: On master: COMMIT
[0m11:33:15.953456 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m11:33:15.954257 [debug] [MainThread]: On master: Close
[0m11:33:15.957370 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:33:15.959190 [debug] [MainThread]: Connection 'model.maker_warehouse.movies' was properly closed.
[0m11:33:15.959878 [debug] [MainThread]: Connection 'model.maker_warehouse.no_of_viewings' was properly closed.
[0m11:33:15.960512 [debug] [MainThread]: Connection 'model.maker_warehouse.all_movies' was properly closed.
[0m11:33:15.961470 [info ] [MainThread]: 
[0m11:33:15.962769 [info ] [MainThread]: Finished running 3 table models in 0 hours 0 minutes and 3.25 seconds (3.25s).
[0m11:33:15.966083 [debug] [MainThread]: Command end result
[0m11:33:15.988744 [info ] [MainThread]: 
[0m11:33:15.989933 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m11:33:15.991186 [info ] [MainThread]: 
[0m11:33:15.992207 [error] [MainThread]: [33mDatabase Error in model no_of_viewings (models/facts/no_of_viewings.sql)[0m
[0m11:33:15.994083 [error] [MainThread]:   syntax error at or near "("
[0m11:33:15.995129 [error] [MainThread]:   LINE 15: COUNT(*) as total_views
[0m11:33:15.996092 [error] [MainThread]:                 ^
[0m11:33:15.997480 [error] [MainThread]:   compiled Code at target/run/maker_warehouse/models/facts/no_of_viewings.sql
[0m11:33:15.998831 [info ] [MainThread]: 
[0m11:33:16.000607 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=1 SKIP=0 TOTAL=3
[0m11:33:16.007167 [debug] [MainThread]: Command `dbt run` failed at 11:33:16.005877 after 4.32 seconds
[0m11:33:16.009897 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106d41550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108573640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1083a41f0>]}
[0m11:33:16.011103 [debug] [MainThread]: Flushing usage events
[0m11:35:28.618766 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1102b27f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11164e2b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10de45a00>]}


============================== 11:35:28.626916 | 211f8f93-b800-4fe5-a67f-e63aef059a0c ==============================
[0m11:35:28.626916 [info ] [MainThread]: Running with dbt=1.5.4
[0m11:35:28.628414 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/denisechan/Documents/Makers/Data_Engineering/Week_6/dbt_warehouse', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/Users/denisechan/Documents/Makers/Data_Engineering/Week_6/dbt_warehouse/logs', 'warn_error': 'None', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'send_anonymous_usage_stats': 'True'}
[0m11:35:28.801192 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '211f8f93-b800-4fe5-a67f-e63aef059a0c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11164e9a0>]}
[0m11:35:28.842798 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '211f8f93-b800-4fe5-a67f-e63aef059a0c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1118b26a0>]}
[0m11:35:28.844789 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m11:35:28.947764 [debug] [MainThread]: checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, vars: {}, profile: , target: , version: 1.5.4
[0m11:35:29.104794 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m11:35:29.106531 [debug] [MainThread]: Partial parsing: updated file: maker_warehouse://models/facts/no_of_viewings.sql
[0m11:35:29.159731 [debug] [MainThread]: 1699: static parser successfully parsed facts/no_of_viewings.sql
[0m11:35:29.198752 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '211f8f93-b800-4fe5-a67f-e63aef059a0c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111b3d9a0>]}
[0m11:35:29.211772 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '211f8f93-b800-4fe5-a67f-e63aef059a0c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111a55a30>]}
[0m11:35:29.212643 [info ] [MainThread]: Found 3 models, 0 tests, 0 snapshots, 0 analyses, 307 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics, 0 groups
[0m11:35:29.213403 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '211f8f93-b800-4fe5-a67f-e63aef059a0c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111a559a0>]}
[0m11:35:29.215573 [info ] [MainThread]: 
[0m11:35:29.217163 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m11:35:29.219160 [debug] [ThreadPool]: Acquiring new postgres connection 'list_mydb'
[0m11:35:29.239883 [debug] [ThreadPool]: Using postgres connection "list_mydb"
[0m11:35:29.240845 [debug] [ThreadPool]: On list_mydb: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "connection_name": "list_mydb"} */

    select distinct nspname from pg_namespace
  
[0m11:35:29.241442 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:35:29.433890 [debug] [ThreadPool]: SQL status: SELECT 5 in 0.0 seconds
[0m11:35:29.437360 [debug] [ThreadPool]: On list_mydb: Close
[0m11:35:29.440280 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_mydb, now list_mydb_dbt_warehouse)
[0m11:35:29.455803 [debug] [ThreadPool]: Using postgres connection "list_mydb_dbt_warehouse"
[0m11:35:29.456520 [debug] [ThreadPool]: On list_mydb_dbt_warehouse: BEGIN
[0m11:35:29.457000 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:35:29.491301 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m11:35:29.492374 [debug] [ThreadPool]: Using postgres connection "list_mydb_dbt_warehouse"
[0m11:35:29.493188 [debug] [ThreadPool]: On list_mydb_dbt_warehouse: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "connection_name": "list_mydb_dbt_warehouse"} */
select
      'mydb' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_warehouse'
    union all
    select
      'mydb' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_warehouse'
  
[0m11:35:29.507202 [debug] [ThreadPool]: SQL status: SELECT 3 in 0.0 seconds
[0m11:35:29.509638 [debug] [ThreadPool]: On list_mydb_dbt_warehouse: ROLLBACK
[0m11:35:29.511558 [debug] [ThreadPool]: On list_mydb_dbt_warehouse: Close
[0m11:35:29.530065 [debug] [MainThread]: Using postgres connection "master"
[0m11:35:29.530753 [debug] [MainThread]: On master: BEGIN
[0m11:35:29.531571 [debug] [MainThread]: Opening a new connection, currently in state init
[0m11:35:29.606971 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m11:35:29.608717 [debug] [MainThread]: Using postgres connection "master"
[0m11:35:29.609915 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m11:35:29.653819 [debug] [MainThread]: SQL status: SELECT 5 in 0.0 seconds
[0m11:35:29.656480 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '211f8f93-b800-4fe5-a67f-e63aef059a0c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111bd9f10>]}
[0m11:35:29.657296 [debug] [MainThread]: On master: ROLLBACK
[0m11:35:29.659419 [debug] [MainThread]: Using postgres connection "master"
[0m11:35:29.660705 [debug] [MainThread]: On master: BEGIN
[0m11:35:29.671252 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m11:35:29.672313 [debug] [MainThread]: On master: COMMIT
[0m11:35:29.674071 [debug] [MainThread]: Using postgres connection "master"
[0m11:35:29.674905 [debug] [MainThread]: On master: COMMIT
[0m11:35:29.676792 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m11:35:29.677718 [debug] [MainThread]: On master: Close
[0m11:35:29.679681 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m11:35:29.682508 [info ] [MainThread]: 
[0m11:35:29.703728 [debug] [Thread-1  ]: Began running node model.maker_warehouse.movies
[0m11:35:29.705174 [debug] [Thread-2  ]: Began running node model.maker_warehouse.no_of_viewings
[0m11:35:29.707162 [info ] [Thread-1  ]: 1 of 3 START sql table model dbt_warehouse.movies .............................. [RUN]
[0m11:35:29.709482 [info ] [Thread-2  ]: 2 of 3 START sql table model dbt_warehouse.no_of_viewings ...................... [RUN]
[0m11:35:29.711864 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_mydb_dbt_warehouse, now model.maker_warehouse.movies)
[0m11:35:29.714079 [debug] [Thread-2  ]: Acquiring new postgres connection 'model.maker_warehouse.no_of_viewings'
[0m11:35:29.715495 [debug] [Thread-1  ]: Began compiling node model.maker_warehouse.movies
[0m11:35:29.716480 [debug] [Thread-2  ]: Began compiling node model.maker_warehouse.no_of_viewings
[0m11:35:29.744562 [debug] [Thread-2  ]: Writing injected SQL for node "model.maker_warehouse.no_of_viewings"
[0m11:35:29.759080 [debug] [Thread-1  ]: Writing injected SQL for node "model.maker_warehouse.movies"
[0m11:35:29.761933 [debug] [Thread-2  ]: Timing info for model.maker_warehouse.no_of_viewings (compile): 11:35:29.727549 => 11:35:29.761186
[0m11:35:29.763084 [debug] [Thread-2  ]: Began executing node model.maker_warehouse.no_of_viewings
[0m11:35:29.777529 [debug] [Thread-1  ]: Timing info for model.maker_warehouse.movies (compile): 11:35:29.718526 => 11:35:29.776900
[0m11:35:29.778623 [debug] [Thread-1  ]: Began executing node model.maker_warehouse.movies
[0m11:35:30.185234 [debug] [Thread-1  ]: Writing runtime sql for node "model.maker_warehouse.movies"
[0m11:35:30.199413 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.movies"
[0m11:35:30.201400 [debug] [Thread-2  ]: Writing runtime sql for node "model.maker_warehouse.no_of_viewings"
[0m11:35:30.202303 [debug] [Thread-1  ]: On model.maker_warehouse.movies: BEGIN
[0m11:35:30.203518 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.no_of_viewings"
[0m11:35:30.204181 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m11:35:30.206071 [debug] [Thread-2  ]: On model.maker_warehouse.no_of_viewings: BEGIN
[0m11:35:30.208575 [debug] [Thread-2  ]: Opening a new connection, currently in state init
[0m11:35:30.262546 [debug] [Thread-2  ]: SQL status: BEGIN in 0.0 seconds
[0m11:35:30.270109 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.no_of_viewings"
[0m11:35:30.272254 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
[0m11:35:30.273395 [debug] [Thread-2  ]: On model.maker_warehouse.no_of_viewings: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.no_of_viewings"} */

  
    

  create  table "mydb"."dbt_warehouse"."no_of_viewings__dbt_tmp"
  
  
    as
  
  (
    
SELECT
  title,
  COUNT(*) as total_views
FROM mydb.public.raw_netflix
GROUP BY title
ORDER BY total_views DESC
  );
  
[0m11:35:30.275222 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.movies"
[0m11:35:30.277158 [debug] [Thread-1  ]: On model.maker_warehouse.movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.movies"} */

  
    

  create  table "mydb"."dbt_warehouse"."movies__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    DISTINCT
    title,
    genres,
    release_date,
    movie_id
FROM mydb.public.raw_netflix
  );
  
[0m11:35:30.738490 [debug] [Thread-2  ]: SQL status: SELECT 7925 in 0.0 seconds
[0m11:35:30.753963 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.no_of_viewings"
[0m11:35:30.755135 [debug] [Thread-2  ]: On model.maker_warehouse.no_of_viewings: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.no_of_viewings"} */
alter table "mydb"."dbt_warehouse"."no_of_viewings__dbt_tmp" rename to "no_of_viewings"
[0m11:35:30.759744 [debug] [Thread-2  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:35:30.811938 [debug] [Thread-2  ]: On model.maker_warehouse.no_of_viewings: COMMIT
[0m11:35:30.812762 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.no_of_viewings"
[0m11:35:30.813391 [debug] [Thread-2  ]: On model.maker_warehouse.no_of_viewings: COMMIT
[0m11:35:30.822735 [debug] [Thread-2  ]: SQL status: COMMIT in 0.0 seconds
[0m11:35:30.832683 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.no_of_viewings"
[0m11:35:30.834049 [debug] [Thread-2  ]: On model.maker_warehouse.no_of_viewings: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.no_of_viewings"} */
drop table if exists "mydb"."dbt_warehouse"."no_of_viewings__dbt_backup" cascade
[0m11:35:30.837203 [debug] [Thread-2  ]: SQL status: DROP TABLE in 0.0 seconds
[0m11:35:30.839831 [debug] [Thread-2  ]: Timing info for model.maker_warehouse.no_of_viewings (execute): 11:35:29.763914 => 11:35:30.839432
[0m11:35:30.840723 [debug] [Thread-2  ]: On model.maker_warehouse.no_of_viewings: Close
[0m11:35:30.842662 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '211f8f93-b800-4fe5-a67f-e63aef059a0c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111c4fd90>]}
[0m11:35:30.843852 [info ] [Thread-2  ]: 2 of 3 OK created sql table model dbt_warehouse.no_of_viewings ................. [[32mSELECT 7925[0m in 1.13s]
[0m11:35:30.846407 [debug] [Thread-2  ]: Finished running node model.maker_warehouse.no_of_viewings
[0m11:35:31.430488 [debug] [Thread-1  ]: SQL status: SELECT 8472 in 1.0 seconds
[0m11:35:31.436533 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.movies"
[0m11:35:31.437408 [debug] [Thread-1  ]: On model.maker_warehouse.movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.movies"} */
alter table "mydb"."dbt_warehouse"."movies" rename to "movies__dbt_backup"
[0m11:35:31.440795 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:35:31.447799 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.movies"
[0m11:35:31.448804 [debug] [Thread-1  ]: On model.maker_warehouse.movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.movies"} */
alter table "mydb"."dbt_warehouse"."movies__dbt_tmp" rename to "movies"
[0m11:35:31.452319 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:35:31.460969 [debug] [Thread-1  ]: On model.maker_warehouse.movies: COMMIT
[0m11:35:31.461625 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.movies"
[0m11:35:31.462176 [debug] [Thread-1  ]: On model.maker_warehouse.movies: COMMIT
[0m11:35:31.470943 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
[0m11:35:31.475590 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.movies"
[0m11:35:31.476252 [debug] [Thread-1  ]: On model.maker_warehouse.movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.movies"} */
drop table if exists "mydb"."dbt_warehouse"."movies__dbt_backup" cascade
[0m11:35:31.488103 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
[0m11:35:31.491076 [debug] [Thread-1  ]: Timing info for model.maker_warehouse.movies (execute): 11:35:29.779337 => 11:35:31.490684
[0m11:35:31.491908 [debug] [Thread-1  ]: On model.maker_warehouse.movies: Close
[0m11:35:31.493590 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '211f8f93-b800-4fe5-a67f-e63aef059a0c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111c6cf70>]}
[0m11:35:31.495394 [info ] [Thread-1  ]: 1 of 3 OK created sql table model dbt_warehouse.movies ......................... [[32mSELECT 8472[0m in 1.78s]
[0m11:35:31.497843 [debug] [Thread-1  ]: Finished running node model.maker_warehouse.movies
[0m11:35:31.503100 [debug] [Thread-4  ]: Began running node model.maker_warehouse.all_movies
[0m11:35:31.507987 [info ] [Thread-4  ]: 3 of 3 START sql table model dbt_warehouse.all_movies .......................... [RUN]
[0m11:35:31.510927 [debug] [Thread-4  ]: Acquiring new postgres connection 'model.maker_warehouse.all_movies'
[0m11:35:31.512160 [debug] [Thread-4  ]: Began compiling node model.maker_warehouse.all_movies
[0m11:35:31.519230 [debug] [Thread-4  ]: Writing injected SQL for node "model.maker_warehouse.all_movies"
[0m11:35:31.522811 [debug] [Thread-4  ]: Timing info for model.maker_warehouse.all_movies (compile): 11:35:31.513186 => 11:35:31.521996
[0m11:35:31.523842 [debug] [Thread-4  ]: Began executing node model.maker_warehouse.all_movies
[0m11:35:31.535566 [debug] [Thread-4  ]: Writing runtime sql for node "model.maker_warehouse.all_movies"
[0m11:35:31.536799 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.all_movies"
[0m11:35:31.537388 [debug] [Thread-4  ]: On model.maker_warehouse.all_movies: BEGIN
[0m11:35:31.537915 [debug] [Thread-4  ]: Opening a new connection, currently in state init
[0m11:35:31.577645 [debug] [Thread-4  ]: SQL status: BEGIN in 0.0 seconds
[0m11:35:31.578648 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.all_movies"
[0m11:35:31.579319 [debug] [Thread-4  ]: On model.maker_warehouse.all_movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.all_movies"} */

  
    

  create  table "mydb"."dbt_warehouse"."all_movies__dbt_tmp"
  
  
    as
  
  (
    
  
SELECT
*
FROM "mydb"."dbt_warehouse"."movies"
  );
  
[0m11:35:31.611334 [debug] [Thread-4  ]: SQL status: SELECT 8472 in 0.0 seconds
[0m11:35:31.617460 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.all_movies"
[0m11:35:31.618336 [debug] [Thread-4  ]: On model.maker_warehouse.all_movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.all_movies"} */
alter table "mydb"."dbt_warehouse"."all_movies" rename to "all_movies__dbt_backup"
[0m11:35:31.621542 [debug] [Thread-4  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:35:31.628564 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.all_movies"
[0m11:35:31.629466 [debug] [Thread-4  ]: On model.maker_warehouse.all_movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.all_movies"} */
alter table "mydb"."dbt_warehouse"."all_movies__dbt_tmp" rename to "all_movies"
[0m11:35:31.632319 [debug] [Thread-4  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:35:31.637748 [debug] [Thread-4  ]: On model.maker_warehouse.all_movies: COMMIT
[0m11:35:31.638415 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.all_movies"
[0m11:35:31.638985 [debug] [Thread-4  ]: On model.maker_warehouse.all_movies: COMMIT
[0m11:35:31.645655 [debug] [Thread-4  ]: SQL status: COMMIT in 0.0 seconds
[0m11:35:31.653537 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.all_movies"
[0m11:35:31.654198 [debug] [Thread-4  ]: On model.maker_warehouse.all_movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.all_movies"} */
drop table if exists "mydb"."dbt_warehouse"."all_movies__dbt_backup" cascade
[0m11:35:31.663880 [debug] [Thread-4  ]: SQL status: DROP TABLE in 0.0 seconds
[0m11:35:31.669674 [debug] [Thread-4  ]: Timing info for model.maker_warehouse.all_movies (execute): 11:35:31.524453 => 11:35:31.669192
[0m11:35:31.670363 [debug] [Thread-4  ]: On model.maker_warehouse.all_movies: Close
[0m11:35:31.671701 [debug] [Thread-4  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '211f8f93-b800-4fe5-a67f-e63aef059a0c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111d0cd90>]}
[0m11:35:31.672968 [info ] [Thread-4  ]: 3 of 3 OK created sql table model dbt_warehouse.all_movies ..................... [[32mSELECT 8472[0m in 0.16s]
[0m11:35:31.674844 [debug] [Thread-4  ]: Finished running node model.maker_warehouse.all_movies
[0m11:35:31.678057 [debug] [MainThread]: Using postgres connection "master"
[0m11:35:31.678780 [debug] [MainThread]: On master: BEGIN
[0m11:35:31.679443 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m11:35:31.720330 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m11:35:31.721385 [debug] [MainThread]: On master: COMMIT
[0m11:35:31.722014 [debug] [MainThread]: Using postgres connection "master"
[0m11:35:31.722589 [debug] [MainThread]: On master: COMMIT
[0m11:35:31.727786 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m11:35:31.728862 [debug] [MainThread]: On master: Close
[0m11:35:31.730520 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:35:31.731224 [debug] [MainThread]: Connection 'model.maker_warehouse.movies' was properly closed.
[0m11:35:31.731763 [debug] [MainThread]: Connection 'model.maker_warehouse.no_of_viewings' was properly closed.
[0m11:35:31.732217 [debug] [MainThread]: Connection 'model.maker_warehouse.all_movies' was properly closed.
[0m11:35:31.732778 [info ] [MainThread]: 
[0m11:35:31.734568 [info ] [MainThread]: Finished running 3 table models in 0 hours 0 minutes and 2.52 seconds (2.52s).
[0m11:35:31.738150 [debug] [MainThread]: Command end result
[0m11:35:31.750450 [info ] [MainThread]: 
[0m11:35:31.754849 [info ] [MainThread]: [32mCompleted successfully[0m
[0m11:35:31.756322 [info ] [MainThread]: 
[0m11:35:31.757616 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
[0m11:35:31.759608 [debug] [MainThread]: Command `dbt run` succeeded at 11:35:31.759295 after 3.21 seconds
[0m11:35:31.760711 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1102b27f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111cf13d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111ae66d0>]}
[0m11:35:31.761955 [debug] [MainThread]: Flushing usage events
[0m11:47:47.510181 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c492550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d82e2b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a025790>]}


============================== 11:47:47.519370 | 0534f02c-541c-4ed2-b1c8-7db6130146bd ==============================
[0m11:47:47.519370 [info ] [MainThread]: Running with dbt=1.5.4
[0m11:47:47.527497 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/denisechan/Documents/Makers/Data_Engineering/Week_6/dbt_warehouse', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/Users/denisechan/Documents/Makers/Data_Engineering/Week_6/dbt_warehouse/logs', 'warn_error': 'None', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'send_anonymous_usage_stats': 'True'}
[0m11:47:47.721756 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '0534f02c-541c-4ed2-b1c8-7db6130146bd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d82e9d0>]}
[0m11:47:47.767549 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '0534f02c-541c-4ed2-b1c8-7db6130146bd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10da866d0>]}
[0m11:47:47.769493 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m11:47:47.817687 [debug] [MainThread]: checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, vars: {}, profile: , target: , version: 1.5.4
[0m11:47:47.972744 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
[0m11:47:47.973576 [debug] [MainThread]: Partial parsing: added file: maker_warehouse://models/facts/total_viewing_time.sql
[0m11:47:48.040661 [debug] [MainThread]: 1699: static parser successfully parsed facts/total_viewing_time.sql
[0m11:47:48.079236 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '0534f02c-541c-4ed2-b1c8-7db6130146bd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dd1a0d0>]}
[0m11:47:48.094162 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '0534f02c-541c-4ed2-b1c8-7db6130146bd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dc97e50>]}
[0m11:47:48.094928 [info ] [MainThread]: Found 4 models, 0 tests, 0 snapshots, 0 analyses, 307 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics, 0 groups
[0m11:47:48.095658 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0534f02c-541c-4ed2-b1c8-7db6130146bd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dc97cd0>]}
[0m11:47:48.100518 [info ] [MainThread]: 
[0m11:47:48.102529 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m11:47:48.106211 [debug] [ThreadPool]: Acquiring new postgres connection 'list_mydb'
[0m11:47:48.132744 [debug] [ThreadPool]: Using postgres connection "list_mydb"
[0m11:47:48.133400 [debug] [ThreadPool]: On list_mydb: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "connection_name": "list_mydb"} */

    select distinct nspname from pg_namespace
  
[0m11:47:48.134326 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:47:48.325373 [debug] [ThreadPool]: SQL status: SELECT 5 in 0.0 seconds
[0m11:47:48.329402 [debug] [ThreadPool]: On list_mydb: Close
[0m11:47:48.333277 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_mydb, now list_mydb_dbt_warehouse)
[0m11:47:48.346792 [debug] [ThreadPool]: Using postgres connection "list_mydb_dbt_warehouse"
[0m11:47:48.347402 [debug] [ThreadPool]: On list_mydb_dbt_warehouse: BEGIN
[0m11:47:48.347972 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:47:48.375897 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m11:47:48.377135 [debug] [ThreadPool]: Using postgres connection "list_mydb_dbt_warehouse"
[0m11:47:48.378169 [debug] [ThreadPool]: On list_mydb_dbt_warehouse: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "connection_name": "list_mydb_dbt_warehouse"} */
select
      'mydb' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_warehouse'
    union all
    select
      'mydb' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_warehouse'
  
[0m11:47:48.394160 [debug] [ThreadPool]: SQL status: SELECT 4 in 0.0 seconds
[0m11:47:48.396597 [debug] [ThreadPool]: On list_mydb_dbt_warehouse: ROLLBACK
[0m11:47:48.398693 [debug] [ThreadPool]: On list_mydb_dbt_warehouse: Close
[0m11:47:48.412794 [debug] [MainThread]: Using postgres connection "master"
[0m11:47:48.413552 [debug] [MainThread]: On master: BEGIN
[0m11:47:48.414181 [debug] [MainThread]: Opening a new connection, currently in state init
[0m11:47:48.445566 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m11:47:48.446909 [debug] [MainThread]: Using postgres connection "master"
[0m11:47:48.447767 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m11:47:48.499083 [debug] [MainThread]: SQL status: SELECT 5 in 0.0 seconds
[0m11:47:48.501488 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0534f02c-541c-4ed2-b1c8-7db6130146bd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dc40280>]}
[0m11:47:48.502447 [debug] [MainThread]: On master: ROLLBACK
[0m11:47:48.506045 [debug] [MainThread]: Using postgres connection "master"
[0m11:47:48.507043 [debug] [MainThread]: On master: BEGIN
[0m11:47:48.510374 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m11:47:48.510991 [debug] [MainThread]: On master: COMMIT
[0m11:47:48.511510 [debug] [MainThread]: Using postgres connection "master"
[0m11:47:48.511976 [debug] [MainThread]: On master: COMMIT
[0m11:47:48.513674 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m11:47:48.514411 [debug] [MainThread]: On master: Close
[0m11:47:48.516066 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m11:47:48.517260 [info ] [MainThread]: 
[0m11:47:48.528985 [debug] [Thread-1  ]: Began running node model.maker_warehouse.movies
[0m11:47:48.529657 [debug] [Thread-2  ]: Began running node model.maker_warehouse.no_of_viewings
[0m11:47:48.530284 [debug] [Thread-3  ]: Began running node model.maker_warehouse.total_viewing_time
[0m11:47:48.531114 [info ] [Thread-1  ]: 1 of 4 START sql table model dbt_warehouse.movies .............................. [RUN]
[0m11:47:48.532428 [info ] [Thread-2  ]: 2 of 4 START sql table model dbt_warehouse.no_of_viewings ...................... [RUN]
[0m11:47:48.533736 [info ] [Thread-3  ]: 3 of 4 START sql table model dbt_warehouse.total_viewing_time .................. [RUN]
[0m11:47:48.535338 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_mydb_dbt_warehouse, now model.maker_warehouse.movies)
[0m11:47:48.537307 [debug] [Thread-2  ]: Acquiring new postgres connection 'model.maker_warehouse.no_of_viewings'
[0m11:47:48.539101 [debug] [Thread-3  ]: Acquiring new postgres connection 'model.maker_warehouse.total_viewing_time'
[0m11:47:48.543041 [debug] [Thread-1  ]: Began compiling node model.maker_warehouse.movies
[0m11:47:48.544034 [debug] [Thread-2  ]: Began compiling node model.maker_warehouse.no_of_viewings
[0m11:47:48.545406 [debug] [Thread-3  ]: Began compiling node model.maker_warehouse.total_viewing_time
[0m11:47:48.562349 [debug] [Thread-2  ]: Writing injected SQL for node "model.maker_warehouse.no_of_viewings"
[0m11:47:48.577464 [debug] [Thread-3  ]: Writing injected SQL for node "model.maker_warehouse.total_viewing_time"
[0m11:47:48.610037 [debug] [Thread-1  ]: Writing injected SQL for node "model.maker_warehouse.movies"
[0m11:47:48.613281 [debug] [Thread-3  ]: Timing info for model.maker_warehouse.total_viewing_time (compile): 11:47:48.568866 => 11:47:48.612537
[0m11:47:48.615872 [debug] [Thread-3  ]: Began executing node model.maker_warehouse.total_viewing_time
[0m11:47:48.629740 [debug] [Thread-1  ]: Timing info for model.maker_warehouse.movies (compile): 11:47:48.548889 => 11:47:48.628242
[0m11:47:48.631512 [debug] [Thread-1  ]: Began executing node model.maker_warehouse.movies
[0m11:47:48.657109 [debug] [Thread-2  ]: Timing info for model.maker_warehouse.no_of_viewings (compile): 11:47:48.557206 => 11:47:48.656388
[0m11:47:48.657974 [debug] [Thread-2  ]: Began executing node model.maker_warehouse.no_of_viewings
[0m11:47:48.988175 [debug] [Thread-3  ]: Writing runtime sql for node "model.maker_warehouse.total_viewing_time"
[0m11:47:48.989277 [debug] [Thread-1  ]: Writing runtime sql for node "model.maker_warehouse.movies"
[0m11:47:48.994519 [debug] [Thread-2  ]: Writing runtime sql for node "model.maker_warehouse.no_of_viewings"
[0m11:47:48.996069 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.total_viewing_time"
[0m11:47:48.996702 [debug] [Thread-3  ]: On model.maker_warehouse.total_viewing_time: BEGIN
[0m11:47:48.997381 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m11:47:48.998955 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.movies"
[0m11:47:49.008148 [debug] [Thread-1  ]: On model.maker_warehouse.movies: BEGIN
[0m11:47:49.002677 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.no_of_viewings"
[0m11:47:49.012916 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m11:47:49.014494 [debug] [Thread-2  ]: On model.maker_warehouse.no_of_viewings: BEGIN
[0m11:47:49.016744 [debug] [Thread-2  ]: Opening a new connection, currently in state init
[0m11:47:49.049467 [debug] [Thread-3  ]: SQL status: BEGIN in 0.0 seconds
[0m11:47:49.053256 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.total_viewing_time"
[0m11:47:49.055508 [debug] [Thread-3  ]: On model.maker_warehouse.total_viewing_time: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_viewing_time"} */

  
    

  create  table "mydb"."dbt_warehouse"."total_viewing_time__dbt_tmp"
  
  
    as
  
  (
    
SELECT
title,
SUM(duration) as total_duration
FROM mydb.public.raw_netflix
GROUP BY title
ORDER BY total_duration DESC
  );
  
[0m11:47:49.148437 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
[0m11:47:49.149777 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.movies"
[0m11:47:49.151682 [debug] [Thread-1  ]: On model.maker_warehouse.movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.movies"} */

  
    

  create  table "mydb"."dbt_warehouse"."movies__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    DISTINCT
    title,
    genres,
    release_date,
    movie_id
FROM mydb.public.raw_netflix
  );
  
[0m11:47:49.162855 [debug] [Thread-2  ]: SQL status: BEGIN in 0.0 seconds
[0m11:47:49.164195 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.no_of_viewings"
[0m11:47:49.165864 [debug] [Thread-2  ]: On model.maker_warehouse.no_of_viewings: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.no_of_viewings"} */

  
    

  create  table "mydb"."dbt_warehouse"."no_of_viewings__dbt_tmp"
  
  
    as
  
  (
    
SELECT
  title,
  COUNT(*) as total_views
FROM mydb.public.raw_netflix
GROUP BY title
ORDER BY total_views DESC
  );
  
[0m11:47:49.993200 [debug] [Thread-2  ]: SQL status: SELECT 7925 in 1.0 seconds
[0m11:47:50.019721 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.no_of_viewings"
[0m11:47:50.021390 [debug] [Thread-2  ]: On model.maker_warehouse.no_of_viewings: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.no_of_viewings"} */
alter table "mydb"."dbt_warehouse"."no_of_viewings" rename to "no_of_viewings__dbt_backup"
[0m11:47:50.040516 [debug] [Thread-2  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:47:50.049289 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.no_of_viewings"
[0m11:47:50.050598 [debug] [Thread-2  ]: On model.maker_warehouse.no_of_viewings: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.no_of_viewings"} */
alter table "mydb"."dbt_warehouse"."no_of_viewings__dbt_tmp" rename to "no_of_viewings"
[0m11:47:50.057845 [debug] [Thread-2  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:47:50.079743 [debug] [Thread-3  ]: SQL status: SELECT 7925 in 1.0 seconds
[0m11:47:50.101814 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.total_viewing_time"
[0m11:47:50.103322 [debug] [Thread-3  ]: On model.maker_warehouse.total_viewing_time: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_viewing_time"} */
alter table "mydb"."dbt_warehouse"."total_viewing_time__dbt_tmp" rename to "total_viewing_time"
[0m11:47:50.163061 [debug] [Thread-3  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:47:50.183655 [debug] [Thread-2  ]: On model.maker_warehouse.no_of_viewings: COMMIT
[0m11:47:50.194448 [debug] [Thread-3  ]: On model.maker_warehouse.total_viewing_time: COMMIT
[0m11:47:50.195466 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.no_of_viewings"
[0m11:47:50.196478 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.total_viewing_time"
[0m11:47:50.197611 [debug] [Thread-2  ]: On model.maker_warehouse.no_of_viewings: COMMIT
[0m11:47:50.198709 [debug] [Thread-3  ]: On model.maker_warehouse.total_viewing_time: COMMIT
[0m11:47:50.205199 [debug] [Thread-2  ]: SQL status: COMMIT in 0.0 seconds
[0m11:47:50.206877 [debug] [Thread-3  ]: SQL status: COMMIT in 0.0 seconds
[0m11:47:50.234553 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.no_of_viewings"
[0m11:47:50.231218 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.total_viewing_time"
[0m11:47:50.237239 [debug] [Thread-2  ]: On model.maker_warehouse.no_of_viewings: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.no_of_viewings"} */
drop table if exists "mydb"."dbt_warehouse"."no_of_viewings__dbt_backup" cascade
[0m11:47:50.238124 [debug] [Thread-3  ]: On model.maker_warehouse.total_viewing_time: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_viewing_time"} */
drop table if exists "mydb"."dbt_warehouse"."total_viewing_time__dbt_backup" cascade
[0m11:47:50.241566 [debug] [Thread-3  ]: SQL status: DROP TABLE in 0.0 seconds
[0m11:47:50.245805 [debug] [Thread-3  ]: Timing info for model.maker_warehouse.total_viewing_time (execute): 11:47:48.616729 => 11:47:50.245125
[0m11:47:50.247273 [debug] [Thread-3  ]: On model.maker_warehouse.total_viewing_time: Close
[0m11:47:50.249217 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0534f02c-541c-4ed2-b1c8-7db6130146bd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10de5ebb0>]}
[0m11:47:50.250946 [info ] [Thread-3  ]: 3 of 4 OK created sql table model dbt_warehouse.total_viewing_time ............. [[32mSELECT 7925[0m in 1.71s]
[0m11:47:50.253723 [debug] [Thread-3  ]: Finished running node model.maker_warehouse.total_viewing_time
[0m11:47:50.255613 [debug] [Thread-2  ]: SQL status: DROP TABLE in 0.0 seconds
[0m11:47:50.258873 [debug] [Thread-2  ]: Timing info for model.maker_warehouse.no_of_viewings (execute): 11:47:48.658676 => 11:47:50.258539
[0m11:47:50.259651 [debug] [Thread-2  ]: On model.maker_warehouse.no_of_viewings: Close
[0m11:47:50.261857 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0534f02c-541c-4ed2-b1c8-7db6130146bd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10de96ee0>]}
[0m11:47:50.263479 [info ] [Thread-2  ]: 2 of 4 OK created sql table model dbt_warehouse.no_of_viewings ................. [[32mSELECT 7925[0m in 1.73s]
[0m11:47:50.266391 [debug] [Thread-2  ]: Finished running node model.maker_warehouse.no_of_viewings
[0m11:47:50.815787 [debug] [Thread-1  ]: SQL status: SELECT 8472 in 2.0 seconds
[0m11:47:50.821911 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.movies"
[0m11:47:50.822593 [debug] [Thread-1  ]: On model.maker_warehouse.movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.movies"} */
alter table "mydb"."dbt_warehouse"."movies" rename to "movies__dbt_backup"
[0m11:47:50.826620 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:47:50.834719 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.movies"
[0m11:47:50.835709 [debug] [Thread-1  ]: On model.maker_warehouse.movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.movies"} */
alter table "mydb"."dbt_warehouse"."movies__dbt_tmp" rename to "movies"
[0m11:47:50.839021 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:47:50.843060 [debug] [Thread-1  ]: On model.maker_warehouse.movies: COMMIT
[0m11:47:50.843840 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.movies"
[0m11:47:50.845028 [debug] [Thread-1  ]: On model.maker_warehouse.movies: COMMIT
[0m11:47:50.851367 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
[0m11:47:50.857254 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.movies"
[0m11:47:50.857984 [debug] [Thread-1  ]: On model.maker_warehouse.movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.movies"} */
drop table if exists "mydb"."dbt_warehouse"."movies__dbt_backup" cascade
[0m11:47:50.872272 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
[0m11:47:50.875205 [debug] [Thread-1  ]: Timing info for model.maker_warehouse.movies (execute): 11:47:48.632034 => 11:47:50.874863
[0m11:47:50.875841 [debug] [Thread-1  ]: On model.maker_warehouse.movies: Close
[0m11:47:50.877177 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0534f02c-541c-4ed2-b1c8-7db6130146bd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10def6100>]}
[0m11:47:50.878495 [info ] [Thread-1  ]: 1 of 4 OK created sql table model dbt_warehouse.movies ......................... [[32mSELECT 8472[0m in 2.34s]
[0m11:47:50.880655 [debug] [Thread-1  ]: Finished running node model.maker_warehouse.movies
[0m11:47:50.882410 [debug] [Thread-4  ]: Began running node model.maker_warehouse.all_movies
[0m11:47:50.883621 [info ] [Thread-4  ]: 4 of 4 START sql table model dbt_warehouse.all_movies .......................... [RUN]
[0m11:47:50.886560 [debug] [Thread-4  ]: Acquiring new postgres connection 'model.maker_warehouse.all_movies'
[0m11:47:50.887886 [debug] [Thread-4  ]: Began compiling node model.maker_warehouse.all_movies
[0m11:47:50.894042 [debug] [Thread-4  ]: Writing injected SQL for node "model.maker_warehouse.all_movies"
[0m11:47:50.896208 [debug] [Thread-4  ]: Timing info for model.maker_warehouse.all_movies (compile): 11:47:50.888874 => 11:47:50.895710
[0m11:47:50.897200 [debug] [Thread-4  ]: Began executing node model.maker_warehouse.all_movies
[0m11:47:50.910732 [debug] [Thread-4  ]: Writing runtime sql for node "model.maker_warehouse.all_movies"
[0m11:47:50.912985 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.all_movies"
[0m11:47:50.913892 [debug] [Thread-4  ]: On model.maker_warehouse.all_movies: BEGIN
[0m11:47:50.914697 [debug] [Thread-4  ]: Opening a new connection, currently in state init
[0m11:47:50.952976 [debug] [Thread-4  ]: SQL status: BEGIN in 0.0 seconds
[0m11:47:50.955173 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.all_movies"
[0m11:47:50.956389 [debug] [Thread-4  ]: On model.maker_warehouse.all_movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.all_movies"} */

  
    

  create  table "mydb"."dbt_warehouse"."all_movies__dbt_tmp"
  
  
    as
  
  (
    
  
SELECT
*
FROM "mydb"."dbt_warehouse"."movies"
  );
  
[0m11:47:50.985557 [debug] [Thread-4  ]: SQL status: SELECT 8472 in 0.0 seconds
[0m11:47:50.991995 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.all_movies"
[0m11:47:50.992654 [debug] [Thread-4  ]: On model.maker_warehouse.all_movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.all_movies"} */
alter table "mydb"."dbt_warehouse"."all_movies" rename to "all_movies__dbt_backup"
[0m11:47:50.995658 [debug] [Thread-4  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:47:51.002398 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.all_movies"
[0m11:47:51.003571 [debug] [Thread-4  ]: On model.maker_warehouse.all_movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.all_movies"} */
alter table "mydb"."dbt_warehouse"."all_movies__dbt_tmp" rename to "all_movies"
[0m11:47:51.008934 [debug] [Thread-4  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:47:51.014531 [debug] [Thread-4  ]: On model.maker_warehouse.all_movies: COMMIT
[0m11:47:51.015247 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.all_movies"
[0m11:47:51.016157 [debug] [Thread-4  ]: On model.maker_warehouse.all_movies: COMMIT
[0m11:47:51.025016 [debug] [Thread-4  ]: SQL status: COMMIT in 0.0 seconds
[0m11:47:51.030381 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.all_movies"
[0m11:47:51.031084 [debug] [Thread-4  ]: On model.maker_warehouse.all_movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.all_movies"} */
drop table if exists "mydb"."dbt_warehouse"."all_movies__dbt_backup" cascade
[0m11:47:51.042007 [debug] [Thread-4  ]: SQL status: DROP TABLE in 0.0 seconds
[0m11:47:51.045071 [debug] [Thread-4  ]: Timing info for model.maker_warehouse.all_movies (execute): 11:47:50.897781 => 11:47:51.044361
[0m11:47:51.046154 [debug] [Thread-4  ]: On model.maker_warehouse.all_movies: Close
[0m11:47:51.047812 [debug] [Thread-4  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0534f02c-541c-4ed2-b1c8-7db6130146bd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10de79430>]}
[0m11:47:51.049261 [info ] [Thread-4  ]: 4 of 4 OK created sql table model dbt_warehouse.all_movies ..................... [[32mSELECT 8472[0m in 0.16s]
[0m11:47:51.050637 [debug] [Thread-4  ]: Finished running node model.maker_warehouse.all_movies
[0m11:47:51.054840 [debug] [MainThread]: Using postgres connection "master"
[0m11:47:51.055444 [debug] [MainThread]: On master: BEGIN
[0m11:47:51.055987 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m11:47:51.091573 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m11:47:51.092395 [debug] [MainThread]: On master: COMMIT
[0m11:47:51.093088 [debug] [MainThread]: Using postgres connection "master"
[0m11:47:51.093718 [debug] [MainThread]: On master: COMMIT
[0m11:47:51.095446 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m11:47:51.096055 [debug] [MainThread]: On master: Close
[0m11:47:51.097487 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:47:51.098199 [debug] [MainThread]: Connection 'model.maker_warehouse.movies' was properly closed.
[0m11:47:51.098803 [debug] [MainThread]: Connection 'model.maker_warehouse.no_of_viewings' was properly closed.
[0m11:47:51.099681 [debug] [MainThread]: Connection 'model.maker_warehouse.total_viewing_time' was properly closed.
[0m11:47:51.100356 [debug] [MainThread]: Connection 'model.maker_warehouse.all_movies' was properly closed.
[0m11:47:51.101346 [info ] [MainThread]: 
[0m11:47:51.102715 [info ] [MainThread]: Finished running 4 table models in 0 hours 0 minutes and 3.00 seconds (3.00s).
[0m11:47:51.106667 [debug] [MainThread]: Command end result
[0m11:47:51.122283 [info ] [MainThread]: 
[0m11:47:51.123261 [info ] [MainThread]: [32mCompleted successfully[0m
[0m11:47:51.125056 [info ] [MainThread]: 
[0m11:47:51.126327 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m11:47:51.128320 [debug] [MainThread]: Command `dbt run` succeeded at 11:47:51.128105 after 3.68 seconds
[0m11:47:51.128993 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c492550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dd2a370>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dcc5ac0>]}
[0m11:47:51.129876 [debug] [MainThread]: Flushing usage events
[0m11:49:13.182202 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c44f7f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d7eb2b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109fe2a00>]}


============================== 11:49:13.191544 | 96174dc7-a095-4a64-ae64-2c56e9141d5a ==============================
[0m11:49:13.191544 [info ] [MainThread]: Running with dbt=1.5.4
[0m11:49:13.193324 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/Users/denisechan/Documents/Makers/Data_Engineering/Week_6/dbt_warehouse/logs', 'fail_fast': 'False', 'profiles_dir': '/Users/denisechan/Documents/Makers/Data_Engineering/Week_6/dbt_warehouse', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'send_anonymous_usage_stats': 'True'}
[0m11:49:13.374715 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '96174dc7-a095-4a64-ae64-2c56e9141d5a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d7eb9a0>]}
[0m11:49:13.417652 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '96174dc7-a095-4a64-ae64-2c56e9141d5a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10da4e6a0>]}
[0m11:49:13.420342 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m11:49:13.483414 [debug] [MainThread]: checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, vars: {}, profile: , target: , version: 1.5.4
[0m11:49:13.626273 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
[0m11:49:13.628198 [debug] [MainThread]: Partial parsing: added file: maker_warehouse://models/facts/avg_viewing_time.sql
[0m11:49:13.682686 [debug] [MainThread]: 1699: static parser successfully parsed facts/avg_viewing_time.sql
[0m11:49:13.735982 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '96174dc7-a095-4a64-ae64-2c56e9141d5a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dcd80d0>]}
[0m11:49:13.750414 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '96174dc7-a095-4a64-ae64-2c56e9141d5a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dbc4e80>]}
[0m11:49:13.751308 [info ] [MainThread]: Found 5 models, 0 tests, 0 snapshots, 0 analyses, 307 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics, 0 groups
[0m11:49:13.752143 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '96174dc7-a095-4a64-ae64-2c56e9141d5a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dbc4d90>]}
[0m11:49:13.755223 [info ] [MainThread]: 
[0m11:49:13.757000 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m11:49:13.759247 [debug] [ThreadPool]: Acquiring new postgres connection 'list_mydb'
[0m11:49:13.783344 [debug] [ThreadPool]: Using postgres connection "list_mydb"
[0m11:49:13.784459 [debug] [ThreadPool]: On list_mydb: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "connection_name": "list_mydb"} */

    select distinct nspname from pg_namespace
  
[0m11:49:13.785071 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:49:13.990680 [debug] [ThreadPool]: SQL status: SELECT 5 in 0.0 seconds
[0m11:49:13.993209 [debug] [ThreadPool]: On list_mydb: Close
[0m11:49:13.996996 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_mydb, now list_mydb_dbt_warehouse)
[0m11:49:14.013107 [debug] [ThreadPool]: Using postgres connection "list_mydb_dbt_warehouse"
[0m11:49:14.013970 [debug] [ThreadPool]: On list_mydb_dbt_warehouse: BEGIN
[0m11:49:14.015051 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:49:14.052755 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m11:49:14.054896 [debug] [ThreadPool]: Using postgres connection "list_mydb_dbt_warehouse"
[0m11:49:14.056233 [debug] [ThreadPool]: On list_mydb_dbt_warehouse: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "connection_name": "list_mydb_dbt_warehouse"} */
select
      'mydb' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_warehouse'
    union all
    select
      'mydb' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_warehouse'
  
[0m11:49:14.072577 [debug] [ThreadPool]: SQL status: SELECT 5 in 0.0 seconds
[0m11:49:14.074849 [debug] [ThreadPool]: On list_mydb_dbt_warehouse: ROLLBACK
[0m11:49:14.076920 [debug] [ThreadPool]: On list_mydb_dbt_warehouse: Close
[0m11:49:14.091105 [debug] [MainThread]: Using postgres connection "master"
[0m11:49:14.091742 [debug] [MainThread]: On master: BEGIN
[0m11:49:14.092211 [debug] [MainThread]: Opening a new connection, currently in state init
[0m11:49:14.131661 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m11:49:14.132391 [debug] [MainThread]: Using postgres connection "master"
[0m11:49:14.133092 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m11:49:14.160018 [debug] [MainThread]: SQL status: SELECT 5 in 0.0 seconds
[0m11:49:14.163007 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '96174dc7-a095-4a64-ae64-2c56e9141d5a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dce4a30>]}
[0m11:49:14.163946 [debug] [MainThread]: On master: ROLLBACK
[0m11:49:14.166333 [debug] [MainThread]: Using postgres connection "master"
[0m11:49:14.167528 [debug] [MainThread]: On master: BEGIN
[0m11:49:14.172922 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m11:49:14.173668 [debug] [MainThread]: On master: COMMIT
[0m11:49:14.174233 [debug] [MainThread]: Using postgres connection "master"
[0m11:49:14.174708 [debug] [MainThread]: On master: COMMIT
[0m11:49:14.176995 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m11:49:14.178005 [debug] [MainThread]: On master: Close
[0m11:49:14.179781 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m11:49:14.181047 [info ] [MainThread]: 
[0m11:49:14.199662 [debug] [Thread-1  ]: Began running node model.maker_warehouse.avg_viewing_time
[0m11:49:14.200807 [debug] [Thread-2  ]: Began running node model.maker_warehouse.movies
[0m11:49:14.201736 [debug] [Thread-3  ]: Began running node model.maker_warehouse.no_of_viewings
[0m11:49:14.202814 [debug] [Thread-4  ]: Began running node model.maker_warehouse.total_viewing_time
[0m11:49:14.204399 [info ] [Thread-1  ]: 1 of 5 START sql table model dbt_warehouse.avg_viewing_time .................... [RUN]
[0m11:49:14.206784 [info ] [Thread-2  ]: 2 of 5 START sql table model dbt_warehouse.movies .............................. [RUN]
[0m11:49:14.208924 [info ] [Thread-3  ]: 3 of 5 START sql table model dbt_warehouse.no_of_viewings ...................... [RUN]
[0m11:49:14.215746 [debug] [Thread-3  ]: Acquiring new postgres connection 'model.maker_warehouse.no_of_viewings'
[0m11:49:14.216435 [debug] [Thread-3  ]: Began compiling node model.maker_warehouse.no_of_viewings
[0m11:49:14.210344 [info ] [Thread-4  ]: 4 of 5 START sql table model dbt_warehouse.total_viewing_time .................. [RUN]
[0m11:49:14.212545 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_mydb_dbt_warehouse, now model.maker_warehouse.avg_viewing_time)
[0m11:49:14.214227 [debug] [Thread-2  ]: Acquiring new postgres connection 'model.maker_warehouse.movies'
[0m11:49:14.234868 [debug] [Thread-4  ]: Acquiring new postgres connection 'model.maker_warehouse.total_viewing_time'
[0m11:49:14.249798 [debug] [Thread-4  ]: Began compiling node model.maker_warehouse.total_viewing_time
[0m11:49:14.242181 [debug] [Thread-3  ]: Writing injected SQL for node "model.maker_warehouse.no_of_viewings"
[0m11:49:14.245640 [debug] [Thread-2  ]: Began compiling node model.maker_warehouse.movies
[0m11:49:14.244132 [debug] [Thread-1  ]: Began compiling node model.maker_warehouse.avg_viewing_time
[0m11:49:14.261039 [debug] [Thread-4  ]: Writing injected SQL for node "model.maker_warehouse.total_viewing_time"
[0m11:49:14.269392 [debug] [Thread-2  ]: Writing injected SQL for node "model.maker_warehouse.movies"
[0m11:49:14.274756 [debug] [Thread-1  ]: Writing injected SQL for node "model.maker_warehouse.avg_viewing_time"
[0m11:49:14.275872 [debug] [Thread-3  ]: Timing info for model.maker_warehouse.no_of_viewings (compile): 11:49:14.216860 => 11:49:14.275481
[0m11:49:14.279319 [debug] [Thread-4  ]: Timing info for model.maker_warehouse.total_viewing_time (compile): 11:49:14.250931 => 11:49:14.277180
[0m11:49:14.281519 [debug] [Thread-2  ]: Timing info for model.maker_warehouse.movies (compile): 11:49:14.263237 => 11:49:14.281069
[0m11:49:14.282245 [debug] [Thread-3  ]: Began executing node model.maker_warehouse.no_of_viewings
[0m11:49:14.283038 [debug] [Thread-4  ]: Began executing node model.maker_warehouse.total_viewing_time
[0m11:49:14.283725 [debug] [Thread-1  ]: Timing info for model.maker_warehouse.avg_viewing_time (compile): 11:49:14.270098 => 11:49:14.283383
[0m11:49:14.284319 [debug] [Thread-2  ]: Began executing node model.maker_warehouse.movies
[0m11:49:14.362448 [debug] [Thread-1  ]: Began executing node model.maker_warehouse.avg_viewing_time
[0m11:49:14.434151 [debug] [Thread-3  ]: Writing runtime sql for node "model.maker_warehouse.no_of_viewings"
[0m11:49:14.435170 [debug] [Thread-4  ]: Writing runtime sql for node "model.maker_warehouse.total_viewing_time"
[0m11:49:14.447212 [debug] [Thread-2  ]: Writing runtime sql for node "model.maker_warehouse.movies"
[0m11:49:14.449542 [debug] [Thread-1  ]: Writing runtime sql for node "model.maker_warehouse.avg_viewing_time"
[0m11:49:14.451068 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.no_of_viewings"
[0m11:49:14.451926 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.total_viewing_time"
[0m11:49:14.453060 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.movies"
[0m11:49:14.453887 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.avg_viewing_time"
[0m11:49:14.454711 [debug] [Thread-3  ]: On model.maker_warehouse.no_of_viewings: BEGIN
[0m11:49:14.455369 [debug] [Thread-4  ]: On model.maker_warehouse.total_viewing_time: BEGIN
[0m11:49:14.456122 [debug] [Thread-2  ]: On model.maker_warehouse.movies: BEGIN
[0m11:49:14.456772 [debug] [Thread-1  ]: On model.maker_warehouse.avg_viewing_time: BEGIN
[0m11:49:14.457369 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m11:49:14.458009 [debug] [Thread-4  ]: Opening a new connection, currently in state init
[0m11:49:14.458619 [debug] [Thread-2  ]: Opening a new connection, currently in state init
[0m11:49:14.459205 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m11:49:14.514323 [debug] [Thread-4  ]: SQL status: BEGIN in 0.0 seconds
[0m11:49:14.515803 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.total_viewing_time"
[0m11:49:14.517511 [debug] [Thread-4  ]: On model.maker_warehouse.total_viewing_time: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_viewing_time"} */

  
    

  create  table "mydb"."dbt_warehouse"."total_viewing_time__dbt_tmp"
  
  
    as
  
  (
    
SELECT
title,
SUM(duration) as total_duration
FROM mydb.public.raw_netflix
GROUP BY title
ORDER BY total_duration DESC
  );
  
[0m11:49:14.524775 [debug] [Thread-3  ]: SQL status: BEGIN in 0.0 seconds
[0m11:49:14.526032 [debug] [Thread-2  ]: SQL status: BEGIN in 0.0 seconds
[0m11:49:14.529328 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.movies"
[0m11:49:14.527598 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.no_of_viewings"
[0m11:49:14.530023 [debug] [Thread-2  ]: On model.maker_warehouse.movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.movies"} */

  
    

  create  table "mydb"."dbt_warehouse"."movies__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    DISTINCT
    title,
    genres,
    release_date,
    movie_id
FROM mydb.public.raw_netflix
  );
  
[0m11:49:14.531630 [debug] [Thread-3  ]: On model.maker_warehouse.no_of_viewings: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.no_of_viewings"} */

  
    

  create  table "mydb"."dbt_warehouse"."no_of_viewings__dbt_tmp"
  
  
    as
  
  (
    
SELECT
  title,
  COUNT(*) as total_views
FROM mydb.public.raw_netflix
GROUP BY title
ORDER BY total_views DESC
  );
  
[0m11:49:14.534272 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
[0m11:49:14.535480 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.avg_viewing_time"
[0m11:49:14.537152 [debug] [Thread-1  ]: On model.maker_warehouse.avg_viewing_time: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.avg_viewing_time"} */

  
    

  create  table "mydb"."dbt_warehouse"."avg_viewing_time__dbt_tmp"
  
  
    as
  
  (
    
SELECT
title,
ROUND(CAST(AVG(duration) AS NUMERIC), 2) as avg_duration
FROM mydb.public.raw_netflix
GROUP BY title
ORDER BY avg_duration DESC
  );
  
[0m11:49:15.629595 [debug] [Thread-4  ]: SQL status: SELECT 7925 in 1.0 seconds
[0m11:49:15.648568 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.total_viewing_time"
[0m11:49:15.649624 [debug] [Thread-4  ]: On model.maker_warehouse.total_viewing_time: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_viewing_time"} */
alter table "mydb"."dbt_warehouse"."total_viewing_time" rename to "total_viewing_time__dbt_backup"
[0m11:49:15.656671 [debug] [Thread-4  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:49:15.665071 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.total_viewing_time"
[0m11:49:15.665732 [debug] [Thread-4  ]: On model.maker_warehouse.total_viewing_time: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_viewing_time"} */
alter table "mydb"."dbt_warehouse"."total_viewing_time__dbt_tmp" rename to "total_viewing_time"
[0m11:49:15.672242 [debug] [Thread-4  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:49:15.738611 [debug] [Thread-4  ]: On model.maker_warehouse.total_viewing_time: COMMIT
[0m11:49:15.739579 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.total_viewing_time"
[0m11:49:15.740470 [debug] [Thread-4  ]: On model.maker_warehouse.total_viewing_time: COMMIT
[0m11:49:15.749994 [debug] [Thread-4  ]: SQL status: COMMIT in 0.0 seconds
[0m11:49:15.764840 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.total_viewing_time"
[0m11:49:15.766030 [debug] [Thread-4  ]: On model.maker_warehouse.total_viewing_time: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_viewing_time"} */
drop table if exists "mydb"."dbt_warehouse"."total_viewing_time__dbt_backup" cascade
[0m11:49:15.776126 [debug] [Thread-3  ]: SQL status: SELECT 7925 in 1.0 seconds
[0m11:49:15.785866 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.no_of_viewings"
[0m11:49:15.788158 [debug] [Thread-3  ]: On model.maker_warehouse.no_of_viewings: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.no_of_viewings"} */
alter table "mydb"."dbt_warehouse"."no_of_viewings" rename to "no_of_viewings__dbt_backup"
[0m11:49:15.792347 [debug] [Thread-3  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:49:15.793261 [debug] [Thread-4  ]: SQL status: DROP TABLE in 0.0 seconds
[0m11:49:15.804323 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.no_of_viewings"
[0m11:49:15.808515 [debug] [Thread-4  ]: Timing info for model.maker_warehouse.total_viewing_time (execute): 11:49:14.308111 => 11:49:15.807830
[0m11:49:15.809882 [debug] [Thread-3  ]: On model.maker_warehouse.no_of_viewings: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.no_of_viewings"} */
alter table "mydb"."dbt_warehouse"."no_of_viewings__dbt_tmp" rename to "no_of_viewings"
[0m11:49:15.810688 [debug] [Thread-4  ]: On model.maker_warehouse.total_viewing_time: Close
[0m11:49:15.813206 [debug] [Thread-4  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '96174dc7-a095-4a64-ae64-2c56e9141d5a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10de48370>]}
[0m11:49:15.814365 [info ] [Thread-4  ]: 4 of 5 OK created sql table model dbt_warehouse.total_viewing_time ............. [[32mSELECT 7925[0m in 1.58s]
[0m11:49:15.815518 [debug] [Thread-4  ]: Finished running node model.maker_warehouse.total_viewing_time
[0m11:49:15.823088 [debug] [Thread-3  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:49:15.830829 [debug] [Thread-3  ]: On model.maker_warehouse.no_of_viewings: COMMIT
[0m11:49:15.831622 [debug] [Thread-1  ]: SQL status: SELECT 7925 in 1.0 seconds
[0m11:49:15.832380 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.no_of_viewings"
[0m11:49:15.841157 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.avg_viewing_time"
[0m11:49:15.842010 [debug] [Thread-3  ]: On model.maker_warehouse.no_of_viewings: COMMIT
[0m11:49:15.843112 [debug] [Thread-1  ]: On model.maker_warehouse.avg_viewing_time: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.avg_viewing_time"} */
alter table "mydb"."dbt_warehouse"."avg_viewing_time__dbt_tmp" rename to "avg_viewing_time"
[0m11:49:15.854382 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:49:15.860241 [debug] [Thread-1  ]: On model.maker_warehouse.avg_viewing_time: COMMIT
[0m11:49:15.861103 [debug] [Thread-3  ]: SQL status: COMMIT in 0.0 seconds
[0m11:49:15.861833 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.avg_viewing_time"
[0m11:49:15.869307 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.no_of_viewings"
[0m11:49:15.871339 [debug] [Thread-1  ]: On model.maker_warehouse.avg_viewing_time: COMMIT
[0m11:49:15.873543 [debug] [Thread-3  ]: On model.maker_warehouse.no_of_viewings: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.no_of_viewings"} */
drop table if exists "mydb"."dbt_warehouse"."no_of_viewings__dbt_backup" cascade
[0m11:49:15.877563 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
[0m11:49:15.885832 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.avg_viewing_time"
[0m11:49:15.887318 [debug] [Thread-1  ]: On model.maker_warehouse.avg_viewing_time: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.avg_viewing_time"} */
drop table if exists "mydb"."dbt_warehouse"."avg_viewing_time__dbt_backup" cascade
[0m11:49:15.891468 [debug] [Thread-3  ]: SQL status: DROP TABLE in 0.0 seconds
[0m11:49:15.895904 [debug] [Thread-3  ]: Timing info for model.maker_warehouse.no_of_viewings (execute): 11:49:14.284733 => 11:49:15.895581
[0m11:49:15.896540 [debug] [Thread-3  ]: On model.maker_warehouse.no_of_viewings: Close
[0m11:49:15.898025 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '96174dc7-a095-4a64-ae64-2c56e9141d5a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10de691f0>]}
[0m11:49:15.900247 [info ] [Thread-3  ]: 3 of 5 OK created sql table model dbt_warehouse.no_of_viewings ................. [[32mSELECT 7925[0m in 1.68s]
[0m11:49:15.901611 [debug] [Thread-3  ]: Finished running node model.maker_warehouse.no_of_viewings
[0m11:49:15.905908 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
[0m11:49:15.911919 [debug] [Thread-1  ]: Timing info for model.maker_warehouse.avg_viewing_time (execute): 11:49:14.441085 => 11:49:15.911163
[0m11:49:15.913009 [debug] [Thread-1  ]: On model.maker_warehouse.avg_viewing_time: Close
[0m11:49:15.914409 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '96174dc7-a095-4a64-ae64-2c56e9141d5a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10de04670>]}
[0m11:49:15.915648 [info ] [Thread-1  ]: 1 of 5 OK created sql table model dbt_warehouse.avg_viewing_time ............... [[32mSELECT 7925[0m in 1.70s]
[0m11:49:15.916702 [debug] [Thread-1  ]: Finished running node model.maker_warehouse.avg_viewing_time
[0m11:49:16.563596 [debug] [Thread-2  ]: SQL status: SELECT 8472 in 2.0 seconds
[0m11:49:16.574852 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.movies"
[0m11:49:16.576390 [debug] [Thread-2  ]: On model.maker_warehouse.movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.movies"} */
alter table "mydb"."dbt_warehouse"."movies" rename to "movies__dbt_backup"
[0m11:49:16.583056 [debug] [Thread-2  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:49:16.596138 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.movies"
[0m11:49:16.597159 [debug] [Thread-2  ]: On model.maker_warehouse.movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.movies"} */
alter table "mydb"."dbt_warehouse"."movies__dbt_tmp" rename to "movies"
[0m11:49:16.605869 [debug] [Thread-2  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:49:16.612611 [debug] [Thread-2  ]: On model.maker_warehouse.movies: COMMIT
[0m11:49:16.613413 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.movies"
[0m11:49:16.613981 [debug] [Thread-2  ]: On model.maker_warehouse.movies: COMMIT
[0m11:49:16.622664 [debug] [Thread-2  ]: SQL status: COMMIT in 0.0 seconds
[0m11:49:16.629198 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.movies"
[0m11:49:16.629950 [debug] [Thread-2  ]: On model.maker_warehouse.movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.movies"} */
drop table if exists "mydb"."dbt_warehouse"."movies__dbt_backup" cascade
[0m11:49:16.650144 [debug] [Thread-2  ]: SQL status: DROP TABLE in 0.0 seconds
[0m11:49:16.722721 [debug] [Thread-2  ]: Timing info for model.maker_warehouse.movies (execute): 11:49:14.384112 => 11:49:16.721740
[0m11:49:16.725004 [debug] [Thread-2  ]: On model.maker_warehouse.movies: Close
[0m11:49:16.734803 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '96174dc7-a095-4a64-ae64-2c56e9141d5a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dcd8a00>]}
[0m11:49:16.736676 [info ] [Thread-2  ]: 2 of 5 OK created sql table model dbt_warehouse.movies ......................... [[32mSELECT 8472[0m in 2.52s]
[0m11:49:16.739750 [debug] [Thread-2  ]: Finished running node model.maker_warehouse.movies
[0m11:49:16.784661 [debug] [Thread-4  ]: Began running node model.maker_warehouse.all_movies
[0m11:49:16.791117 [info ] [Thread-4  ]: 5 of 5 START sql table model dbt_warehouse.all_movies .......................... [RUN]
[0m11:49:16.793886 [debug] [Thread-4  ]: Re-using an available connection from the pool (formerly model.maker_warehouse.total_viewing_time, now model.maker_warehouse.all_movies)
[0m11:49:16.795013 [debug] [Thread-4  ]: Began compiling node model.maker_warehouse.all_movies
[0m11:49:16.818445 [debug] [Thread-4  ]: Writing injected SQL for node "model.maker_warehouse.all_movies"
[0m11:49:16.824828 [debug] [Thread-4  ]: Timing info for model.maker_warehouse.all_movies (compile): 11:49:16.796904 => 11:49:16.824040
[0m11:49:16.826097 [debug] [Thread-4  ]: Began executing node model.maker_warehouse.all_movies
[0m11:49:16.852736 [debug] [Thread-4  ]: Writing runtime sql for node "model.maker_warehouse.all_movies"
[0m11:49:16.856171 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.all_movies"
[0m11:49:16.857406 [debug] [Thread-4  ]: On model.maker_warehouse.all_movies: BEGIN
[0m11:49:16.858324 [debug] [Thread-4  ]: Opening a new connection, currently in state closed
[0m11:49:16.914968 [debug] [Thread-4  ]: SQL status: BEGIN in 0.0 seconds
[0m11:49:16.916327 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.all_movies"
[0m11:49:16.917770 [debug] [Thread-4  ]: On model.maker_warehouse.all_movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.all_movies"} */

  
    

  create  table "mydb"."dbt_warehouse"."all_movies__dbt_tmp"
  
  
    as
  
  (
    
  
SELECT
*
FROM "mydb"."dbt_warehouse"."movies"
  );
  
[0m11:49:17.039601 [debug] [Thread-4  ]: SQL status: SELECT 8472 in 0.0 seconds
[0m11:49:17.054315 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.all_movies"
[0m11:49:17.056456 [debug] [Thread-4  ]: On model.maker_warehouse.all_movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.all_movies"} */
alter table "mydb"."dbt_warehouse"."all_movies" rename to "all_movies__dbt_backup"
[0m11:49:17.068829 [debug] [Thread-4  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:49:17.117013 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.all_movies"
[0m11:49:17.122072 [debug] [Thread-4  ]: On model.maker_warehouse.all_movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.all_movies"} */
alter table "mydb"."dbt_warehouse"."all_movies__dbt_tmp" rename to "all_movies"
[0m11:49:17.144645 [debug] [Thread-4  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:49:17.155374 [debug] [Thread-4  ]: On model.maker_warehouse.all_movies: COMMIT
[0m11:49:17.157622 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.all_movies"
[0m11:49:17.164973 [debug] [Thread-4  ]: On model.maker_warehouse.all_movies: COMMIT
[0m11:49:17.179242 [debug] [Thread-4  ]: SQL status: COMMIT in 0.0 seconds
[0m11:49:17.186645 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.all_movies"
[0m11:49:17.188970 [debug] [Thread-4  ]: On model.maker_warehouse.all_movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.all_movies"} */
drop table if exists "mydb"."dbt_warehouse"."all_movies__dbt_backup" cascade
[0m11:49:17.211078 [debug] [Thread-4  ]: SQL status: DROP TABLE in 0.0 seconds
[0m11:49:17.215417 [debug] [Thread-4  ]: Timing info for model.maker_warehouse.all_movies (execute): 11:49:16.828578 => 11:49:17.214831
[0m11:49:17.221267 [debug] [Thread-4  ]: On model.maker_warehouse.all_movies: Close
[0m11:49:17.223616 [debug] [Thread-4  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '96174dc7-a095-4a64-ae64-2c56e9141d5a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10df3b040>]}
[0m11:49:17.231171 [info ] [Thread-4  ]: 5 of 5 OK created sql table model dbt_warehouse.all_movies ..................... [[32mSELECT 8472[0m in 0.43s]
[0m11:49:17.234154 [debug] [Thread-4  ]: Finished running node model.maker_warehouse.all_movies
[0m11:49:17.237340 [debug] [MainThread]: Using postgres connection "master"
[0m11:49:17.238354 [debug] [MainThread]: On master: BEGIN
[0m11:49:17.239376 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m11:49:17.280899 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m11:49:17.281960 [debug] [MainThread]: On master: COMMIT
[0m11:49:17.282760 [debug] [MainThread]: Using postgres connection "master"
[0m11:49:17.283510 [debug] [MainThread]: On master: COMMIT
[0m11:49:17.287123 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m11:49:17.288223 [debug] [MainThread]: On master: Close
[0m11:49:17.290803 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:49:17.291603 [debug] [MainThread]: Connection 'model.maker_warehouse.avg_viewing_time' was properly closed.
[0m11:49:17.292384 [debug] [MainThread]: Connection 'model.maker_warehouse.movies' was properly closed.
[0m11:49:17.293361 [debug] [MainThread]: Connection 'model.maker_warehouse.no_of_viewings' was properly closed.
[0m11:49:17.294759 [debug] [MainThread]: Connection 'model.maker_warehouse.all_movies' was properly closed.
[0m11:49:17.296059 [info ] [MainThread]: 
[0m11:49:17.297249 [info ] [MainThread]: Finished running 5 table models in 0 hours 0 minutes and 3.54 seconds (3.54s).
[0m11:49:17.304642 [debug] [MainThread]: Command end result
[0m11:49:17.319929 [info ] [MainThread]: 
[0m11:49:17.321872 [info ] [MainThread]: [32mCompleted successfully[0m
[0m11:49:17.323340 [info ] [MainThread]: 
[0m11:49:17.324548 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
[0m11:49:17.327402 [debug] [MainThread]: Command `dbt run` succeeded at 11:49:17.326030 after 4.19 seconds
[0m11:49:17.328949 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c44f7f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10df29f70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10df16b80>]}
[0m11:49:17.329829 [debug] [MainThread]: Flushing usage events
[0m11:51:23.775696 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1103d97f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1117752b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10df6ca00>]}


============================== 11:51:23.783586 | a04ea96e-586d-4462-9ffb-10291f185407 ==============================
[0m11:51:23.783586 [info ] [MainThread]: Running with dbt=1.5.4
[0m11:51:23.784915 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/denisechan/Documents/Makers/Data_Engineering/Week_6/dbt_warehouse', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': '/Users/denisechan/Documents/Makers/Data_Engineering/Week_6/dbt_warehouse/logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'send_anonymous_usage_stats': 'True'}
[0m11:51:24.225040 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a04ea96e-586d-4462-9ffb-10291f185407', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1117759a0>]}
[0m11:51:24.266849 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'a04ea96e-586d-4462-9ffb-10291f185407', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1119d86a0>]}
[0m11:51:24.268803 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m11:51:24.318477 [debug] [MainThread]: checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, vars: {}, profile: , target: , version: 1.5.4
[0m11:51:24.473864 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
[0m11:51:24.474787 [debug] [MainThread]: Partial parsing: added file: maker_warehouse://models/facts/total_unique_users.sql
[0m11:51:24.527355 [debug] [MainThread]: 1699: static parser successfully parsed facts/total_unique_users.sql
[0m11:51:24.565125 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a04ea96e-586d-4462-9ffb-10291f185407', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111c5cf10>]}
[0m11:51:24.578985 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a04ea96e-586d-4462-9ffb-10291f185407', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111b8a490>]}
[0m11:51:24.579940 [info ] [MainThread]: Found 6 models, 0 tests, 0 snapshots, 0 analyses, 307 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics, 0 groups
[0m11:51:24.581011 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a04ea96e-586d-4462-9ffb-10291f185407', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111b8a430>]}
[0m11:51:24.584640 [info ] [MainThread]: 
[0m11:51:24.595256 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m11:51:24.599003 [debug] [ThreadPool]: Acquiring new postgres connection 'list_mydb'
[0m11:51:24.621735 [debug] [ThreadPool]: Using postgres connection "list_mydb"
[0m11:51:24.622410 [debug] [ThreadPool]: On list_mydb: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "connection_name": "list_mydb"} */

    select distinct nspname from pg_namespace
  
[0m11:51:24.623098 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:51:24.829473 [debug] [ThreadPool]: SQL status: SELECT 5 in 0.0 seconds
[0m11:51:24.833613 [debug] [ThreadPool]: On list_mydb: Close
[0m11:51:24.841201 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_mydb, now list_mydb_dbt_warehouse)
[0m11:51:24.853770 [debug] [ThreadPool]: Using postgres connection "list_mydb_dbt_warehouse"
[0m11:51:24.854355 [debug] [ThreadPool]: On list_mydb_dbt_warehouse: BEGIN
[0m11:51:24.854915 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:51:24.909459 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m11:51:24.911137 [debug] [ThreadPool]: Using postgres connection "list_mydb_dbt_warehouse"
[0m11:51:24.912306 [debug] [ThreadPool]: On list_mydb_dbt_warehouse: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "connection_name": "list_mydb_dbt_warehouse"} */
select
      'mydb' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_warehouse'
    union all
    select
      'mydb' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_warehouse'
  
[0m11:51:24.954961 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.0 seconds
[0m11:51:24.964155 [debug] [ThreadPool]: On list_mydb_dbt_warehouse: ROLLBACK
[0m11:51:25.090978 [debug] [ThreadPool]: On list_mydb_dbt_warehouse: Close
[0m11:51:25.123324 [debug] [MainThread]: Using postgres connection "master"
[0m11:51:25.124340 [debug] [MainThread]: On master: BEGIN
[0m11:51:25.125185 [debug] [MainThread]: Opening a new connection, currently in state init
[0m11:51:25.227861 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m11:51:25.230647 [debug] [MainThread]: Using postgres connection "master"
[0m11:51:25.232033 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m11:51:25.301048 [debug] [MainThread]: SQL status: SELECT 5 in 0.0 seconds
[0m11:51:25.304147 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a04ea96e-586d-4462-9ffb-10291f185407', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111c746a0>]}
[0m11:51:25.305483 [debug] [MainThread]: On master: ROLLBACK
[0m11:51:25.311127 [debug] [MainThread]: Using postgres connection "master"
[0m11:51:25.311982 [debug] [MainThread]: On master: BEGIN
[0m11:51:25.321613 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m11:51:25.323409 [debug] [MainThread]: On master: COMMIT
[0m11:51:25.324354 [debug] [MainThread]: Using postgres connection "master"
[0m11:51:25.325392 [debug] [MainThread]: On master: COMMIT
[0m11:51:25.328751 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m11:51:25.330378 [debug] [MainThread]: On master: Close
[0m11:51:25.333735 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m11:51:25.335271 [info ] [MainThread]: 
[0m11:51:25.350272 [debug] [Thread-1  ]: Began running node model.maker_warehouse.avg_viewing_time
[0m11:51:25.351204 [debug] [Thread-2  ]: Began running node model.maker_warehouse.movies
[0m11:51:25.352222 [debug] [Thread-3  ]: Began running node model.maker_warehouse.no_of_viewings
[0m11:51:25.353575 [debug] [Thread-4  ]: Began running node model.maker_warehouse.total_unique_users
[0m11:51:25.355059 [info ] [Thread-1  ]: 1 of 6 START sql table model dbt_warehouse.avg_viewing_time .................... [RUN]
[0m11:51:25.356912 [info ] [Thread-2  ]: 2 of 6 START sql table model dbt_warehouse.movies .............................. [RUN]
[0m11:51:25.358496 [info ] [Thread-3  ]: 3 of 6 START sql table model dbt_warehouse.no_of_viewings ...................... [RUN]
[0m11:51:25.360048 [info ] [Thread-4  ]: 4 of 6 START sql table model dbt_warehouse.total_unique_users .................. [RUN]
[0m11:51:25.368969 [debug] [Thread-4  ]: Acquiring new postgres connection 'model.maker_warehouse.total_unique_users'
[0m11:51:25.362112 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_mydb_dbt_warehouse, now model.maker_warehouse.avg_viewing_time)
[0m11:51:25.366737 [debug] [Thread-3  ]: Acquiring new postgres connection 'model.maker_warehouse.no_of_viewings'
[0m11:51:25.370156 [debug] [Thread-4  ]: Began compiling node model.maker_warehouse.total_unique_users
[0m11:51:25.364267 [debug] [Thread-2  ]: Acquiring new postgres connection 'model.maker_warehouse.movies'
[0m11:51:25.371663 [debug] [Thread-1  ]: Began compiling node model.maker_warehouse.avg_viewing_time
[0m11:51:25.373526 [debug] [Thread-3  ]: Began compiling node model.maker_warehouse.no_of_viewings
[0m11:51:25.401364 [debug] [Thread-2  ]: Began compiling node model.maker_warehouse.movies
[0m11:51:25.398402 [debug] [Thread-4  ]: Writing injected SQL for node "model.maker_warehouse.total_unique_users"
[0m11:51:25.419178 [debug] [Thread-3  ]: Writing injected SQL for node "model.maker_warehouse.no_of_viewings"
[0m11:51:25.422036 [debug] [Thread-1  ]: Writing injected SQL for node "model.maker_warehouse.avg_viewing_time"
[0m11:51:25.432708 [debug] [Thread-2  ]: Writing injected SQL for node "model.maker_warehouse.movies"
[0m11:51:25.435453 [debug] [Thread-4  ]: Timing info for model.maker_warehouse.total_unique_users (compile): 11:51:25.374344 => 11:51:25.434841
[0m11:51:25.437815 [debug] [Thread-4  ]: Began executing node model.maker_warehouse.total_unique_users
[0m11:51:25.438952 [debug] [Thread-1  ]: Timing info for model.maker_warehouse.avg_viewing_time (compile): 11:51:25.403258 => 11:51:25.438370
[0m11:51:25.464468 [debug] [Thread-3  ]: Timing info for model.maker_warehouse.no_of_viewings (compile): 11:51:25.413361 => 11:51:25.463829
[0m11:51:25.465682 [debug] [Thread-1  ]: Began executing node model.maker_warehouse.avg_viewing_time
[0m11:51:25.467850 [debug] [Thread-2  ]: Timing info for model.maker_warehouse.movies (compile): 11:51:25.423173 => 11:51:25.467230
[0m11:51:25.468891 [debug] [Thread-3  ]: Began executing node model.maker_warehouse.no_of_viewings
[0m11:51:25.475827 [debug] [Thread-2  ]: Began executing node model.maker_warehouse.movies
[0m11:51:25.706898 [debug] [Thread-4  ]: Writing runtime sql for node "model.maker_warehouse.total_unique_users"
[0m11:51:25.715495 [debug] [Thread-1  ]: Writing runtime sql for node "model.maker_warehouse.avg_viewing_time"
[0m11:51:25.722883 [debug] [Thread-3  ]: Writing runtime sql for node "model.maker_warehouse.no_of_viewings"
[0m11:51:25.724814 [debug] [Thread-2  ]: Writing runtime sql for node "model.maker_warehouse.movies"
[0m11:51:25.726424 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.total_unique_users"
[0m11:51:25.727308 [debug] [Thread-4  ]: On model.maker_warehouse.total_unique_users: BEGIN
[0m11:51:25.728055 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.avg_viewing_time"
[0m11:51:25.728739 [debug] [Thread-4  ]: Opening a new connection, currently in state init
[0m11:51:25.729414 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.movies"
[0m11:51:25.730747 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.no_of_viewings"
[0m11:51:25.731575 [debug] [Thread-1  ]: On model.maker_warehouse.avg_viewing_time: BEGIN
[0m11:51:25.732800 [debug] [Thread-2  ]: On model.maker_warehouse.movies: BEGIN
[0m11:51:25.733934 [debug] [Thread-3  ]: On model.maker_warehouse.no_of_viewings: BEGIN
[0m11:51:25.735231 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m11:51:25.736271 [debug] [Thread-2  ]: Opening a new connection, currently in state init
[0m11:51:25.737255 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m11:51:25.792506 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
[0m11:51:25.793791 [debug] [Thread-3  ]: SQL status: BEGIN in 0.0 seconds
[0m11:51:25.794482 [debug] [Thread-4  ]: SQL status: BEGIN in 0.0 seconds
[0m11:51:25.795527 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.avg_viewing_time"
[0m11:51:25.796470 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.no_of_viewings"
[0m11:51:25.797547 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.total_unique_users"
[0m11:51:25.798479 [debug] [Thread-1  ]: On model.maker_warehouse.avg_viewing_time: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.avg_viewing_time"} */

  
    

  create  table "mydb"."dbt_warehouse"."avg_viewing_time__dbt_tmp"
  
  
    as
  
  (
    
SELECT
title,
ROUND(CAST(AVG(duration) AS NUMERIC), 2) as avg_duration
FROM mydb.public.raw_netflix
GROUP BY title
ORDER BY avg_duration DESC
  );
  
[0m11:51:25.799945 [debug] [Thread-3  ]: On model.maker_warehouse.no_of_viewings: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.no_of_viewings"} */

  
    

  create  table "mydb"."dbt_warehouse"."no_of_viewings__dbt_tmp"
  
  
    as
  
  (
    
SELECT
  title,
  COUNT(*) as total_views
FROM mydb.public.raw_netflix
GROUP BY title
ORDER BY total_views DESC
  );
  
[0m11:51:25.800628 [debug] [Thread-2  ]: SQL status: BEGIN in 0.0 seconds
[0m11:51:25.801342 [debug] [Thread-4  ]: On model.maker_warehouse.total_unique_users: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_unique_users"} */

  
    

  create  table "mydb"."dbt_warehouse"."total_unique_users__dbt_tmp"
  
  
    as
  
  (
    
SELECT 
COUNT(DISTINCT(user_id)) AS total_unique_users
FROM mydb.public.raw_netflix
  );
  
[0m11:51:25.802523 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.movies"
[0m11:51:25.804158 [debug] [Thread-2  ]: On model.maker_warehouse.movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.movies"} */

  
    

  create  table "mydb"."dbt_warehouse"."movies__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    DISTINCT
    title,
    genres,
    release_date,
    movie_id
FROM mydb.public.raw_netflix
  );
  
[0m11:51:26.552834 [debug] [Thread-3  ]: SQL status: SELECT 7925 in 1.0 seconds
[0m11:51:26.575968 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.no_of_viewings"
[0m11:51:26.577306 [debug] [Thread-3  ]: On model.maker_warehouse.no_of_viewings: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.no_of_viewings"} */
alter table "mydb"."dbt_warehouse"."no_of_viewings" rename to "no_of_viewings__dbt_backup"
[0m11:51:26.581130 [debug] [Thread-3  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:51:26.595604 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.no_of_viewings"
[0m11:51:26.597387 [debug] [Thread-3  ]: On model.maker_warehouse.no_of_viewings: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.no_of_viewings"} */
alter table "mydb"."dbt_warehouse"."no_of_viewings__dbt_tmp" rename to "no_of_viewings"
[0m11:51:26.608934 [debug] [Thread-3  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:51:26.690451 [debug] [Thread-3  ]: On model.maker_warehouse.no_of_viewings: COMMIT
[0m11:51:26.692051 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.no_of_viewings"
[0m11:51:26.693528 [debug] [Thread-3  ]: On model.maker_warehouse.no_of_viewings: COMMIT
[0m11:51:26.708241 [debug] [Thread-3  ]: SQL status: COMMIT in 0.0 seconds
[0m11:51:26.795290 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.no_of_viewings"
[0m11:51:26.797836 [debug] [Thread-3  ]: On model.maker_warehouse.no_of_viewings: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.no_of_viewings"} */
drop table if exists "mydb"."dbt_warehouse"."no_of_viewings__dbt_backup" cascade
[0m11:51:27.129706 [debug] [Thread-3  ]: SQL status: DROP TABLE in 0.0 seconds
[0m11:51:27.134034 [debug] [Thread-3  ]: Timing info for model.maker_warehouse.no_of_viewings (execute): 11:51:25.476521 => 11:51:27.133461
[0m11:51:27.135147 [debug] [Thread-3  ]: On model.maker_warehouse.no_of_viewings: Close
[0m11:51:27.137652 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a04ea96e-586d-4462-9ffb-10291f185407', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111e04f70>]}
[0m11:51:27.139506 [info ] [Thread-3  ]: 3 of 6 OK created sql table model dbt_warehouse.no_of_viewings ................. [[32mSELECT 7925[0m in 1.77s]
[0m11:51:27.145937 [debug] [Thread-3  ]: Finished running node model.maker_warehouse.no_of_viewings
[0m11:51:27.147240 [debug] [Thread-3  ]: Began running node model.maker_warehouse.total_viewing_time
[0m11:51:27.148412 [info ] [Thread-3  ]: 5 of 6 START sql table model dbt_warehouse.total_viewing_time .................. [RUN]
[0m11:51:27.151913 [debug] [Thread-3  ]: Re-using an available connection from the pool (formerly model.maker_warehouse.no_of_viewings, now model.maker_warehouse.total_viewing_time)
[0m11:51:27.153655 [debug] [Thread-3  ]: Began compiling node model.maker_warehouse.total_viewing_time
[0m11:51:27.162872 [debug] [Thread-3  ]: Writing injected SQL for node "model.maker_warehouse.total_viewing_time"
[0m11:51:27.176632 [debug] [Thread-3  ]: Timing info for model.maker_warehouse.total_viewing_time (compile): 11:51:27.154582 => 11:51:27.165221
[0m11:51:27.180325 [debug] [Thread-3  ]: Began executing node model.maker_warehouse.total_viewing_time
[0m11:51:27.198261 [debug] [Thread-3  ]: Writing runtime sql for node "model.maker_warehouse.total_viewing_time"
[0m11:51:27.200987 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.total_viewing_time"
[0m11:51:27.202278 [debug] [Thread-3  ]: On model.maker_warehouse.total_viewing_time: BEGIN
[0m11:51:27.203014 [debug] [Thread-3  ]: Opening a new connection, currently in state closed
[0m11:51:27.441931 [debug] [Thread-3  ]: SQL status: BEGIN in 0.0 seconds
[0m11:51:27.443396 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.total_viewing_time"
[0m11:51:27.444575 [debug] [Thread-3  ]: On model.maker_warehouse.total_viewing_time: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_viewing_time"} */

  
    

  create  table "mydb"."dbt_warehouse"."total_viewing_time__dbt_tmp"
  
  
    as
  
  (
    
SELECT
title,
SUM(duration) as total_duration
FROM mydb.public.raw_netflix
GROUP BY title
ORDER BY total_duration DESC
  );
  
[0m11:51:27.567094 [debug] [Thread-1  ]: SQL status: SELECT 7925 in 2.0 seconds
[0m11:51:27.576787 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.avg_viewing_time"
[0m11:51:27.578014 [debug] [Thread-1  ]: On model.maker_warehouse.avg_viewing_time: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.avg_viewing_time"} */
alter table "mydb"."dbt_warehouse"."avg_viewing_time" rename to "avg_viewing_time__dbt_backup"
[0m11:51:27.581857 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:51:27.591339 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.avg_viewing_time"
[0m11:51:27.592695 [debug] [Thread-1  ]: On model.maker_warehouse.avg_viewing_time: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.avg_viewing_time"} */
alter table "mydb"."dbt_warehouse"."avg_viewing_time__dbt_tmp" rename to "avg_viewing_time"
[0m11:51:27.595903 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:51:27.602903 [debug] [Thread-1  ]: On model.maker_warehouse.avg_viewing_time: COMMIT
[0m11:51:27.604223 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.avg_viewing_time"
[0m11:51:27.605412 [debug] [Thread-1  ]: On model.maker_warehouse.avg_viewing_time: COMMIT
[0m11:51:27.611795 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
[0m11:51:27.617818 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.avg_viewing_time"
[0m11:51:27.618651 [debug] [Thread-1  ]: On model.maker_warehouse.avg_viewing_time: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.avg_viewing_time"} */
drop table if exists "mydb"."dbt_warehouse"."avg_viewing_time__dbt_backup" cascade
[0m11:51:27.635134 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
[0m11:51:27.639909 [debug] [Thread-1  ]: Timing info for model.maker_warehouse.avg_viewing_time (execute): 11:51:25.469530 => 11:51:27.639214
[0m11:51:27.640607 [debug] [Thread-1  ]: On model.maker_warehouse.avg_viewing_time: Close
[0m11:51:27.642812 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a04ea96e-586d-4462-9ffb-10291f185407', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111c80e50>]}
[0m11:51:27.645050 [info ] [Thread-1  ]: 1 of 6 OK created sql table model dbt_warehouse.avg_viewing_time ............... [[32mSELECT 7925[0m in 2.28s]
[0m11:51:27.647351 [debug] [Thread-1  ]: Finished running node model.maker_warehouse.avg_viewing_time
[0m11:51:28.104056 [debug] [Thread-3  ]: SQL status: SELECT 7925 in 1.0 seconds
[0m11:51:28.114974 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.total_viewing_time"
[0m11:51:28.116356 [debug] [Thread-3  ]: On model.maker_warehouse.total_viewing_time: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_viewing_time"} */
alter table "mydb"."dbt_warehouse"."total_viewing_time" rename to "total_viewing_time__dbt_backup"
[0m11:51:28.120969 [debug] [Thread-3  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:51:28.129462 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.total_viewing_time"
[0m11:51:28.131037 [debug] [Thread-3  ]: On model.maker_warehouse.total_viewing_time: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_viewing_time"} */
alter table "mydb"."dbt_warehouse"."total_viewing_time__dbt_tmp" rename to "total_viewing_time"
[0m11:51:28.136133 [debug] [Thread-3  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:51:28.143197 [debug] [Thread-3  ]: On model.maker_warehouse.total_viewing_time: COMMIT
[0m11:51:28.144845 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.total_viewing_time"
[0m11:51:28.146275 [debug] [Thread-3  ]: On model.maker_warehouse.total_viewing_time: COMMIT
[0m11:51:28.154339 [debug] [Thread-3  ]: SQL status: COMMIT in 0.0 seconds
[0m11:51:28.162977 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.total_viewing_time"
[0m11:51:28.164278 [debug] [Thread-3  ]: On model.maker_warehouse.total_viewing_time: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_viewing_time"} */
drop table if exists "mydb"."dbt_warehouse"."total_viewing_time__dbt_backup" cascade
[0m11:51:28.171719 [debug] [Thread-3  ]: SQL status: DROP TABLE in 0.0 seconds
[0m11:51:28.175842 [debug] [Thread-3  ]: Timing info for model.maker_warehouse.total_viewing_time (execute): 11:51:27.181295 => 11:51:28.175264
[0m11:51:28.177010 [debug] [Thread-3  ]: On model.maker_warehouse.total_viewing_time: Close
[0m11:51:28.178667 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a04ea96e-586d-4462-9ffb-10291f185407', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111e11160>]}
[0m11:51:28.180072 [info ] [Thread-3  ]: 5 of 6 OK created sql table model dbt_warehouse.total_viewing_time ............. [[32mSELECT 7925[0m in 1.03s]
[0m11:51:28.182275 [debug] [Thread-3  ]: Finished running node model.maker_warehouse.total_viewing_time
[0m11:51:28.583610 [debug] [Thread-2  ]: SQL status: SELECT 8472 in 3.0 seconds
[0m11:51:28.593037 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.movies"
[0m11:51:28.594112 [debug] [Thread-2  ]: On model.maker_warehouse.movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.movies"} */
alter table "mydb"."dbt_warehouse"."movies" rename to "movies__dbt_backup"
[0m11:51:28.603815 [debug] [Thread-2  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:51:28.615049 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.movies"
[0m11:51:28.616431 [debug] [Thread-2  ]: On model.maker_warehouse.movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.movies"} */
alter table "mydb"."dbt_warehouse"."movies__dbt_tmp" rename to "movies"
[0m11:51:28.620092 [debug] [Thread-2  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:51:28.626415 [debug] [Thread-2  ]: On model.maker_warehouse.movies: COMMIT
[0m11:51:28.627491 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.movies"
[0m11:51:28.628458 [debug] [Thread-2  ]: On model.maker_warehouse.movies: COMMIT
[0m11:51:28.634183 [debug] [Thread-2  ]: SQL status: COMMIT in 0.0 seconds
[0m11:51:28.640683 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.movies"
[0m11:51:28.641475 [debug] [Thread-2  ]: On model.maker_warehouse.movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.movies"} */
drop table if exists "mydb"."dbt_warehouse"."movies__dbt_backup" cascade
[0m11:51:28.655073 [debug] [Thread-2  ]: SQL status: DROP TABLE in 0.0 seconds
[0m11:51:28.658330 [debug] [Thread-2  ]: Timing info for model.maker_warehouse.movies (execute): 11:51:25.519251 => 11:51:28.657919
[0m11:51:28.659076 [debug] [Thread-2  ]: On model.maker_warehouse.movies: Close
[0m11:51:28.660362 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a04ea96e-586d-4462-9ffb-10291f185407', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111c6e250>]}
[0m11:51:28.661902 [info ] [Thread-2  ]: 2 of 6 OK created sql table model dbt_warehouse.movies ......................... [[32mSELECT 8472[0m in 3.30s]
[0m11:51:28.663618 [debug] [Thread-2  ]: Finished running node model.maker_warehouse.movies
[0m11:51:28.664750 [debug] [Thread-1  ]: Began running node model.maker_warehouse.all_movies
[0m11:51:28.665971 [info ] [Thread-1  ]: 6 of 6 START sql table model dbt_warehouse.all_movies .......................... [RUN]
[0m11:51:28.667959 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.maker_warehouse.avg_viewing_time, now model.maker_warehouse.all_movies)
[0m11:51:28.671115 [debug] [Thread-1  ]: Began compiling node model.maker_warehouse.all_movies
[0m11:51:28.680253 [debug] [Thread-1  ]: Writing injected SQL for node "model.maker_warehouse.all_movies"
[0m11:51:28.684154 [debug] [Thread-1  ]: Timing info for model.maker_warehouse.all_movies (compile): 11:51:28.672262 => 11:51:28.682895
[0m11:51:28.685776 [debug] [Thread-1  ]: Began executing node model.maker_warehouse.all_movies
[0m11:51:28.707039 [debug] [Thread-1  ]: Writing runtime sql for node "model.maker_warehouse.all_movies"
[0m11:51:28.709046 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.all_movies"
[0m11:51:28.710092 [debug] [Thread-1  ]: On model.maker_warehouse.all_movies: BEGIN
[0m11:51:28.711174 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m11:51:28.760554 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
[0m11:51:28.762711 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.all_movies"
[0m11:51:28.764096 [debug] [Thread-1  ]: On model.maker_warehouse.all_movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.all_movies"} */

  
    

  create  table "mydb"."dbt_warehouse"."all_movies__dbt_tmp"
  
  
    as
  
  (
    
  
SELECT
*
FROM "mydb"."dbt_warehouse"."movies"
  );
  
[0m11:51:28.805934 [debug] [Thread-1  ]: SQL status: SELECT 8472 in 0.0 seconds
[0m11:51:28.814288 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.all_movies"
[0m11:51:28.815125 [debug] [Thread-1  ]: On model.maker_warehouse.all_movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.all_movies"} */
alter table "mydb"."dbt_warehouse"."all_movies" rename to "all_movies__dbt_backup"
[0m11:51:28.821239 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:51:28.829044 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.all_movies"
[0m11:51:28.830320 [debug] [Thread-1  ]: On model.maker_warehouse.all_movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.all_movies"} */
alter table "mydb"."dbt_warehouse"."all_movies__dbt_tmp" rename to "all_movies"
[0m11:51:28.837137 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:51:28.843123 [debug] [Thread-1  ]: On model.maker_warehouse.all_movies: COMMIT
[0m11:51:28.843975 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.all_movies"
[0m11:51:28.844588 [debug] [Thread-1  ]: On model.maker_warehouse.all_movies: COMMIT
[0m11:51:28.854761 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
[0m11:51:28.861438 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.all_movies"
[0m11:51:28.862276 [debug] [Thread-1  ]: On model.maker_warehouse.all_movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.all_movies"} */
drop table if exists "mydb"."dbt_warehouse"."all_movies__dbt_backup" cascade
[0m11:51:28.885959 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
[0m11:51:28.893239 [debug] [Thread-1  ]: Timing info for model.maker_warehouse.all_movies (execute): 11:51:28.686596 => 11:51:28.892296
[0m11:51:28.895927 [debug] [Thread-1  ]: On model.maker_warehouse.all_movies: Close
[0m11:51:28.897659 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a04ea96e-586d-4462-9ffb-10291f185407', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111e87dc0>]}
[0m11:51:28.899312 [info ] [Thread-1  ]: 6 of 6 OK created sql table model dbt_warehouse.all_movies ..................... [[32mSELECT 8472[0m in 0.23s]
[0m11:51:28.903145 [debug] [Thread-1  ]: Finished running node model.maker_warehouse.all_movies
[0m11:51:30.418203 [debug] [Thread-4  ]: SQL status: SELECT 1 in 5.0 seconds
[0m11:51:30.425157 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.total_unique_users"
[0m11:51:30.426194 [debug] [Thread-4  ]: On model.maker_warehouse.total_unique_users: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_unique_users"} */
alter table "mydb"."dbt_warehouse"."total_unique_users__dbt_tmp" rename to "total_unique_users"
[0m11:51:30.429474 [debug] [Thread-4  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:51:30.435139 [debug] [Thread-4  ]: On model.maker_warehouse.total_unique_users: COMMIT
[0m11:51:30.435820 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.total_unique_users"
[0m11:51:30.436425 [debug] [Thread-4  ]: On model.maker_warehouse.total_unique_users: COMMIT
[0m11:51:30.443712 [debug] [Thread-4  ]: SQL status: COMMIT in 0.0 seconds
[0m11:51:30.448524 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.total_unique_users"
[0m11:51:30.449410 [debug] [Thread-4  ]: On model.maker_warehouse.total_unique_users: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_unique_users"} */
drop table if exists "mydb"."dbt_warehouse"."total_unique_users__dbt_backup" cascade
[0m11:51:30.453534 [debug] [Thread-4  ]: SQL status: DROP TABLE in 0.0 seconds
[0m11:51:30.457988 [debug] [Thread-4  ]: Timing info for model.maker_warehouse.total_unique_users (execute): 11:51:25.440616 => 11:51:30.457415
[0m11:51:30.458652 [debug] [Thread-4  ]: On model.maker_warehouse.total_unique_users: Close
[0m11:51:30.459915 [debug] [Thread-4  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a04ea96e-586d-4462-9ffb-10291f185407', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111dc8f40>]}
[0m11:51:30.460859 [info ] [Thread-4  ]: 4 of 6 OK created sql table model dbt_warehouse.total_unique_users ............. [[32mSELECT 1[0m in 5.09s]
[0m11:51:30.463458 [debug] [Thread-4  ]: Finished running node model.maker_warehouse.total_unique_users
[0m11:51:30.470014 [debug] [MainThread]: Using postgres connection "master"
[0m11:51:30.471364 [debug] [MainThread]: On master: BEGIN
[0m11:51:30.472584 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m11:51:30.526971 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m11:51:30.528268 [debug] [MainThread]: On master: COMMIT
[0m11:51:30.528944 [debug] [MainThread]: Using postgres connection "master"
[0m11:51:30.529903 [debug] [MainThread]: On master: COMMIT
[0m11:51:30.538684 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m11:51:30.539801 [debug] [MainThread]: On master: Close
[0m11:51:30.541836 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:51:30.542489 [debug] [MainThread]: Connection 'model.maker_warehouse.all_movies' was properly closed.
[0m11:51:30.543155 [debug] [MainThread]: Connection 'model.maker_warehouse.movies' was properly closed.
[0m11:51:30.543953 [debug] [MainThread]: Connection 'model.maker_warehouse.total_viewing_time' was properly closed.
[0m11:51:30.546112 [debug] [MainThread]: Connection 'model.maker_warehouse.total_unique_users' was properly closed.
[0m11:51:30.547094 [info ] [MainThread]: 
[0m11:51:30.548409 [info ] [MainThread]: Finished running 6 table models in 0 hours 0 minutes and 5.95 seconds (5.95s).
[0m11:51:30.556059 [debug] [MainThread]: Command end result
[0m11:51:30.580023 [info ] [MainThread]: 
[0m11:51:30.586668 [info ] [MainThread]: [32mCompleted successfully[0m
[0m11:51:30.588033 [info ] [MainThread]: 
[0m11:51:30.592753 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=0 SKIP=0 TOTAL=6
[0m11:51:30.594754 [debug] [MainThread]: Command `dbt run` succeeded at 11:51:30.594426 after 6.86 seconds
[0m11:51:30.596051 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1103d97f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1119f6fd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1119f6c10>]}
[0m11:51:30.599557 [debug] [MainThread]: Flushing usage events
[0m11:53:02.653436 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d155f40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e4efa30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e4e6700>]}


============================== 11:53:02.664133 | 7fe4792c-bc62-4dd3-845b-c08a1eea23db ==============================
[0m11:53:02.664133 [info ] [MainThread]: Running with dbt=1.5.4
[0m11:53:02.666391 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/denisechan/Documents/Makers/Data_Engineering/Week_6/dbt_warehouse', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/Users/denisechan/Documents/Makers/Data_Engineering/Week_6/dbt_warehouse/logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'send_anonymous_usage_stats': 'True'}
[0m11:53:02.889061 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '7fe4792c-bc62-4dd3-845b-c08a1eea23db', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e4e6700>]}
[0m11:53:02.938557 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '7fe4792c-bc62-4dd3-845b-c08a1eea23db', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e754730>]}
[0m11:53:02.941638 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m11:53:02.999685 [debug] [MainThread]: checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, vars: {}, profile: , target: , version: 1.5.4
[0m11:53:03.202299 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
[0m11:53:03.203199 [debug] [MainThread]: Partial parsing: added file: maker_warehouse://models/facts/user_engagement.sql
[0m11:53:03.274127 [debug] [MainThread]: 1699: static parser successfully parsed facts/user_engagement.sql
[0m11:53:03.318950 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '7fe4792c-bc62-4dd3-845b-c08a1eea23db', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e9db0d0>]}
[0m11:53:03.332307 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '7fe4792c-bc62-4dd3-845b-c08a1eea23db', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e9618b0>]}
[0m11:53:03.333583 [info ] [MainThread]: Found 7 models, 0 tests, 0 snapshots, 0 analyses, 307 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics, 0 groups
[0m11:53:03.335073 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7fe4792c-bc62-4dd3-845b-c08a1eea23db', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e961e20>]}
[0m11:53:03.337766 [info ] [MainThread]: 
[0m11:53:03.340966 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m11:53:03.343454 [debug] [ThreadPool]: Acquiring new postgres connection 'list_mydb'
[0m11:53:03.367635 [debug] [ThreadPool]: Using postgres connection "list_mydb"
[0m11:53:03.369315 [debug] [ThreadPool]: On list_mydb: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "connection_name": "list_mydb"} */

    select distinct nspname from pg_namespace
  
[0m11:53:03.370008 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:53:03.580431 [debug] [ThreadPool]: SQL status: SELECT 5 in 0.0 seconds
[0m11:53:03.583927 [debug] [ThreadPool]: On list_mydb: Close
[0m11:53:03.588797 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_mydb, now list_mydb_dbt_warehouse)
[0m11:53:03.606751 [debug] [ThreadPool]: Using postgres connection "list_mydb_dbt_warehouse"
[0m11:53:03.607682 [debug] [ThreadPool]: On list_mydb_dbt_warehouse: BEGIN
[0m11:53:03.609316 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:53:03.646316 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m11:53:03.647638 [debug] [ThreadPool]: Using postgres connection "list_mydb_dbt_warehouse"
[0m11:53:03.648566 [debug] [ThreadPool]: On list_mydb_dbt_warehouse: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "connection_name": "list_mydb_dbt_warehouse"} */
select
      'mydb' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_warehouse'
    union all
    select
      'mydb' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_warehouse'
  
[0m11:53:03.670007 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.0 seconds
[0m11:53:03.672442 [debug] [ThreadPool]: On list_mydb_dbt_warehouse: ROLLBACK
[0m11:53:03.677967 [debug] [ThreadPool]: On list_mydb_dbt_warehouse: Close
[0m11:53:03.697266 [debug] [MainThread]: Using postgres connection "master"
[0m11:53:03.697993 [debug] [MainThread]: On master: BEGIN
[0m11:53:03.698466 [debug] [MainThread]: Opening a new connection, currently in state init
[0m11:53:03.728884 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m11:53:03.729737 [debug] [MainThread]: Using postgres connection "master"
[0m11:53:03.730526 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m11:53:03.757649 [debug] [MainThread]: SQL status: SELECT 5 in 0.0 seconds
[0m11:53:03.759945 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7fe4792c-bc62-4dd3-845b-c08a1eea23db', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e9c6130>]}
[0m11:53:03.760677 [debug] [MainThread]: On master: ROLLBACK
[0m11:53:03.762716 [debug] [MainThread]: Using postgres connection "master"
[0m11:53:03.763439 [debug] [MainThread]: On master: BEGIN
[0m11:53:03.771418 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m11:53:03.772239 [debug] [MainThread]: On master: COMMIT
[0m11:53:03.773829 [debug] [MainThread]: Using postgres connection "master"
[0m11:53:03.775424 [debug] [MainThread]: On master: COMMIT
[0m11:53:03.778962 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m11:53:03.779574 [debug] [MainThread]: On master: Close
[0m11:53:03.780925 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m11:53:03.782671 [info ] [MainThread]: 
[0m11:53:03.797046 [debug] [Thread-1  ]: Began running node model.maker_warehouse.avg_viewing_time
[0m11:53:03.798118 [debug] [Thread-2  ]: Began running node model.maker_warehouse.movies
[0m11:53:03.798886 [debug] [Thread-3  ]: Began running node model.maker_warehouse.no_of_viewings
[0m11:53:03.799579 [debug] [Thread-4  ]: Began running node model.maker_warehouse.total_unique_users
[0m11:53:03.800356 [info ] [Thread-1  ]: 1 of 7 START sql table model dbt_warehouse.avg_viewing_time .................... [RUN]
[0m11:53:03.801366 [info ] [Thread-2  ]: 2 of 7 START sql table model dbt_warehouse.movies .............................. [RUN]
[0m11:53:03.802393 [info ] [Thread-3  ]: 3 of 7 START sql table model dbt_warehouse.no_of_viewings ...................... [RUN]
[0m11:53:03.803523 [info ] [Thread-4  ]: 4 of 7 START sql table model dbt_warehouse.total_unique_users .................. [RUN]
[0m11:53:03.805999 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_mydb_dbt_warehouse, now model.maker_warehouse.avg_viewing_time)
[0m11:53:03.807704 [debug] [Thread-2  ]: Acquiring new postgres connection 'model.maker_warehouse.movies'
[0m11:53:03.809697 [debug] [Thread-3  ]: Acquiring new postgres connection 'model.maker_warehouse.no_of_viewings'
[0m11:53:03.811086 [debug] [Thread-4  ]: Acquiring new postgres connection 'model.maker_warehouse.total_unique_users'
[0m11:53:03.813989 [debug] [Thread-1  ]: Began compiling node model.maker_warehouse.avg_viewing_time
[0m11:53:03.815094 [debug] [Thread-2  ]: Began compiling node model.maker_warehouse.movies
[0m11:53:03.816091 [debug] [Thread-3  ]: Began compiling node model.maker_warehouse.no_of_viewings
[0m11:53:03.817060 [debug] [Thread-4  ]: Began compiling node model.maker_warehouse.total_unique_users
[0m11:53:03.839281 [debug] [Thread-1  ]: Writing injected SQL for node "model.maker_warehouse.avg_viewing_time"
[0m11:53:03.851032 [debug] [Thread-2  ]: Writing injected SQL for node "model.maker_warehouse.movies"
[0m11:53:03.860370 [debug] [Thread-3  ]: Writing injected SQL for node "model.maker_warehouse.no_of_viewings"
[0m11:53:03.870676 [debug] [Thread-4  ]: Writing injected SQL for node "model.maker_warehouse.total_unique_users"
[0m11:53:03.912187 [debug] [Thread-1  ]: Timing info for model.maker_warehouse.avg_viewing_time (compile): 11:53:03.817550 => 11:53:03.909967
[0m11:53:03.923424 [debug] [Thread-1  ]: Began executing node model.maker_warehouse.avg_viewing_time
[0m11:53:03.919311 [debug] [Thread-2  ]: Timing info for model.maker_warehouse.movies (compile): 11:53:03.839877 => 11:53:03.917743
[0m11:53:03.951314 [debug] [Thread-4  ]: Timing info for model.maker_warehouse.total_unique_users (compile): 11:53:03.861680 => 11:53:03.950629
[0m11:53:03.958839 [debug] [Thread-2  ]: Began executing node model.maker_warehouse.movies
[0m11:53:03.965340 [debug] [Thread-3  ]: Timing info for model.maker_warehouse.no_of_viewings (compile): 11:53:03.852160 => 11:53:03.964717
[0m11:53:03.990575 [debug] [Thread-4  ]: Began executing node model.maker_warehouse.total_unique_users
[0m11:53:04.078290 [debug] [Thread-2  ]: Writing runtime sql for node "model.maker_warehouse.movies"
[0m11:53:04.074042 [debug] [Thread-1  ]: Writing runtime sql for node "model.maker_warehouse.avg_viewing_time"
[0m11:53:04.078973 [debug] [Thread-3  ]: Began executing node model.maker_warehouse.no_of_viewings
[0m11:53:04.093146 [debug] [Thread-4  ]: Writing runtime sql for node "model.maker_warehouse.total_unique_users"
[0m11:53:04.103354 [debug] [Thread-3  ]: Writing runtime sql for node "model.maker_warehouse.no_of_viewings"
[0m11:53:04.105585 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.movies"
[0m11:53:04.107913 [debug] [Thread-2  ]: On model.maker_warehouse.movies: BEGIN
[0m11:53:04.109272 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.total_unique_users"
[0m11:53:04.110306 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.avg_viewing_time"
[0m11:53:04.111185 [debug] [Thread-2  ]: Opening a new connection, currently in state init
[0m11:53:04.113552 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.no_of_viewings"
[0m11:53:04.114537 [debug] [Thread-4  ]: On model.maker_warehouse.total_unique_users: BEGIN
[0m11:53:04.115256 [debug] [Thread-1  ]: On model.maker_warehouse.avg_viewing_time: BEGIN
[0m11:53:04.116158 [debug] [Thread-3  ]: On model.maker_warehouse.no_of_viewings: BEGIN
[0m11:53:04.117225 [debug] [Thread-4  ]: Opening a new connection, currently in state init
[0m11:53:04.120767 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m11:53:04.121744 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m11:53:04.173219 [debug] [Thread-4  ]: SQL status: BEGIN in 0.0 seconds
[0m11:53:04.175151 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.total_unique_users"
[0m11:53:04.176292 [debug] [Thread-4  ]: On model.maker_warehouse.total_unique_users: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_unique_users"} */

  
    

  create  table "mydb"."dbt_warehouse"."total_unique_users__dbt_tmp"
  
  
    as
  
  (
    
SELECT 
COUNT(DISTINCT(user_id)) AS total_unique_users
FROM mydb.public.raw_netflix
  );
  
[0m11:53:04.185839 [debug] [Thread-2  ]: SQL status: BEGIN in 0.0 seconds
[0m11:53:04.186824 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.movies"
[0m11:53:04.188448 [debug] [Thread-2  ]: On model.maker_warehouse.movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.movies"} */

  
    

  create  table "mydb"."dbt_warehouse"."movies__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    DISTINCT
    title,
    genres,
    release_date,
    movie_id
FROM mydb.public.raw_netflix
  );
  
[0m11:53:04.200582 [debug] [Thread-3  ]: SQL status: BEGIN in 0.0 seconds
[0m11:53:04.201480 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.no_of_viewings"
[0m11:53:04.202714 [debug] [Thread-3  ]: On model.maker_warehouse.no_of_viewings: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.no_of_viewings"} */

  
    

  create  table "mydb"."dbt_warehouse"."no_of_viewings__dbt_tmp"
  
  
    as
  
  (
    
SELECT
  title,
  COUNT(*) as total_views
FROM mydb.public.raw_netflix
GROUP BY title
ORDER BY total_views DESC
  );
  
[0m11:53:04.206737 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
[0m11:53:04.208386 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.avg_viewing_time"
[0m11:53:04.210759 [debug] [Thread-1  ]: On model.maker_warehouse.avg_viewing_time: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.avg_viewing_time"} */

  
    

  create  table "mydb"."dbt_warehouse"."avg_viewing_time__dbt_tmp"
  
  
    as
  
  (
    
SELECT
title,
ROUND(CAST(AVG(duration) AS NUMERIC), 2) as avg_duration
FROM mydb.public.raw_netflix
GROUP BY title
ORDER BY avg_duration DESC
  );
  
[0m11:53:07.451255 [debug] [Thread-1  ]: SQL status: SELECT 7925 in 3.0 seconds
[0m11:53:07.475826 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.avg_viewing_time"
[0m11:53:07.477372 [debug] [Thread-1  ]: On model.maker_warehouse.avg_viewing_time: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.avg_viewing_time"} */
alter table "mydb"."dbt_warehouse"."avg_viewing_time" rename to "avg_viewing_time__dbt_backup"
[0m11:53:07.481709 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:53:07.492185 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.avg_viewing_time"
[0m11:53:07.493622 [debug] [Thread-3  ]: SQL status: SELECT 7925 in 3.0 seconds
[0m11:53:07.494783 [debug] [Thread-1  ]: On model.maker_warehouse.avg_viewing_time: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.avg_viewing_time"} */
alter table "mydb"."dbt_warehouse"."avg_viewing_time__dbt_tmp" rename to "avg_viewing_time"
[0m11:53:07.504041 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.no_of_viewings"
[0m11:53:07.505370 [debug] [Thread-3  ]: On model.maker_warehouse.no_of_viewings: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.no_of_viewings"} */
alter table "mydb"."dbt_warehouse"."no_of_viewings" rename to "no_of_viewings__dbt_backup"
[0m11:53:07.564527 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:53:07.571257 [debug] [Thread-3  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:53:07.604398 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.no_of_viewings"
[0m11:53:07.623152 [debug] [Thread-3  ]: On model.maker_warehouse.no_of_viewings: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.no_of_viewings"} */
alter table "mydb"."dbt_warehouse"."no_of_viewings__dbt_tmp" rename to "no_of_viewings"
[0m11:53:07.647440 [debug] [Thread-1  ]: On model.maker_warehouse.avg_viewing_time: COMMIT
[0m11:53:07.648866 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.avg_viewing_time"
[0m11:53:07.650035 [debug] [Thread-1  ]: On model.maker_warehouse.avg_viewing_time: COMMIT
[0m11:53:07.652952 [debug] [Thread-3  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:53:07.661175 [debug] [Thread-3  ]: On model.maker_warehouse.no_of_viewings: COMMIT
[0m11:53:07.662210 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.no_of_viewings"
[0m11:53:07.663479 [debug] [Thread-3  ]: On model.maker_warehouse.no_of_viewings: COMMIT
[0m11:53:07.664482 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
[0m11:53:07.673604 [debug] [Thread-3  ]: SQL status: COMMIT in 0.0 seconds
[0m11:53:07.685916 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.avg_viewing_time"
[0m11:53:07.699691 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.no_of_viewings"
[0m11:53:07.700628 [debug] [Thread-1  ]: On model.maker_warehouse.avg_viewing_time: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.avg_viewing_time"} */
drop table if exists "mydb"."dbt_warehouse"."avg_viewing_time__dbt_backup" cascade
[0m11:53:07.701806 [debug] [Thread-3  ]: On model.maker_warehouse.no_of_viewings: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.no_of_viewings"} */
drop table if exists "mydb"."dbt_warehouse"."no_of_viewings__dbt_backup" cascade
[0m11:53:07.728510 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
[0m11:53:07.733387 [debug] [Thread-1  ]: Timing info for model.maker_warehouse.avg_viewing_time (execute): 11:53:03.930280 => 11:53:07.732473
[0m11:53:07.735158 [debug] [Thread-1  ]: On model.maker_warehouse.avg_viewing_time: Close
[0m11:53:07.736351 [debug] [Thread-3  ]: SQL status: DROP TABLE in 0.0 seconds
[0m11:53:07.739128 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7fe4792c-bc62-4dd3-845b-c08a1eea23db', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10eb7dfd0>]}
[0m11:53:07.744588 [debug] [Thread-3  ]: Timing info for model.maker_warehouse.no_of_viewings (execute): 11:53:04.094579 => 11:53:07.743908
[0m11:53:07.754255 [debug] [Thread-3  ]: On model.maker_warehouse.no_of_viewings: Close
[0m11:53:07.750188 [info ] [Thread-1  ]: 1 of 7 OK created sql table model dbt_warehouse.avg_viewing_time ............... [[32mSELECT 7925[0m in 3.93s]
[0m11:53:07.762132 [debug] [Thread-1  ]: Finished running node model.maker_warehouse.avg_viewing_time
[0m11:53:07.763383 [debug] [Thread-1  ]: Began running node model.maker_warehouse.total_viewing_time
[0m11:53:07.764598 [info ] [Thread-1  ]: 5 of 7 START sql table model dbt_warehouse.total_viewing_time .................. [RUN]
[0m11:53:07.758958 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7fe4792c-bc62-4dd3-845b-c08a1eea23db', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ea301f0>]}
[0m11:53:07.772052 [info ] [Thread-3  ]: 3 of 7 OK created sql table model dbt_warehouse.no_of_viewings ................. [[32mSELECT 7925[0m in 3.95s]
[0m11:53:07.767079 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.maker_warehouse.avg_viewing_time, now model.maker_warehouse.total_viewing_time)
[0m11:53:07.781356 [debug] [Thread-1  ]: Began compiling node model.maker_warehouse.total_viewing_time
[0m11:53:07.775585 [debug] [Thread-3  ]: Finished running node model.maker_warehouse.no_of_viewings
[0m11:53:07.805757 [debug] [Thread-3  ]: Began running node model.maker_warehouse.user_engagement
[0m11:53:07.807522 [info ] [Thread-3  ]: 6 of 7 START sql table model dbt_warehouse.user_engagement ..................... [RUN]
[0m11:53:07.811261 [debug] [Thread-3  ]: Re-using an available connection from the pool (formerly model.maker_warehouse.no_of_viewings, now model.maker_warehouse.user_engagement)
[0m11:53:07.812672 [debug] [Thread-3  ]: Began compiling node model.maker_warehouse.user_engagement
[0m11:53:07.844079 [debug] [Thread-1  ]: Writing injected SQL for node "model.maker_warehouse.total_viewing_time"
[0m11:53:07.848021 [debug] [Thread-3  ]: Writing injected SQL for node "model.maker_warehouse.user_engagement"
[0m11:53:07.850128 [debug] [Thread-3  ]: Timing info for model.maker_warehouse.user_engagement (compile): 11:53:07.813818 => 11:53:07.849437
[0m11:53:07.851241 [debug] [Thread-3  ]: Began executing node model.maker_warehouse.user_engagement
[0m11:53:07.867171 [debug] [Thread-1  ]: Timing info for model.maker_warehouse.total_viewing_time (compile): 11:53:07.782116 => 11:53:07.866169
[0m11:53:07.870790 [debug] [Thread-1  ]: Began executing node model.maker_warehouse.total_viewing_time
[0m11:53:07.905867 [debug] [Thread-3  ]: Writing runtime sql for node "model.maker_warehouse.user_engagement"
[0m11:53:07.917989 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.user_engagement"
[0m11:53:07.919139 [debug] [Thread-3  ]: On model.maker_warehouse.user_engagement: BEGIN
[0m11:53:07.920120 [debug] [Thread-3  ]: Opening a new connection, currently in state closed
[0m11:53:07.939263 [debug] [Thread-1  ]: Writing runtime sql for node "model.maker_warehouse.total_viewing_time"
[0m11:53:07.946275 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.total_viewing_time"
[0m11:53:07.947448 [debug] [Thread-1  ]: On model.maker_warehouse.total_viewing_time: BEGIN
[0m11:53:07.948705 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m11:53:08.028512 [debug] [Thread-3  ]: SQL status: BEGIN in 0.0 seconds
[0m11:53:08.029868 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.user_engagement"
[0m11:53:08.030919 [debug] [Thread-3  ]: On model.maker_warehouse.user_engagement: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.user_engagement"} */

  
    

  create  table "mydb"."dbt_warehouse"."user_engagement__dbt_tmp"
  
  
    as
  
  (
    
SELECT 
DISTINCT(user_id),
COUNT(DISTINCT(title)) AS total_titles,
SUM(duration) AS total_duration
FROM mydb.public.raw_netflix
GROUP BY user_id
  );
  
[0m11:53:08.060613 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
[0m11:53:08.062133 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.total_viewing_time"
[0m11:53:08.063257 [debug] [Thread-1  ]: On model.maker_warehouse.total_viewing_time: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_viewing_time"} */

  
    

  create  table "mydb"."dbt_warehouse"."total_viewing_time__dbt_tmp"
  
  
    as
  
  (
    
SELECT
title,
SUM(duration) as total_duration
FROM mydb.public.raw_netflix
GROUP BY title
ORDER BY total_duration DESC
  );
  
[0m11:53:08.950032 [debug] [Thread-1  ]: SQL status: SELECT 7925 in 1.0 seconds
[0m11:53:08.962195 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.total_viewing_time"
[0m11:53:08.965044 [debug] [Thread-1  ]: On model.maker_warehouse.total_viewing_time: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_viewing_time"} */
alter table "mydb"."dbt_warehouse"."total_viewing_time" rename to "total_viewing_time__dbt_backup"
[0m11:53:08.970693 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:53:08.983779 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.total_viewing_time"
[0m11:53:08.984673 [debug] [Thread-1  ]: On model.maker_warehouse.total_viewing_time: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_viewing_time"} */
alter table "mydb"."dbt_warehouse"."total_viewing_time__dbt_tmp" rename to "total_viewing_time"
[0m11:53:08.988471 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:53:09.000516 [debug] [Thread-1  ]: On model.maker_warehouse.total_viewing_time: COMMIT
[0m11:53:09.002921 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.total_viewing_time"
[0m11:53:09.004195 [debug] [Thread-1  ]: On model.maker_warehouse.total_viewing_time: COMMIT
[0m11:53:09.015977 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
[0m11:53:09.029661 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.total_viewing_time"
[0m11:53:09.030435 [debug] [Thread-1  ]: On model.maker_warehouse.total_viewing_time: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_viewing_time"} */
drop table if exists "mydb"."dbt_warehouse"."total_viewing_time__dbt_backup" cascade
[0m11:53:09.061555 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
[0m11:53:09.066922 [debug] [Thread-1  ]: Timing info for model.maker_warehouse.total_viewing_time (execute): 11:53:07.871630 => 11:53:09.066381
[0m11:53:09.068132 [debug] [Thread-1  ]: On model.maker_warehouse.total_viewing_time: Close
[0m11:53:09.070851 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7fe4792c-bc62-4dd3-845b-c08a1eea23db', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10eb19130>]}
[0m11:53:09.073005 [info ] [Thread-1  ]: 5 of 7 OK created sql table model dbt_warehouse.total_viewing_time ............. [[32mSELECT 7925[0m in 1.31s]
[0m11:53:09.079218 [debug] [Thread-1  ]: Finished running node model.maker_warehouse.total_viewing_time
[0m11:53:10.323107 [debug] [Thread-2  ]: SQL status: SELECT 8472 in 6.0 seconds
[0m11:53:10.332010 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.movies"
[0m11:53:10.333347 [debug] [Thread-2  ]: On model.maker_warehouse.movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.movies"} */
alter table "mydb"."dbt_warehouse"."movies" rename to "movies__dbt_backup"
[0m11:53:10.338068 [debug] [Thread-2  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:53:10.345741 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.movies"
[0m11:53:10.346525 [debug] [Thread-2  ]: On model.maker_warehouse.movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.movies"} */
alter table "mydb"."dbt_warehouse"."movies__dbt_tmp" rename to "movies"
[0m11:53:10.349288 [debug] [Thread-2  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:53:10.357984 [debug] [Thread-2  ]: On model.maker_warehouse.movies: COMMIT
[0m11:53:10.358708 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.movies"
[0m11:53:10.359409 [debug] [Thread-2  ]: On model.maker_warehouse.movies: COMMIT
[0m11:53:10.368947 [debug] [Thread-2  ]: SQL status: COMMIT in 0.0 seconds
[0m11:53:10.376168 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.movies"
[0m11:53:10.377056 [debug] [Thread-2  ]: On model.maker_warehouse.movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.movies"} */
drop table if exists "mydb"."dbt_warehouse"."movies__dbt_backup" cascade
[0m11:53:10.387150 [debug] [Thread-2  ]: SQL status: DROP TABLE in 0.0 seconds
[0m11:53:10.390733 [debug] [Thread-2  ]: Timing info for model.maker_warehouse.movies (execute): 11:53:04.029374 => 11:53:10.389905
[0m11:53:10.392201 [debug] [Thread-2  ]: On model.maker_warehouse.movies: Close
[0m11:53:10.394288 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7fe4792c-bc62-4dd3-845b-c08a1eea23db', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10eb791c0>]}
[0m11:53:10.396491 [info ] [Thread-2  ]: 2 of 7 OK created sql table model dbt_warehouse.movies ......................... [[32mSELECT 8472[0m in 6.59s]
[0m11:53:10.398563 [debug] [Thread-2  ]: Finished running node model.maker_warehouse.movies
[0m11:53:10.400040 [debug] [Thread-1  ]: Began running node model.maker_warehouse.all_movies
[0m11:53:10.401360 [info ] [Thread-1  ]: 7 of 7 START sql table model dbt_warehouse.all_movies .......................... [RUN]
[0m11:53:10.403263 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.maker_warehouse.total_viewing_time, now model.maker_warehouse.all_movies)
[0m11:53:10.404075 [debug] [Thread-1  ]: Began compiling node model.maker_warehouse.all_movies
[0m11:53:10.411951 [debug] [Thread-1  ]: Writing injected SQL for node "model.maker_warehouse.all_movies"
[0m11:53:10.415019 [debug] [Thread-1  ]: Timing info for model.maker_warehouse.all_movies (compile): 11:53:10.404785 => 11:53:10.414200
[0m11:53:10.416116 [debug] [Thread-1  ]: Began executing node model.maker_warehouse.all_movies
[0m11:53:10.433428 [debug] [Thread-1  ]: Writing runtime sql for node "model.maker_warehouse.all_movies"
[0m11:53:10.435750 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.all_movies"
[0m11:53:10.436930 [debug] [Thread-1  ]: On model.maker_warehouse.all_movies: BEGIN
[0m11:53:10.438116 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m11:53:10.507043 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
[0m11:53:10.508688 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.all_movies"
[0m11:53:10.509898 [debug] [Thread-1  ]: On model.maker_warehouse.all_movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.all_movies"} */

  
    

  create  table "mydb"."dbt_warehouse"."all_movies__dbt_tmp"
  
  
    as
  
  (
    
  
SELECT
*
FROM "mydb"."dbt_warehouse"."movies"
  );
  
[0m11:53:10.562609 [debug] [Thread-1  ]: SQL status: SELECT 8472 in 0.0 seconds
[0m11:53:10.570273 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.all_movies"
[0m11:53:10.571364 [debug] [Thread-1  ]: On model.maker_warehouse.all_movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.all_movies"} */
alter table "mydb"."dbt_warehouse"."all_movies" rename to "all_movies__dbt_backup"
[0m11:53:10.736800 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:53:10.746592 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.all_movies"
[0m11:53:10.748191 [debug] [Thread-1  ]: On model.maker_warehouse.all_movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.all_movies"} */
alter table "mydb"."dbt_warehouse"."all_movies__dbt_tmp" rename to "all_movies"
[0m11:53:10.754313 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:53:10.762084 [debug] [Thread-1  ]: On model.maker_warehouse.all_movies: COMMIT
[0m11:53:10.763153 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.all_movies"
[0m11:53:10.763775 [debug] [Thread-1  ]: On model.maker_warehouse.all_movies: COMMIT
[0m11:53:10.770809 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
[0m11:53:10.780787 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.all_movies"
[0m11:53:10.781874 [debug] [Thread-1  ]: On model.maker_warehouse.all_movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.all_movies"} */
drop table if exists "mydb"."dbt_warehouse"."all_movies__dbt_backup" cascade
[0m11:53:10.809938 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
[0m11:53:10.814740 [debug] [Thread-1  ]: Timing info for model.maker_warehouse.all_movies (execute): 11:53:10.416882 => 11:53:10.814032
[0m11:53:10.815888 [debug] [Thread-1  ]: On model.maker_warehouse.all_movies: Close
[0m11:53:10.817619 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7fe4792c-bc62-4dd3-845b-c08a1eea23db', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10eaf6700>]}
[0m11:53:10.818574 [info ] [Thread-1  ]: 7 of 7 OK created sql table model dbt_warehouse.all_movies ..................... [[32mSELECT 8472[0m in 0.41s]
[0m11:53:10.819657 [debug] [Thread-1  ]: Finished running node model.maker_warehouse.all_movies
[0m11:53:13.028882 [debug] [Thread-4  ]: SQL status: SELECT 1 in 9.0 seconds
[0m11:53:13.037349 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.total_unique_users"
[0m11:53:13.038064 [debug] [Thread-4  ]: On model.maker_warehouse.total_unique_users: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_unique_users"} */
alter table "mydb"."dbt_warehouse"."total_unique_users" rename to "total_unique_users__dbt_backup"
[0m11:53:13.043711 [debug] [Thread-4  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:53:13.051144 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.total_unique_users"
[0m11:53:13.051831 [debug] [Thread-4  ]: On model.maker_warehouse.total_unique_users: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_unique_users"} */
alter table "mydb"."dbt_warehouse"."total_unique_users__dbt_tmp" rename to "total_unique_users"
[0m11:53:13.055583 [debug] [Thread-4  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:53:13.060990 [debug] [Thread-4  ]: On model.maker_warehouse.total_unique_users: COMMIT
[0m11:53:13.061882 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.total_unique_users"
[0m11:53:13.062500 [debug] [Thread-4  ]: On model.maker_warehouse.total_unique_users: COMMIT
[0m11:53:13.066669 [debug] [Thread-4  ]: SQL status: COMMIT in 0.0 seconds
[0m11:53:13.075902 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.total_unique_users"
[0m11:53:13.076663 [debug] [Thread-4  ]: On model.maker_warehouse.total_unique_users: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_unique_users"} */
drop table if exists "mydb"."dbt_warehouse"."total_unique_users__dbt_backup" cascade
[0m11:53:13.087218 [debug] [Thread-4  ]: SQL status: DROP TABLE in 0.0 seconds
[0m11:53:13.090559 [debug] [Thread-4  ]: Timing info for model.maker_warehouse.total_unique_users (execute): 11:53:04.079425 => 11:53:13.089870
[0m11:53:13.091469 [debug] [Thread-4  ]: On model.maker_warehouse.total_unique_users: Close
[0m11:53:13.093683 [debug] [Thread-4  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7fe4792c-bc62-4dd3-845b-c08a1eea23db', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10eba7850>]}
[0m11:53:13.094957 [info ] [Thread-4  ]: 4 of 7 OK created sql table model dbt_warehouse.total_unique_users ............. [[32mSELECT 1[0m in 9.28s]
[0m11:53:13.097188 [debug] [Thread-4  ]: Finished running node model.maker_warehouse.total_unique_users
[0m11:53:17.269498 [debug] [Thread-3  ]: SQL status: SELECT 161918 in 9.0 seconds
[0m11:53:17.281321 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.user_engagement"
[0m11:53:17.282792 [debug] [Thread-3  ]: On model.maker_warehouse.user_engagement: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.user_engagement"} */
alter table "mydb"."dbt_warehouse"."user_engagement__dbt_tmp" rename to "user_engagement"
[0m11:53:17.291211 [debug] [Thread-3  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:53:17.299704 [debug] [Thread-3  ]: On model.maker_warehouse.user_engagement: COMMIT
[0m11:53:17.300814 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.user_engagement"
[0m11:53:17.302003 [debug] [Thread-3  ]: On model.maker_warehouse.user_engagement: COMMIT
[0m11:53:17.309857 [debug] [Thread-3  ]: SQL status: COMMIT in 0.0 seconds
[0m11:53:17.320170 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.user_engagement"
[0m11:53:17.322346 [debug] [Thread-3  ]: On model.maker_warehouse.user_engagement: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.user_engagement"} */
drop table if exists "mydb"."dbt_warehouse"."user_engagement__dbt_backup" cascade
[0m11:53:17.338945 [debug] [Thread-3  ]: SQL status: DROP TABLE in 0.0 seconds
[0m11:53:17.345777 [debug] [Thread-3  ]: Timing info for model.maker_warehouse.user_engagement (execute): 11:53:07.852019 => 11:53:17.345258
[0m11:53:17.346835 [debug] [Thread-3  ]: On model.maker_warehouse.user_engagement: Close
[0m11:53:17.349087 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7fe4792c-bc62-4dd3-845b-c08a1eea23db', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e9f1b80>]}
[0m11:53:17.351937 [info ] [Thread-3  ]: 6 of 7 OK created sql table model dbt_warehouse.user_engagement ................ [[32mSELECT 161918[0m in 9.54s]
[0m11:53:17.355848 [debug] [Thread-3  ]: Finished running node model.maker_warehouse.user_engagement
[0m11:53:17.363404 [debug] [MainThread]: Using postgres connection "master"
[0m11:53:17.364570 [debug] [MainThread]: On master: BEGIN
[0m11:53:17.366262 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m11:53:17.496055 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m11:53:17.497321 [debug] [MainThread]: On master: COMMIT
[0m11:53:17.498308 [debug] [MainThread]: Using postgres connection "master"
[0m11:53:17.499231 [debug] [MainThread]: On master: COMMIT
[0m11:53:17.502020 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m11:53:17.502983 [debug] [MainThread]: On master: Close
[0m11:53:17.505222 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:53:17.506318 [debug] [MainThread]: Connection 'model.maker_warehouse.all_movies' was properly closed.
[0m11:53:17.507303 [debug] [MainThread]: Connection 'model.maker_warehouse.movies' was properly closed.
[0m11:53:17.508929 [debug] [MainThread]: Connection 'model.maker_warehouse.user_engagement' was properly closed.
[0m11:53:17.509988 [debug] [MainThread]: Connection 'model.maker_warehouse.total_unique_users' was properly closed.
[0m11:53:17.511177 [info ] [MainThread]: 
[0m11:53:17.513102 [info ] [MainThread]: Finished running 7 table models in 0 hours 0 minutes and 14.17 seconds (14.17s).
[0m11:53:17.518564 [debug] [MainThread]: Command end result
[0m11:53:17.548991 [info ] [MainThread]: 
[0m11:53:17.551150 [info ] [MainThread]: [32mCompleted successfully[0m
[0m11:53:17.553638 [info ] [MainThread]: 
[0m11:53:17.555733 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=0 SKIP=0 TOTAL=7
[0m11:53:17.579422 [debug] [MainThread]: Command `dbt run` succeeded at 11:53:17.578945 after 14.98 seconds
[0m11:53:17.581717 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d155f40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e96f040>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e6c7220>]}
[0m11:53:17.582923 [debug] [MainThread]: Flushing usage events
[0m12:03:31.541131 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106bef550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107f8c2b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104783790>]}


============================== 12:03:31.554595 | 6c862daa-1da0-46f2-abda-4b7643b9caad ==============================
[0m12:03:31.554595 [info ] [MainThread]: Running with dbt=1.5.4
[0m12:03:31.556347 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/denisechan/Documents/Makers/Data_Engineering/Week_6/dbt_warehouse', 'version_check': 'True', 'warn_error': 'None', 'log_path': '/Users/denisechan/Documents/Makers/Data_Engineering/Week_6/dbt_warehouse/logs', 'debug': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'send_anonymous_usage_stats': 'True'}
[0m12:03:32.186243 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '6c862daa-1da0-46f2-abda-4b7643b9caad', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107f8c9d0>]}
[0m12:03:32.361270 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '6c862daa-1da0-46f2-abda-4b7643b9caad', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1081ef6d0>]}
[0m12:03:32.363053 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m12:03:32.413940 [debug] [MainThread]: checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, vars: {}, profile: , target: , version: 1.5.4
[0m12:03:32.656354 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
[0m12:03:32.657208 [debug] [MainThread]: Partial parsing: added file: maker_warehouse://models/summary/total_viewings_year_month.sql
[0m12:03:32.715472 [debug] [MainThread]: 1699: static parser successfully parsed summary/total_viewings_year_month.sql
[0m12:03:32.762564 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '6c862daa-1da0-46f2-abda-4b7643b9caad', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1084ae0d0>]}
[0m12:03:32.778047 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '6c862daa-1da0-46f2-abda-4b7643b9caad', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1083fdb50>]}
[0m12:03:32.779414 [info ] [MainThread]: Found 8 models, 0 tests, 0 snapshots, 0 analyses, 307 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics, 0 groups
[0m12:03:32.781004 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6c862daa-1da0-46f2-abda-4b7643b9caad', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1083fdf40>]}
[0m12:03:32.785895 [info ] [MainThread]: 
[0m12:03:32.787661 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m12:03:32.789752 [debug] [ThreadPool]: Acquiring new postgres connection 'list_mydb'
[0m12:03:32.810094 [debug] [ThreadPool]: Using postgres connection "list_mydb"
[0m12:03:32.810832 [debug] [ThreadPool]: On list_mydb: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "connection_name": "list_mydb"} */

    select distinct nspname from pg_namespace
  
[0m12:03:32.811389 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:03:32.994994 [debug] [ThreadPool]: SQL status: SELECT 5 in 0.0 seconds
[0m12:03:32.998098 [debug] [ThreadPool]: On list_mydb: Close
[0m12:03:33.004289 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_mydb, now list_mydb_dbt_warehouse)
[0m12:03:33.020676 [debug] [ThreadPool]: Using postgres connection "list_mydb_dbt_warehouse"
[0m12:03:33.021277 [debug] [ThreadPool]: On list_mydb_dbt_warehouse: BEGIN
[0m12:03:33.021892 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:03:33.050468 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m12:03:33.051887 [debug] [ThreadPool]: Using postgres connection "list_mydb_dbt_warehouse"
[0m12:03:33.052758 [debug] [ThreadPool]: On list_mydb_dbt_warehouse: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "connection_name": "list_mydb_dbt_warehouse"} */
select
      'mydb' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_warehouse'
    union all
    select
      'mydb' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_warehouse'
  
[0m12:03:33.076633 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.0 seconds
[0m12:03:33.079208 [debug] [ThreadPool]: On list_mydb_dbt_warehouse: ROLLBACK
[0m12:03:33.081505 [debug] [ThreadPool]: On list_mydb_dbt_warehouse: Close
[0m12:03:33.097678 [debug] [MainThread]: Using postgres connection "master"
[0m12:03:33.098856 [debug] [MainThread]: On master: BEGIN
[0m12:03:33.099666 [debug] [MainThread]: Opening a new connection, currently in state init
[0m12:03:33.130968 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m12:03:33.131759 [debug] [MainThread]: Using postgres connection "master"
[0m12:03:33.132505 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m12:03:33.159984 [debug] [MainThread]: SQL status: SELECT 5 in 0.0 seconds
[0m12:03:33.162064 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6c862daa-1da0-46f2-abda-4b7643b9caad', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1084869a0>]}
[0m12:03:33.162836 [debug] [MainThread]: On master: ROLLBACK
[0m12:03:33.166269 [debug] [MainThread]: Using postgres connection "master"
[0m12:03:33.166971 [debug] [MainThread]: On master: BEGIN
[0m12:03:33.170910 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m12:03:33.171639 [debug] [MainThread]: On master: COMMIT
[0m12:03:33.172254 [debug] [MainThread]: Using postgres connection "master"
[0m12:03:33.172831 [debug] [MainThread]: On master: COMMIT
[0m12:03:33.174754 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m12:03:33.175790 [debug] [MainThread]: On master: Close
[0m12:03:33.177144 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m12:03:33.178539 [info ] [MainThread]: 
[0m12:03:33.190266 [debug] [Thread-1  ]: Began running node model.maker_warehouse.avg_viewing_time
[0m12:03:33.191251 [debug] [Thread-2  ]: Began running node model.maker_warehouse.movies
[0m12:03:33.192185 [debug] [Thread-3  ]: Began running node model.maker_warehouse.no_of_viewings
[0m12:03:33.192893 [debug] [Thread-4  ]: Began running node model.maker_warehouse.total_unique_users
[0m12:03:33.193713 [info ] [Thread-1  ]: 1 of 8 START sql table model dbt_warehouse.avg_viewing_time .................... [RUN]
[0m12:03:33.195073 [info ] [Thread-2  ]: 2 of 8 START sql table model dbt_warehouse.movies .............................. [RUN]
[0m12:03:33.196091 [info ] [Thread-3  ]: 3 of 8 START sql table model dbt_warehouse.no_of_viewings ...................... [RUN]
[0m12:03:33.197172 [info ] [Thread-4  ]: 4 of 8 START sql table model dbt_warehouse.total_unique_users .................. [RUN]
[0m12:03:33.198672 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_mydb_dbt_warehouse, now model.maker_warehouse.avg_viewing_time)
[0m12:03:33.200242 [debug] [Thread-2  ]: Acquiring new postgres connection 'model.maker_warehouse.movies'
[0m12:03:33.201681 [debug] [Thread-3  ]: Acquiring new postgres connection 'model.maker_warehouse.no_of_viewings'
[0m12:03:33.203893 [debug] [Thread-4  ]: Acquiring new postgres connection 'model.maker_warehouse.total_unique_users'
[0m12:03:33.204879 [debug] [Thread-1  ]: Began compiling node model.maker_warehouse.avg_viewing_time
[0m12:03:33.205831 [debug] [Thread-2  ]: Began compiling node model.maker_warehouse.movies
[0m12:03:33.206528 [debug] [Thread-3  ]: Began compiling node model.maker_warehouse.no_of_viewings
[0m12:03:33.207191 [debug] [Thread-4  ]: Began compiling node model.maker_warehouse.total_unique_users
[0m12:03:33.236392 [debug] [Thread-2  ]: Writing injected SQL for node "model.maker_warehouse.movies"
[0m12:03:33.222950 [debug] [Thread-1  ]: Writing injected SQL for node "model.maker_warehouse.avg_viewing_time"
[0m12:03:33.241967 [debug] [Thread-3  ]: Writing injected SQL for node "model.maker_warehouse.no_of_viewings"
[0m12:03:33.250203 [debug] [Thread-4  ]: Writing injected SQL for node "model.maker_warehouse.total_unique_users"
[0m12:03:33.251819 [debug] [Thread-2  ]: Timing info for model.maker_warehouse.movies (compile): 12:03:33.225077 => 12:03:33.251348
[0m12:03:33.254334 [debug] [Thread-2  ]: Began executing node model.maker_warehouse.movies
[0m12:03:33.261557 [debug] [Thread-1  ]: Timing info for model.maker_warehouse.avg_viewing_time (compile): 12:03:33.207905 => 12:03:33.260920
[0m12:03:33.274859 [debug] [Thread-3  ]: Timing info for model.maker_warehouse.no_of_viewings (compile): 12:03:33.237004 => 12:03:33.274220
[0m12:03:33.276565 [debug] [Thread-1  ]: Began executing node model.maker_warehouse.avg_viewing_time
[0m12:03:33.286709 [debug] [Thread-4  ]: Timing info for model.maker_warehouse.total_unique_users (compile): 12:03:33.243291 => 12:03:33.285969
[0m12:03:33.314716 [debug] [Thread-3  ]: Began executing node model.maker_warehouse.no_of_viewings
[0m12:03:33.361288 [debug] [Thread-2  ]: Writing runtime sql for node "model.maker_warehouse.movies"
[0m12:03:33.368849 [debug] [Thread-1  ]: Writing runtime sql for node "model.maker_warehouse.avg_viewing_time"
[0m12:03:33.369567 [debug] [Thread-4  ]: Began executing node model.maker_warehouse.total_unique_users
[0m12:03:33.377504 [debug] [Thread-3  ]: Writing runtime sql for node "model.maker_warehouse.no_of_viewings"
[0m12:03:33.388139 [debug] [Thread-4  ]: Writing runtime sql for node "model.maker_warehouse.total_unique_users"
[0m12:03:33.389334 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.movies"
[0m12:03:33.390016 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.avg_viewing_time"
[0m12:03:33.391245 [debug] [Thread-2  ]: On model.maker_warehouse.movies: BEGIN
[0m12:03:33.392523 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.total_unique_users"
[0m12:03:33.393061 [debug] [Thread-1  ]: On model.maker_warehouse.avg_viewing_time: BEGIN
[0m12:03:33.393725 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.no_of_viewings"
[0m12:03:33.394309 [debug] [Thread-2  ]: Opening a new connection, currently in state init
[0m12:03:33.394962 [debug] [Thread-4  ]: On model.maker_warehouse.total_unique_users: BEGIN
[0m12:03:33.395524 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m12:03:33.396292 [debug] [Thread-3  ]: On model.maker_warehouse.no_of_viewings: BEGIN
[0m12:03:33.397341 [debug] [Thread-4  ]: Opening a new connection, currently in state init
[0m12:03:33.399541 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m12:03:33.457829 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
[0m12:03:33.459496 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.avg_viewing_time"
[0m12:03:33.460368 [debug] [Thread-1  ]: On model.maker_warehouse.avg_viewing_time: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.avg_viewing_time"} */

  
    

  create  table "mydb"."dbt_warehouse"."avg_viewing_time__dbt_tmp"
  
  
    as
  
  (
    
SELECT
title,
ROUND(CAST(AVG(duration) AS NUMERIC), 2) as avg_duration
FROM mydb.public.raw_netflix
GROUP BY title
ORDER BY avg_duration DESC
  );
  
[0m12:03:33.461824 [debug] [Thread-2  ]: SQL status: BEGIN in 0.0 seconds
[0m12:03:33.463486 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.movies"
[0m12:03:33.465131 [debug] [Thread-2  ]: On model.maker_warehouse.movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.movies"} */

  
    

  create  table "mydb"."dbt_warehouse"."movies__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    DISTINCT
    title,
    genres,
    release_date,
    movie_id
FROM mydb.public.raw_netflix
  );
  
[0m12:03:33.466820 [debug] [Thread-4  ]: SQL status: BEGIN in 0.0 seconds
[0m12:03:33.468024 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.total_unique_users"
[0m12:03:33.468833 [debug] [Thread-4  ]: On model.maker_warehouse.total_unique_users: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_unique_users"} */

  
    

  create  table "mydb"."dbt_warehouse"."total_unique_users__dbt_tmp"
  
  
    as
  
  (
    
SELECT 
COUNT(DISTINCT(user_id)) AS total_unique_users
FROM mydb.public.raw_netflix
  );
  
[0m12:03:33.477174 [debug] [Thread-3  ]: SQL status: BEGIN in 0.0 seconds
[0m12:03:33.477981 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.no_of_viewings"
[0m12:03:33.478910 [debug] [Thread-3  ]: On model.maker_warehouse.no_of_viewings: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.no_of_viewings"} */

  
    

  create  table "mydb"."dbt_warehouse"."no_of_viewings__dbt_tmp"
  
  
    as
  
  (
    
SELECT
  title,
  COUNT(*) as total_views
FROM mydb.public.raw_netflix
GROUP BY title
ORDER BY total_views DESC
  );
  
[0m12:03:34.902108 [debug] [Thread-3  ]: SQL status: SELECT 7925 in 1.0 seconds
[0m12:03:34.917649 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.no_of_viewings"
[0m12:03:34.919061 [debug] [Thread-3  ]: On model.maker_warehouse.no_of_viewings: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.no_of_viewings"} */
alter table "mydb"."dbt_warehouse"."no_of_viewings" rename to "no_of_viewings__dbt_backup"
[0m12:03:34.923238 [debug] [Thread-3  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:03:34.930927 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.no_of_viewings"
[0m12:03:34.931613 [debug] [Thread-3  ]: On model.maker_warehouse.no_of_viewings: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.no_of_viewings"} */
alter table "mydb"."dbt_warehouse"."no_of_viewings__dbt_tmp" rename to "no_of_viewings"
[0m12:03:34.938132 [debug] [Thread-3  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:03:34.974572 [debug] [Thread-1  ]: SQL status: SELECT 7925 in 2.0 seconds
[0m12:03:34.983679 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.avg_viewing_time"
[0m12:03:35.014914 [debug] [Thread-3  ]: On model.maker_warehouse.no_of_viewings: COMMIT
[0m12:03:35.016733 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.no_of_viewings"
[0m12:03:35.015628 [debug] [Thread-1  ]: On model.maker_warehouse.avg_viewing_time: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.avg_viewing_time"} */
alter table "mydb"."dbt_warehouse"."avg_viewing_time" rename to "avg_viewing_time__dbt_backup"
[0m12:03:35.017364 [debug] [Thread-3  ]: On model.maker_warehouse.no_of_viewings: COMMIT
[0m12:03:35.023066 [debug] [Thread-3  ]: SQL status: COMMIT in 0.0 seconds
[0m12:03:35.032836 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:03:35.041652 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.no_of_viewings"
[0m12:03:35.051199 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.avg_viewing_time"
[0m12:03:35.052440 [debug] [Thread-3  ]: On model.maker_warehouse.no_of_viewings: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.no_of_viewings"} */
drop table if exists "mydb"."dbt_warehouse"."no_of_viewings__dbt_backup" cascade
[0m12:03:35.053561 [debug] [Thread-1  ]: On model.maker_warehouse.avg_viewing_time: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.avg_viewing_time"} */
alter table "mydb"."dbt_warehouse"."avg_viewing_time__dbt_tmp" rename to "avg_viewing_time"
[0m12:03:35.057403 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:03:35.064405 [debug] [Thread-1  ]: On model.maker_warehouse.avg_viewing_time: COMMIT
[0m12:03:35.065881 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.avg_viewing_time"
[0m12:03:35.067001 [debug] [Thread-1  ]: On model.maker_warehouse.avg_viewing_time: COMMIT
[0m12:03:35.072483 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
[0m12:03:35.073327 [debug] [Thread-3  ]: SQL status: DROP TABLE in 0.0 seconds
[0m12:03:35.083824 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.avg_viewing_time"
[0m12:03:35.087179 [debug] [Thread-3  ]: Timing info for model.maker_warehouse.no_of_viewings (execute): 12:03:33.370021 => 12:03:35.086782
[0m12:03:35.088282 [debug] [Thread-1  ]: On model.maker_warehouse.avg_viewing_time: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.avg_viewing_time"} */
drop table if exists "mydb"."dbt_warehouse"."avg_viewing_time__dbt_backup" cascade
[0m12:03:35.089600 [debug] [Thread-3  ]: On model.maker_warehouse.no_of_viewings: Close
[0m12:03:35.091902 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6c862daa-1da0-46f2-abda-4b7643b9caad', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1085ad520>]}
[0m12:03:35.093808 [info ] [Thread-3  ]: 3 of 8 OK created sql table model dbt_warehouse.no_of_viewings ................. [[32mSELECT 7925[0m in 1.89s]
[0m12:03:35.096099 [debug] [Thread-3  ]: Finished running node model.maker_warehouse.no_of_viewings
[0m12:03:35.097359 [debug] [Thread-3  ]: Began running node model.maker_warehouse.total_viewing_time
[0m12:03:35.098759 [info ] [Thread-3  ]: 5 of 8 START sql table model dbt_warehouse.total_viewing_time .................. [RUN]
[0m12:03:35.100913 [debug] [Thread-3  ]: Re-using an available connection from the pool (formerly model.maker_warehouse.no_of_viewings, now model.maker_warehouse.total_viewing_time)
[0m12:03:35.101703 [debug] [Thread-3  ]: Began compiling node model.maker_warehouse.total_viewing_time
[0m12:03:35.109644 [debug] [Thread-3  ]: Writing injected SQL for node "model.maker_warehouse.total_viewing_time"
[0m12:03:35.123323 [debug] [Thread-3  ]: Timing info for model.maker_warehouse.total_viewing_time (compile): 12:03:35.102355 => 12:03:35.121484
[0m12:03:35.126871 [debug] [Thread-3  ]: Began executing node model.maker_warehouse.total_viewing_time
[0m12:03:35.145868 [debug] [Thread-3  ]: Writing runtime sql for node "model.maker_warehouse.total_viewing_time"
[0m12:03:35.148784 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.total_viewing_time"
[0m12:03:35.152779 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
[0m12:03:35.154878 [debug] [Thread-3  ]: On model.maker_warehouse.total_viewing_time: BEGIN
[0m12:03:35.167331 [debug] [Thread-1  ]: Timing info for model.maker_warehouse.avg_viewing_time (execute): 12:03:33.338385 => 12:03:35.166991
[0m12:03:35.183549 [debug] [Thread-1  ]: On model.maker_warehouse.avg_viewing_time: Close
[0m12:03:35.186188 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6c862daa-1da0-46f2-abda-4b7643b9caad', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108555dc0>]}
[0m12:03:35.187809 [info ] [Thread-1  ]: 1 of 8 OK created sql table model dbt_warehouse.avg_viewing_time ............... [[32mSELECT 7925[0m in 1.99s]
[0m12:03:35.189952 [debug] [Thread-1  ]: Finished running node model.maker_warehouse.avg_viewing_time
[0m12:03:35.179924 [debug] [Thread-3  ]: Opening a new connection, currently in state closed
[0m12:03:35.190861 [debug] [Thread-1  ]: Began running node model.maker_warehouse.total_viewings_year_month
[0m12:03:35.196236 [info ] [Thread-1  ]: 6 of 8 START sql table model dbt_warehouse.total_viewings_year_month ........... [RUN]
[0m12:03:35.198856 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.maker_warehouse.avg_viewing_time, now model.maker_warehouse.total_viewings_year_month)
[0m12:03:35.200171 [debug] [Thread-1  ]: Began compiling node model.maker_warehouse.total_viewings_year_month
[0m12:03:35.217714 [debug] [Thread-1  ]: Writing injected SQL for node "model.maker_warehouse.total_viewings_year_month"
[0m12:03:35.220643 [debug] [Thread-1  ]: Timing info for model.maker_warehouse.total_viewings_year_month (compile): 12:03:35.200901 => 12:03:35.219963
[0m12:03:35.221903 [debug] [Thread-1  ]: Began executing node model.maker_warehouse.total_viewings_year_month
[0m12:03:35.239989 [debug] [Thread-1  ]: Writing runtime sql for node "model.maker_warehouse.total_viewings_year_month"
[0m12:03:35.248953 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.total_viewings_year_month"
[0m12:03:35.250331 [debug] [Thread-1  ]: On model.maker_warehouse.total_viewings_year_month: BEGIN
[0m12:03:35.251634 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m12:03:35.296595 [debug] [Thread-3  ]: SQL status: BEGIN in 0.0 seconds
[0m12:03:35.297917 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.total_viewing_time"
[0m12:03:35.299927 [debug] [Thread-3  ]: On model.maker_warehouse.total_viewing_time: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_viewing_time"} */

  
    

  create  table "mydb"."dbt_warehouse"."total_viewing_time__dbt_tmp"
  
  
    as
  
  (
    
SELECT
title,
SUM(duration) as total_duration
FROM mydb.public.raw_netflix
GROUP BY title
ORDER BY total_duration DESC
  );
  
[0m12:03:35.304852 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
[0m12:03:35.306024 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.total_viewings_year_month"
[0m12:03:35.307172 [debug] [Thread-1  ]: On model.maker_warehouse.total_viewings_year_month: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_viewings_year_month"} */

  
    

  create  table "mydb"."dbt_warehouse"."total_viewings_year_month__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    EXTRACT(YEAR FROM CAST("datetime" AS DATE)) AS "Year",
    EXTRACT(MONTH FROM CAST("datetime" AS DATE)) AS "Month",
    COUNT(*) AS "Total_Views"
FROM mydb.public.raw_netflix
GROUP BY
    EXTRACT(YEAR FROM CAST("datetime" AS DATE)),
    EXTRACT(MONTH FROM CAST("datetime" AS DATE))
ORDER BY
    "Year", "Month"
  );
  
[0m12:03:35.860067 [debug] [Thread-3  ]: SQL status: SELECT 7925 in 1.0 seconds
[0m12:03:35.870100 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.total_viewing_time"
[0m12:03:35.871562 [debug] [Thread-3  ]: On model.maker_warehouse.total_viewing_time: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_viewing_time"} */
alter table "mydb"."dbt_warehouse"."total_viewing_time" rename to "total_viewing_time__dbt_backup"
[0m12:03:35.877240 [debug] [Thread-3  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:03:35.886202 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.total_viewing_time"
[0m12:03:35.888120 [debug] [Thread-3  ]: On model.maker_warehouse.total_viewing_time: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_viewing_time"} */
alter table "mydb"."dbt_warehouse"."total_viewing_time__dbt_tmp" rename to "total_viewing_time"
[0m12:03:35.905038 [debug] [Thread-3  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:03:35.913274 [debug] [Thread-3  ]: On model.maker_warehouse.total_viewing_time: COMMIT
[0m12:03:35.914401 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.total_viewing_time"
[0m12:03:35.915072 [debug] [Thread-3  ]: On model.maker_warehouse.total_viewing_time: COMMIT
[0m12:03:35.929663 [debug] [Thread-3  ]: SQL status: COMMIT in 0.0 seconds
[0m12:03:35.937135 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.total_viewing_time"
[0m12:03:35.937853 [debug] [Thread-3  ]: On model.maker_warehouse.total_viewing_time: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_viewing_time"} */
drop table if exists "mydb"."dbt_warehouse"."total_viewing_time__dbt_backup" cascade
[0m12:03:35.955246 [debug] [Thread-3  ]: SQL status: DROP TABLE in 0.0 seconds
[0m12:03:35.959937 [debug] [Thread-3  ]: Timing info for model.maker_warehouse.total_viewing_time (execute): 12:03:35.127853 => 12:03:35.959500
[0m12:03:35.961061 [debug] [Thread-3  ]: On model.maker_warehouse.total_viewing_time: Close
[0m12:03:35.963682 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6c862daa-1da0-46f2-abda-4b7643b9caad', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1085557f0>]}
[0m12:03:35.965830 [info ] [Thread-3  ]: 5 of 8 OK created sql table model dbt_warehouse.total_viewing_time ............. [[32mSELECT 7925[0m in 0.86s]
[0m12:03:35.969334 [debug] [Thread-3  ]: Finished running node model.maker_warehouse.total_viewing_time
[0m12:03:35.970273 [debug] [Thread-3  ]: Began running node model.maker_warehouse.user_engagement
[0m12:03:35.970982 [info ] [Thread-3  ]: 7 of 8 START sql table model dbt_warehouse.user_engagement ..................... [RUN]
[0m12:03:35.972068 [debug] [Thread-3  ]: Re-using an available connection from the pool (formerly model.maker_warehouse.total_viewing_time, now model.maker_warehouse.user_engagement)
[0m12:03:35.972645 [debug] [Thread-3  ]: Began compiling node model.maker_warehouse.user_engagement
[0m12:03:35.984674 [debug] [Thread-3  ]: Writing injected SQL for node "model.maker_warehouse.user_engagement"
[0m12:03:35.987019 [debug] [Thread-3  ]: Timing info for model.maker_warehouse.user_engagement (compile): 12:03:35.973023 => 12:03:35.986490
[0m12:03:35.988104 [debug] [Thread-3  ]: Began executing node model.maker_warehouse.user_engagement
[0m12:03:36.008736 [debug] [Thread-3  ]: Writing runtime sql for node "model.maker_warehouse.user_engagement"
[0m12:03:36.011441 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.user_engagement"
[0m12:03:36.012750 [debug] [Thread-3  ]: On model.maker_warehouse.user_engagement: BEGIN
[0m12:03:36.014354 [debug] [Thread-3  ]: Opening a new connection, currently in state closed
[0m12:03:36.126223 [debug] [Thread-3  ]: SQL status: BEGIN in 0.0 seconds
[0m12:03:36.127641 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.user_engagement"
[0m12:03:36.129159 [debug] [Thread-3  ]: On model.maker_warehouse.user_engagement: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.user_engagement"} */

  
    

  create  table "mydb"."dbt_warehouse"."user_engagement__dbt_tmp"
  
  
    as
  
  (
    
SELECT 
DISTINCT(user_id),
COUNT(DISTINCT(title)) AS total_titles,
SUM(duration) AS total_duration
FROM mydb.public.raw_netflix
GROUP BY user_id
  );
  
[0m12:03:37.063540 [debug] [Thread-2  ]: SQL status: SELECT 8472 in 4.0 seconds
[0m12:03:37.115564 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.movies"
[0m12:03:37.117480 [debug] [Thread-2  ]: On model.maker_warehouse.movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.movies"} */
alter table "mydb"."dbt_warehouse"."movies" rename to "movies__dbt_backup"
[0m12:03:37.133269 [debug] [Thread-2  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:03:37.141734 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.movies"
[0m12:03:37.143738 [debug] [Thread-2  ]: On model.maker_warehouse.movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.movies"} */
alter table "mydb"."dbt_warehouse"."movies__dbt_tmp" rename to "movies"
[0m12:03:37.157367 [debug] [Thread-2  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:03:37.172782 [debug] [Thread-2  ]: On model.maker_warehouse.movies: COMMIT
[0m12:03:37.173872 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.movies"
[0m12:03:37.175095 [debug] [Thread-2  ]: On model.maker_warehouse.movies: COMMIT
[0m12:03:37.183104 [debug] [Thread-2  ]: SQL status: COMMIT in 0.0 seconds
[0m12:03:37.190410 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.movies"
[0m12:03:37.191309 [debug] [Thread-2  ]: On model.maker_warehouse.movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.movies"} */
drop table if exists "mydb"."dbt_warehouse"."movies__dbt_backup" cascade
[0m12:03:37.216610 [debug] [Thread-2  ]: SQL status: DROP TABLE in 0.0 seconds
[0m12:03:37.219494 [debug] [Thread-2  ]: Timing info for model.maker_warehouse.movies (execute): 12:03:33.255266 => 12:03:37.219108
[0m12:03:37.220364 [debug] [Thread-2  ]: On model.maker_warehouse.movies: Close
[0m12:03:37.222150 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6c862daa-1da0-46f2-abda-4b7643b9caad', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1085e2bb0>]}
[0m12:03:37.224629 [info ] [Thread-2  ]: 2 of 8 OK created sql table model dbt_warehouse.movies ......................... [[32mSELECT 8472[0m in 4.02s]
[0m12:03:37.227762 [debug] [Thread-2  ]: Finished running node model.maker_warehouse.movies
[0m12:03:37.233830 [debug] [Thread-2  ]: Began running node model.maker_warehouse.all_movies
[0m12:03:37.235758 [info ] [Thread-2  ]: 8 of 8 START sql table model dbt_warehouse.all_movies .......................... [RUN]
[0m12:03:37.239436 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly model.maker_warehouse.movies, now model.maker_warehouse.all_movies)
[0m12:03:37.241244 [debug] [Thread-2  ]: Began compiling node model.maker_warehouse.all_movies
[0m12:03:37.270982 [debug] [Thread-2  ]: Writing injected SQL for node "model.maker_warehouse.all_movies"
[0m12:03:37.275619 [debug] [Thread-2  ]: Timing info for model.maker_warehouse.all_movies (compile): 12:03:37.242105 => 12:03:37.273851
[0m12:03:37.280984 [debug] [Thread-2  ]: Began executing node model.maker_warehouse.all_movies
[0m12:03:37.311412 [debug] [Thread-2  ]: Writing runtime sql for node "model.maker_warehouse.all_movies"
[0m12:03:37.314475 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.all_movies"
[0m12:03:37.316346 [debug] [Thread-2  ]: On model.maker_warehouse.all_movies: BEGIN
[0m12:03:37.317445 [debug] [Thread-2  ]: Opening a new connection, currently in state closed
[0m12:03:37.450295 [debug] [Thread-2  ]: SQL status: BEGIN in 0.0 seconds
[0m12:03:37.451851 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.all_movies"
[0m12:03:37.452968 [debug] [Thread-2  ]: On model.maker_warehouse.all_movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.all_movies"} */

  
    

  create  table "mydb"."dbt_warehouse"."all_movies__dbt_tmp"
  
  
    as
  
  (
    
  
SELECT
*
FROM "mydb"."dbt_warehouse"."movies"
  );
  
[0m12:03:37.522185 [debug] [Thread-2  ]: SQL status: SELECT 8472 in 0.0 seconds
[0m12:03:37.535437 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.all_movies"
[0m12:03:37.536748 [debug] [Thread-2  ]: On model.maker_warehouse.all_movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.all_movies"} */
alter table "mydb"."dbt_warehouse"."all_movies" rename to "all_movies__dbt_backup"
[0m12:03:37.542416 [debug] [Thread-2  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:03:37.555772 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.all_movies"
[0m12:03:37.557034 [debug] [Thread-2  ]: On model.maker_warehouse.all_movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.all_movies"} */
alter table "mydb"."dbt_warehouse"."all_movies__dbt_tmp" rename to "all_movies"
[0m12:03:37.562098 [debug] [Thread-2  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:03:37.570367 [debug] [Thread-2  ]: On model.maker_warehouse.all_movies: COMMIT
[0m12:03:37.571027 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.all_movies"
[0m12:03:37.571714 [debug] [Thread-2  ]: On model.maker_warehouse.all_movies: COMMIT
[0m12:03:37.585697 [debug] [Thread-2  ]: SQL status: COMMIT in 0.0 seconds
[0m12:03:37.594434 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.all_movies"
[0m12:03:37.595297 [debug] [Thread-2  ]: On model.maker_warehouse.all_movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.all_movies"} */
drop table if exists "mydb"."dbt_warehouse"."all_movies__dbt_backup" cascade
[0m12:03:37.611714 [debug] [Thread-2  ]: SQL status: DROP TABLE in 0.0 seconds
[0m12:03:37.615750 [debug] [Thread-2  ]: Timing info for model.maker_warehouse.all_movies (execute): 12:03:37.281952 => 12:03:37.615254
[0m12:03:37.616568 [debug] [Thread-2  ]: On model.maker_warehouse.all_movies: Close
[0m12:03:37.618484 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6c862daa-1da0-46f2-abda-4b7643b9caad', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10849fbe0>]}
[0m12:03:37.620635 [info ] [Thread-2  ]: 8 of 8 OK created sql table model dbt_warehouse.all_movies ..................... [[32mSELECT 8472[0m in 0.38s]
[0m12:03:37.622687 [debug] [Thread-2  ]: Finished running node model.maker_warehouse.all_movies
[0m12:03:40.655930 [debug] [Thread-1  ]: SQL status: SELECT 30 in 5.0 seconds
[0m12:03:40.665941 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.total_viewings_year_month"
[0m12:03:40.669131 [debug] [Thread-1  ]: On model.maker_warehouse.total_viewings_year_month: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_viewings_year_month"} */
alter table "mydb"."dbt_warehouse"."total_viewings_year_month__dbt_tmp" rename to "total_viewings_year_month"
[0m12:03:40.673308 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:03:40.682403 [debug] [Thread-1  ]: On model.maker_warehouse.total_viewings_year_month: COMMIT
[0m12:03:40.683997 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.total_viewings_year_month"
[0m12:03:40.685236 [debug] [Thread-1  ]: On model.maker_warehouse.total_viewings_year_month: COMMIT
[0m12:03:40.695913 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
[0m12:03:40.704522 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.total_viewings_year_month"
[0m12:03:40.705823 [debug] [Thread-1  ]: On model.maker_warehouse.total_viewings_year_month: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_viewings_year_month"} */
drop table if exists "mydb"."dbt_warehouse"."total_viewings_year_month__dbt_backup" cascade
[0m12:03:40.711853 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
[0m12:03:40.715598 [debug] [Thread-1  ]: Timing info for model.maker_warehouse.total_viewings_year_month (execute): 12:03:35.222483 => 12:03:40.714960
[0m12:03:40.716404 [debug] [Thread-1  ]: On model.maker_warehouse.total_viewings_year_month: Close
[0m12:03:40.718055 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6c862daa-1da0-46f2-abda-4b7643b9caad', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108628b20>]}
[0m12:03:40.719535 [info ] [Thread-1  ]: 6 of 8 OK created sql table model dbt_warehouse.total_viewings_year_month ...... [[32mSELECT 30[0m in 5.52s]
[0m12:03:40.721661 [debug] [Thread-1  ]: Finished running node model.maker_warehouse.total_viewings_year_month
[0m12:03:41.182854 [debug] [Thread-4  ]: SQL status: SELECT 1 in 8.0 seconds
[0m12:03:41.190063 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.total_unique_users"
[0m12:03:41.191038 [debug] [Thread-4  ]: On model.maker_warehouse.total_unique_users: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_unique_users"} */
alter table "mydb"."dbt_warehouse"."total_unique_users" rename to "total_unique_users__dbt_backup"
[0m12:03:41.194642 [debug] [Thread-4  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:03:41.200430 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.total_unique_users"
[0m12:03:41.201191 [debug] [Thread-4  ]: On model.maker_warehouse.total_unique_users: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_unique_users"} */
alter table "mydb"."dbt_warehouse"."total_unique_users__dbt_tmp" rename to "total_unique_users"
[0m12:03:41.205430 [debug] [Thread-4  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:03:41.209916 [debug] [Thread-4  ]: On model.maker_warehouse.total_unique_users: COMMIT
[0m12:03:41.210778 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.total_unique_users"
[0m12:03:41.211371 [debug] [Thread-4  ]: On model.maker_warehouse.total_unique_users: COMMIT
[0m12:03:41.216969 [debug] [Thread-4  ]: SQL status: COMMIT in 0.0 seconds
[0m12:03:41.223832 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.total_unique_users"
[0m12:03:41.225058 [debug] [Thread-4  ]: On model.maker_warehouse.total_unique_users: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_unique_users"} */
drop table if exists "mydb"."dbt_warehouse"."total_unique_users__dbt_backup" cascade
[0m12:03:41.233290 [debug] [Thread-4  ]: SQL status: DROP TABLE in 0.0 seconds
[0m12:03:41.236238 [debug] [Thread-4  ]: Timing info for model.maker_warehouse.total_unique_users (execute): 12:03:33.379799 => 12:03:41.235918
[0m12:03:41.236871 [debug] [Thread-4  ]: On model.maker_warehouse.total_unique_users: Close
[0m12:03:41.238542 [debug] [Thread-4  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6c862daa-1da0-46f2-abda-4b7643b9caad', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10849f7f0>]}
[0m12:03:41.240181 [info ] [Thread-4  ]: 4 of 8 OK created sql table model dbt_warehouse.total_unique_users ............. [[32mSELECT 1[0m in 8.04s]
[0m12:03:41.242832 [debug] [Thread-4  ]: Finished running node model.maker_warehouse.total_unique_users
[0m12:03:43.418455 [debug] [Thread-3  ]: SQL status: SELECT 161918 in 7.0 seconds
[0m12:03:43.425534 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.user_engagement"
[0m12:03:43.426346 [debug] [Thread-3  ]: On model.maker_warehouse.user_engagement: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.user_engagement"} */
alter table "mydb"."dbt_warehouse"."user_engagement" rename to "user_engagement__dbt_backup"
[0m12:03:43.430110 [debug] [Thread-3  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:03:43.436585 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.user_engagement"
[0m12:03:43.437419 [debug] [Thread-3  ]: On model.maker_warehouse.user_engagement: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.user_engagement"} */
alter table "mydb"."dbt_warehouse"."user_engagement__dbt_tmp" rename to "user_engagement"
[0m12:03:43.440267 [debug] [Thread-3  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:03:43.445988 [debug] [Thread-3  ]: On model.maker_warehouse.user_engagement: COMMIT
[0m12:03:43.447223 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.user_engagement"
[0m12:03:43.447920 [debug] [Thread-3  ]: On model.maker_warehouse.user_engagement: COMMIT
[0m12:03:43.469601 [debug] [Thread-3  ]: SQL status: COMMIT in 0.0 seconds
[0m12:03:43.474025 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.user_engagement"
[0m12:03:43.474829 [debug] [Thread-3  ]: On model.maker_warehouse.user_engagement: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.user_engagement"} */
drop table if exists "mydb"."dbt_warehouse"."user_engagement__dbt_backup" cascade
[0m12:03:43.491309 [debug] [Thread-3  ]: SQL status: DROP TABLE in 0.0 seconds
[0m12:03:43.494232 [debug] [Thread-3  ]: Timing info for model.maker_warehouse.user_engagement (execute): 12:03:35.988756 => 12:03:43.493793
[0m12:03:43.494906 [debug] [Thread-3  ]: On model.maker_warehouse.user_engagement: Close
[0m12:03:43.496363 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6c862daa-1da0-46f2-abda-4b7643b9caad', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10849ff10>]}
[0m12:03:43.497754 [info ] [Thread-3  ]: 7 of 8 OK created sql table model dbt_warehouse.user_engagement ................ [[32mSELECT 161918[0m in 7.52s]
[0m12:03:43.500428 [debug] [Thread-3  ]: Finished running node model.maker_warehouse.user_engagement
[0m12:03:43.508111 [debug] [MainThread]: Using postgres connection "master"
[0m12:03:43.509515 [debug] [MainThread]: On master: BEGIN
[0m12:03:43.510320 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m12:03:43.548567 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m12:03:43.549926 [debug] [MainThread]: On master: COMMIT
[0m12:03:43.552939 [debug] [MainThread]: Using postgres connection "master"
[0m12:03:43.554714 [debug] [MainThread]: On master: COMMIT
[0m12:03:43.557227 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m12:03:43.558218 [debug] [MainThread]: On master: Close
[0m12:03:43.561680 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:03:43.562671 [debug] [MainThread]: Connection 'model.maker_warehouse.total_viewings_year_month' was properly closed.
[0m12:03:43.564164 [debug] [MainThread]: Connection 'model.maker_warehouse.all_movies' was properly closed.
[0m12:03:43.565340 [debug] [MainThread]: Connection 'model.maker_warehouse.user_engagement' was properly closed.
[0m12:03:43.566376 [debug] [MainThread]: Connection 'model.maker_warehouse.total_unique_users' was properly closed.
[0m12:03:43.567443 [info ] [MainThread]: 
[0m12:03:43.568343 [info ] [MainThread]: Finished running 8 table models in 0 hours 0 minutes and 10.78 seconds (10.78s).
[0m12:03:43.571846 [debug] [MainThread]: Command end result
[0m12:03:43.588480 [info ] [MainThread]: 
[0m12:03:43.589566 [info ] [MainThread]: [32mCompleted successfully[0m
[0m12:03:43.590606 [info ] [MainThread]: 
[0m12:03:43.591822 [info ] [MainThread]: Done. PASS=8 WARN=0 ERROR=0 SKIP=0 TOTAL=8
[0m12:03:43.594439 [debug] [MainThread]: Command `dbt run` succeeded at 12:03:43.593957 after 12.11 seconds
[0m12:03:43.596029 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106bef550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10842e040>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108170520>]}
[0m12:03:43.597366 [debug] [MainThread]: Flushing usage events
[0m12:05:52.697070 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105a144f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106daf2b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1035a7790>]}


============================== 12:05:52.705626 | 09660a19-88ee-43af-bcf5-b3d79f743d9f ==============================
[0m12:05:52.705626 [info ] [MainThread]: Running with dbt=1.5.4
[0m12:05:52.708637 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/denisechan/Documents/Makers/Data_Engineering/Week_6/dbt_warehouse', 'debug': 'False', 'version_check': 'True', 'log_path': '/Users/denisechan/Documents/Makers/Data_Engineering/Week_6/dbt_warehouse/logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'send_anonymous_usage_stats': 'True'}
[0m12:05:52.917377 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '09660a19-88ee-43af-bcf5-b3d79f743d9f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106dafa00>]}
[0m12:05:52.961529 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '09660a19-88ee-43af-bcf5-b3d79f743d9f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107014700>]}
[0m12:05:52.964599 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m12:05:53.045897 [debug] [MainThread]: checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, vars: {}, profile: , target: , version: 1.5.4
[0m12:05:53.191147 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
[0m12:05:53.191972 [debug] [MainThread]: Partial parsing: added file: maker_warehouse://models/summary/total_duration_year_month.sql
[0m12:05:53.264669 [debug] [MainThread]: 1699: static parser successfully parsed summary/total_duration_year_month.sql
[0m12:05:53.305503 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '09660a19-88ee-43af-bcf5-b3d79f743d9f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1072e6f40>]}
[0m12:05:53.321111 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '09660a19-88ee-43af-bcf5-b3d79f743d9f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107224e80>]}
[0m12:05:53.322357 [info ] [MainThread]: Found 9 models, 0 tests, 0 snapshots, 0 analyses, 307 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics, 0 groups
[0m12:05:53.323389 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '09660a19-88ee-43af-bcf5-b3d79f743d9f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107224eb0>]}
[0m12:05:53.328852 [info ] [MainThread]: 
[0m12:05:53.331079 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m12:05:53.334459 [debug] [ThreadPool]: Acquiring new postgres connection 'list_mydb'
[0m12:05:53.364547 [debug] [ThreadPool]: Using postgres connection "list_mydb"
[0m12:05:53.365568 [debug] [ThreadPool]: On list_mydb: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "connection_name": "list_mydb"} */

    select distinct nspname from pg_namespace
  
[0m12:05:53.366446 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:05:53.539396 [debug] [ThreadPool]: SQL status: SELECT 5 in 0.0 seconds
[0m12:05:53.542927 [debug] [ThreadPool]: On list_mydb: Close
[0m12:05:53.548980 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_mydb, now list_mydb_dbt_warehouse)
[0m12:05:53.561391 [debug] [ThreadPool]: Using postgres connection "list_mydb_dbt_warehouse"
[0m12:05:53.562156 [debug] [ThreadPool]: On list_mydb_dbt_warehouse: BEGIN
[0m12:05:53.562655 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:05:53.591432 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m12:05:53.592435 [debug] [ThreadPool]: Using postgres connection "list_mydb_dbt_warehouse"
[0m12:05:53.593077 [debug] [ThreadPool]: On list_mydb_dbt_warehouse: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "connection_name": "list_mydb_dbt_warehouse"} */
select
      'mydb' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_warehouse'
    union all
    select
      'mydb' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_warehouse'
  
[0m12:05:53.607295 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.0 seconds
[0m12:05:53.610649 [debug] [ThreadPool]: On list_mydb_dbt_warehouse: ROLLBACK
[0m12:05:53.612826 [debug] [ThreadPool]: On list_mydb_dbt_warehouse: Close
[0m12:05:53.627018 [debug] [MainThread]: Using postgres connection "master"
[0m12:05:53.628200 [debug] [MainThread]: On master: BEGIN
[0m12:05:53.628895 [debug] [MainThread]: Opening a new connection, currently in state init
[0m12:05:53.656494 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m12:05:53.657694 [debug] [MainThread]: Using postgres connection "master"
[0m12:05:53.658686 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m12:05:53.683187 [debug] [MainThread]: SQL status: SELECT 5 in 0.0 seconds
[0m12:05:53.685518 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '09660a19-88ee-43af-bcf5-b3d79f743d9f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107291fa0>]}
[0m12:05:53.686504 [debug] [MainThread]: On master: ROLLBACK
[0m12:05:53.689313 [debug] [MainThread]: Using postgres connection "master"
[0m12:05:53.689920 [debug] [MainThread]: On master: BEGIN
[0m12:05:53.694883 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m12:05:53.696067 [debug] [MainThread]: On master: COMMIT
[0m12:05:53.696939 [debug] [MainThread]: Using postgres connection "master"
[0m12:05:53.697750 [debug] [MainThread]: On master: COMMIT
[0m12:05:53.699931 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m12:05:53.700748 [debug] [MainThread]: On master: Close
[0m12:05:53.702718 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m12:05:53.704372 [info ] [MainThread]: 
[0m12:05:53.720429 [debug] [Thread-1  ]: Began running node model.maker_warehouse.avg_viewing_time
[0m12:05:53.721220 [debug] [Thread-2  ]: Began running node model.maker_warehouse.movies
[0m12:05:53.722331 [debug] [Thread-3  ]: Began running node model.maker_warehouse.no_of_viewings
[0m12:05:53.723091 [debug] [Thread-4  ]: Began running node model.maker_warehouse.total_duration_year_month
[0m12:05:53.723888 [info ] [Thread-1  ]: 1 of 9 START sql table model dbt_warehouse.avg_viewing_time .................... [RUN]
[0m12:05:53.724834 [info ] [Thread-2  ]: 2 of 9 START sql table model dbt_warehouse.movies .............................. [RUN]
[0m12:05:53.726444 [info ] [Thread-3  ]: 3 of 9 START sql table model dbt_warehouse.no_of_viewings ...................... [RUN]
[0m12:05:53.728852 [info ] [Thread-4  ]: 4 of 9 START sql table model dbt_warehouse.total_duration_year_month ........... [RUN]
[0m12:05:53.730136 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_mydb_dbt_warehouse, now model.maker_warehouse.avg_viewing_time)
[0m12:05:53.731223 [debug] [Thread-2  ]: Acquiring new postgres connection 'model.maker_warehouse.movies'
[0m12:05:53.736071 [debug] [Thread-2  ]: Began compiling node model.maker_warehouse.movies
[0m12:05:53.732618 [debug] [Thread-3  ]: Acquiring new postgres connection 'model.maker_warehouse.no_of_viewings'
[0m12:05:53.735154 [debug] [Thread-1  ]: Began compiling node model.maker_warehouse.avg_viewing_time
[0m12:05:53.734338 [debug] [Thread-4  ]: Acquiring new postgres connection 'model.maker_warehouse.total_duration_year_month'
[0m12:05:53.753559 [debug] [Thread-2  ]: Writing injected SQL for node "model.maker_warehouse.movies"
[0m12:05:53.754380 [debug] [Thread-3  ]: Began compiling node model.maker_warehouse.no_of_viewings
[0m12:05:53.759954 [debug] [Thread-1  ]: Writing injected SQL for node "model.maker_warehouse.avg_viewing_time"
[0m12:05:53.761079 [debug] [Thread-4  ]: Began compiling node model.maker_warehouse.total_duration_year_month
[0m12:05:53.770750 [debug] [Thread-3  ]: Writing injected SQL for node "model.maker_warehouse.no_of_viewings"
[0m12:05:53.773006 [debug] [Thread-2  ]: Timing info for model.maker_warehouse.movies (compile): 12:05:53.736528 => 12:05:53.772233
[0m12:05:53.789208 [debug] [Thread-2  ]: Began executing node model.maker_warehouse.movies
[0m12:05:53.780372 [debug] [Thread-1  ]: Timing info for model.maker_warehouse.avg_viewing_time (compile): 12:05:53.755128 => 12:05:53.779613
[0m12:05:53.826848 [debug] [Thread-1  ]: Began executing node model.maker_warehouse.avg_viewing_time
[0m12:05:53.797460 [debug] [Thread-3  ]: Timing info for model.maker_warehouse.no_of_viewings (compile): 12:05:53.761972 => 12:05:53.796665
[0m12:05:53.851911 [debug] [Thread-3  ]: Began executing node model.maker_warehouse.no_of_viewings
[0m12:05:53.786661 [debug] [Thread-4  ]: Writing injected SQL for node "model.maker_warehouse.total_duration_year_month"
[0m12:05:53.931515 [debug] [Thread-4  ]: Timing info for model.maker_warehouse.total_duration_year_month (compile): 12:05:53.773826 => 12:05:53.930885
[0m12:05:53.937617 [debug] [Thread-4  ]: Began executing node model.maker_warehouse.total_duration_year_month
[0m12:05:54.033069 [debug] [Thread-3  ]: Writing runtime sql for node "model.maker_warehouse.no_of_viewings"
[0m12:05:54.037897 [debug] [Thread-1  ]: Writing runtime sql for node "model.maker_warehouse.avg_viewing_time"
[0m12:05:54.038592 [debug] [Thread-4  ]: Writing runtime sql for node "model.maker_warehouse.total_duration_year_month"
[0m12:05:54.047093 [debug] [Thread-2  ]: Writing runtime sql for node "model.maker_warehouse.movies"
[0m12:05:54.050766 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.avg_viewing_time"
[0m12:05:54.051430 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.no_of_viewings"
[0m12:05:54.052161 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.total_duration_year_month"
[0m12:05:54.053107 [debug] [Thread-1  ]: On model.maker_warehouse.avg_viewing_time: BEGIN
[0m12:05:54.053868 [debug] [Thread-3  ]: On model.maker_warehouse.no_of_viewings: BEGIN
[0m12:05:54.054515 [debug] [Thread-4  ]: On model.maker_warehouse.total_duration_year_month: BEGIN
[0m12:05:54.055121 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.movies"
[0m12:05:54.055694 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m12:05:54.056247 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m12:05:54.056801 [debug] [Thread-4  ]: Opening a new connection, currently in state init
[0m12:05:54.057398 [debug] [Thread-2  ]: On model.maker_warehouse.movies: BEGIN
[0m12:05:54.059581 [debug] [Thread-2  ]: Opening a new connection, currently in state init
[0m12:05:54.112219 [debug] [Thread-4  ]: SQL status: BEGIN in 0.0 seconds
[0m12:05:54.113485 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.total_duration_year_month"
[0m12:05:54.114526 [debug] [Thread-4  ]: On model.maker_warehouse.total_duration_year_month: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_duration_year_month"} */

  
    

  create  table "mydb"."dbt_warehouse"."total_duration_year_month__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    EXTRACT(YEAR FROM CAST("datetime" AS DATE)) AS "Year",
    EXTRACT(MONTH FROM CAST("datetime" AS DATE)) AS "Month",
    SUM(duration) AS "Total_Duration"
FROM
    mydb.public.raw_netflix
GROUP BY
    EXTRACT(YEAR FROM CAST("datetime" AS DATE)),
    EXTRACT(MONTH FROM CAST("datetime" AS DATE))
ORDER BY
    "Year", "Month"
  );
  
[0m12:05:54.116028 [debug] [Thread-2  ]: SQL status: BEGIN in 0.0 seconds
[0m12:05:54.117174 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.movies"
[0m12:05:54.118445 [debug] [Thread-2  ]: On model.maker_warehouse.movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.movies"} */

  
    

  create  table "mydb"."dbt_warehouse"."movies__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    DISTINCT
    title,
    genres,
    release_date,
    movie_id
FROM mydb.public.raw_netflix
  );
  
[0m12:05:54.132296 [debug] [Thread-3  ]: SQL status: BEGIN in 0.0 seconds
[0m12:05:54.133359 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
[0m12:05:54.134476 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.no_of_viewings"
[0m12:05:54.137339 [debug] [Thread-3  ]: On model.maker_warehouse.no_of_viewings: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.no_of_viewings"} */

  
    

  create  table "mydb"."dbt_warehouse"."no_of_viewings__dbt_tmp"
  
  
    as
  
  (
    
SELECT
  title,
  COUNT(*) as total_views
FROM mydb.public.raw_netflix
GROUP BY title
ORDER BY total_views DESC
  );
  
[0m12:05:54.135379 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.avg_viewing_time"
[0m12:05:54.138742 [debug] [Thread-1  ]: On model.maker_warehouse.avg_viewing_time: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.avg_viewing_time"} */

  
    

  create  table "mydb"."dbt_warehouse"."avg_viewing_time__dbt_tmp"
  
  
    as
  
  (
    
SELECT
title,
ROUND(CAST(AVG(duration) AS NUMERIC), 2) as avg_duration
FROM mydb.public.raw_netflix
GROUP BY title
ORDER BY avg_duration DESC
  );
  
[0m12:05:55.629104 [debug] [Thread-3  ]: SQL status: SELECT 7925 in 1.0 seconds
[0m12:05:55.645930 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.no_of_viewings"
[0m12:05:55.647337 [debug] [Thread-3  ]: On model.maker_warehouse.no_of_viewings: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.no_of_viewings"} */
alter table "mydb"."dbt_warehouse"."no_of_viewings" rename to "no_of_viewings__dbt_backup"
[0m12:05:55.651001 [debug] [Thread-3  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:05:55.658193 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.no_of_viewings"
[0m12:05:55.659479 [debug] [Thread-3  ]: On model.maker_warehouse.no_of_viewings: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.no_of_viewings"} */
alter table "mydb"."dbt_warehouse"."no_of_viewings__dbt_tmp" rename to "no_of_viewings"
[0m12:05:55.664780 [debug] [Thread-3  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:05:55.734132 [debug] [Thread-3  ]: On model.maker_warehouse.no_of_viewings: COMMIT
[0m12:05:55.735550 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.no_of_viewings"
[0m12:05:55.736568 [debug] [Thread-3  ]: On model.maker_warehouse.no_of_viewings: COMMIT
[0m12:05:55.740932 [debug] [Thread-3  ]: SQL status: COMMIT in 0.0 seconds
[0m12:05:55.757337 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.no_of_viewings"
[0m12:05:55.758475 [debug] [Thread-3  ]: On model.maker_warehouse.no_of_viewings: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.no_of_viewings"} */
drop table if exists "mydb"."dbt_warehouse"."no_of_viewings__dbt_backup" cascade
[0m12:05:55.769089 [debug] [Thread-3  ]: SQL status: DROP TABLE in 0.0 seconds
[0m12:05:55.773198 [debug] [Thread-3  ]: Timing info for model.maker_warehouse.no_of_viewings (execute): 12:05:53.852429 => 12:05:55.772504
[0m12:05:55.774052 [debug] [Thread-3  ]: On model.maker_warehouse.no_of_viewings: Close
[0m12:05:55.776163 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '09660a19-88ee-43af-bcf5-b3d79f743d9f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10744bb80>]}
[0m12:05:55.778393 [info ] [Thread-3  ]: 3 of 9 OK created sql table model dbt_warehouse.no_of_viewings ................. [[32mSELECT 7925[0m in 2.04s]
[0m12:05:55.780937 [debug] [Thread-3  ]: Finished running node model.maker_warehouse.no_of_viewings
[0m12:05:55.782609 [debug] [Thread-3  ]: Began running node model.maker_warehouse.total_unique_users
[0m12:05:55.784247 [info ] [Thread-3  ]: 5 of 9 START sql table model dbt_warehouse.total_unique_users .................. [RUN]
[0m12:05:55.786416 [debug] [Thread-3  ]: Re-using an available connection from the pool (formerly model.maker_warehouse.no_of_viewings, now model.maker_warehouse.total_unique_users)
[0m12:05:55.787505 [debug] [Thread-3  ]: Began compiling node model.maker_warehouse.total_unique_users
[0m12:05:55.798257 [debug] [Thread-3  ]: Writing injected SQL for node "model.maker_warehouse.total_unique_users"
[0m12:05:55.801112 [debug] [Thread-3  ]: Timing info for model.maker_warehouse.total_unique_users (compile): 12:05:55.788463 => 12:05:55.800307
[0m12:05:55.802366 [debug] [Thread-3  ]: Began executing node model.maker_warehouse.total_unique_users
[0m12:05:55.819089 [debug] [Thread-3  ]: Writing runtime sql for node "model.maker_warehouse.total_unique_users"
[0m12:05:55.820463 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.total_unique_users"
[0m12:05:55.821981 [debug] [Thread-3  ]: On model.maker_warehouse.total_unique_users: BEGIN
[0m12:05:55.823015 [debug] [Thread-3  ]: Opening a new connection, currently in state closed
[0m12:05:55.854266 [debug] [Thread-1  ]: SQL status: SELECT 7925 in 2.0 seconds
[0m12:05:55.865055 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.avg_viewing_time"
[0m12:05:55.866184 [debug] [Thread-1  ]: On model.maker_warehouse.avg_viewing_time: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.avg_viewing_time"} */
alter table "mydb"."dbt_warehouse"."avg_viewing_time" rename to "avg_viewing_time__dbt_backup"
[0m12:05:55.871003 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:05:55.880796 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.avg_viewing_time"
[0m12:05:55.882415 [debug] [Thread-1  ]: On model.maker_warehouse.avg_viewing_time: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.avg_viewing_time"} */
alter table "mydb"."dbt_warehouse"."avg_viewing_time__dbt_tmp" rename to "avg_viewing_time"
[0m12:05:55.890895 [debug] [Thread-3  ]: SQL status: BEGIN in 0.0 seconds
[0m12:05:55.892131 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:05:55.893808 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.total_unique_users"
[0m12:05:55.900999 [debug] [Thread-1  ]: On model.maker_warehouse.avg_viewing_time: COMMIT
[0m12:05:55.902569 [debug] [Thread-3  ]: On model.maker_warehouse.total_unique_users: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_unique_users"} */

  
    

  create  table "mydb"."dbt_warehouse"."total_unique_users__dbt_tmp"
  
  
    as
  
  (
    
SELECT 
COUNT(DISTINCT(user_id)) AS total_unique_users
FROM mydb.public.raw_netflix
  );
  
[0m12:05:55.904162 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.avg_viewing_time"
[0m12:05:55.905908 [debug] [Thread-1  ]: On model.maker_warehouse.avg_viewing_time: COMMIT
[0m12:05:55.912758 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
[0m12:05:55.919656 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.avg_viewing_time"
[0m12:05:55.920879 [debug] [Thread-1  ]: On model.maker_warehouse.avg_viewing_time: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.avg_viewing_time"} */
drop table if exists "mydb"."dbt_warehouse"."avg_viewing_time__dbt_backup" cascade
[0m12:05:55.959809 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
[0m12:05:55.965062 [debug] [Thread-1  ]: Timing info for model.maker_warehouse.avg_viewing_time (execute): 12:05:53.827781 => 12:05:55.964480
[0m12:05:55.966114 [debug] [Thread-1  ]: On model.maker_warehouse.avg_viewing_time: Close
[0m12:05:55.971137 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '09660a19-88ee-43af-bcf5-b3d79f743d9f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1072bf130>]}
[0m12:05:55.972697 [info ] [Thread-1  ]: 1 of 9 OK created sql table model dbt_warehouse.avg_viewing_time ............... [[32mSELECT 7925[0m in 2.24s]
[0m12:05:55.973867 [debug] [Thread-1  ]: Finished running node model.maker_warehouse.avg_viewing_time
[0m12:05:55.974741 [debug] [Thread-1  ]: Began running node model.maker_warehouse.total_viewing_time
[0m12:05:55.975423 [info ] [Thread-1  ]: 6 of 9 START sql table model dbt_warehouse.total_viewing_time .................. [RUN]
[0m12:05:55.978070 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.maker_warehouse.avg_viewing_time, now model.maker_warehouse.total_viewing_time)
[0m12:05:55.979083 [debug] [Thread-1  ]: Began compiling node model.maker_warehouse.total_viewing_time
[0m12:05:55.987949 [debug] [Thread-1  ]: Writing injected SQL for node "model.maker_warehouse.total_viewing_time"
[0m12:05:55.990398 [debug] [Thread-1  ]: Timing info for model.maker_warehouse.total_viewing_time (compile): 12:05:55.979497 => 12:05:55.989737
[0m12:05:55.991486 [debug] [Thread-1  ]: Began executing node model.maker_warehouse.total_viewing_time
[0m12:05:56.007642 [debug] [Thread-1  ]: Writing runtime sql for node "model.maker_warehouse.total_viewing_time"
[0m12:05:56.012266 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.total_viewing_time"
[0m12:05:56.013389 [debug] [Thread-1  ]: On model.maker_warehouse.total_viewing_time: BEGIN
[0m12:05:56.014442 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m12:05:56.090545 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
[0m12:05:56.092509 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.total_viewing_time"
[0m12:05:56.093711 [debug] [Thread-1  ]: On model.maker_warehouse.total_viewing_time: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_viewing_time"} */

  
    

  create  table "mydb"."dbt_warehouse"."total_viewing_time__dbt_tmp"
  
  
    as
  
  (
    
SELECT
title,
SUM(duration) as total_duration
FROM mydb.public.raw_netflix
GROUP BY title
ORDER BY total_duration DESC
  );
  
[0m12:05:57.676724 [debug] [Thread-1  ]: SQL status: SELECT 7925 in 2.0 seconds
[0m12:05:57.685794 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.total_viewing_time"
[0m12:05:57.687128 [debug] [Thread-1  ]: On model.maker_warehouse.total_viewing_time: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_viewing_time"} */
alter table "mydb"."dbt_warehouse"."total_viewing_time" rename to "total_viewing_time__dbt_backup"
[0m12:05:57.692887 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:05:57.701969 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.total_viewing_time"
[0m12:05:57.703072 [debug] [Thread-1  ]: On model.maker_warehouse.total_viewing_time: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_viewing_time"} */
alter table "mydb"."dbt_warehouse"."total_viewing_time__dbt_tmp" rename to "total_viewing_time"
[0m12:05:57.707820 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:05:57.715481 [debug] [Thread-1  ]: On model.maker_warehouse.total_viewing_time: COMMIT
[0m12:05:57.716536 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.total_viewing_time"
[0m12:05:57.717428 [debug] [Thread-1  ]: On model.maker_warehouse.total_viewing_time: COMMIT
[0m12:05:57.726370 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
[0m12:05:57.735120 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.total_viewing_time"
[0m12:05:57.735957 [debug] [Thread-1  ]: On model.maker_warehouse.total_viewing_time: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_viewing_time"} */
drop table if exists "mydb"."dbt_warehouse"."total_viewing_time__dbt_backup" cascade
[0m12:05:57.755123 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
[0m12:05:57.758829 [debug] [Thread-1  ]: Timing info for model.maker_warehouse.total_viewing_time (execute): 12:05:55.992117 => 12:05:57.758412
[0m12:05:57.760004 [debug] [Thread-1  ]: On model.maker_warehouse.total_viewing_time: Close
[0m12:05:57.762144 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '09660a19-88ee-43af-bcf5-b3d79f743d9f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1073dd5e0>]}
[0m12:05:57.763347 [info ] [Thread-1  ]: 6 of 9 OK created sql table model dbt_warehouse.total_viewing_time ............. [[32mSELECT 7925[0m in 1.78s]
[0m12:05:57.766834 [debug] [Thread-1  ]: Finished running node model.maker_warehouse.total_viewing_time
[0m12:05:57.768768 [debug] [Thread-1  ]: Began running node model.maker_warehouse.total_viewings_year_month
[0m12:05:57.772021 [info ] [Thread-1  ]: 7 of 9 START sql table model dbt_warehouse.total_viewings_year_month ........... [RUN]
[0m12:05:57.774004 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.maker_warehouse.total_viewing_time, now model.maker_warehouse.total_viewings_year_month)
[0m12:05:57.775649 [debug] [Thread-1  ]: Began compiling node model.maker_warehouse.total_viewings_year_month
[0m12:05:57.789748 [debug] [Thread-1  ]: Writing injected SQL for node "model.maker_warehouse.total_viewings_year_month"
[0m12:05:57.791766 [debug] [Thread-1  ]: Timing info for model.maker_warehouse.total_viewings_year_month (compile): 12:05:57.776777 => 12:05:57.791116
[0m12:05:57.793145 [debug] [Thread-1  ]: Began executing node model.maker_warehouse.total_viewings_year_month
[0m12:05:57.809723 [debug] [Thread-1  ]: Writing runtime sql for node "model.maker_warehouse.total_viewings_year_month"
[0m12:05:57.811638 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.total_viewings_year_month"
[0m12:05:57.812877 [debug] [Thread-1  ]: On model.maker_warehouse.total_viewings_year_month: BEGIN
[0m12:05:57.813891 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m12:05:57.872579 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
[0m12:05:57.873953 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.total_viewings_year_month"
[0m12:05:57.875054 [debug] [Thread-1  ]: On model.maker_warehouse.total_viewings_year_month: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_viewings_year_month"} */

  
    

  create  table "mydb"."dbt_warehouse"."total_viewings_year_month__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    EXTRACT(YEAR FROM CAST("datetime" AS DATE)) AS "Year",
    EXTRACT(MONTH FROM CAST("datetime" AS DATE)) AS "Month",
    COUNT(*) AS "Total_Views"
FROM mydb.public.raw_netflix
GROUP BY
    EXTRACT(YEAR FROM CAST("datetime" AS DATE)),
    EXTRACT(MONTH FROM CAST("datetime" AS DATE))
ORDER BY
    "Year", "Month"
  );
  
[0m12:05:59.256743 [debug] [Thread-4  ]: SQL status: SELECT 30 in 5.0 seconds
[0m12:05:59.267935 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.total_duration_year_month"
[0m12:05:59.269304 [debug] [Thread-4  ]: On model.maker_warehouse.total_duration_year_month: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_duration_year_month"} */
alter table "mydb"."dbt_warehouse"."total_duration_year_month__dbt_tmp" rename to "total_duration_year_month"
[0m12:05:59.274034 [debug] [Thread-4  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:05:59.280155 [debug] [Thread-4  ]: On model.maker_warehouse.total_duration_year_month: COMMIT
[0m12:05:59.281386 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.total_duration_year_month"
[0m12:05:59.282706 [debug] [Thread-4  ]: On model.maker_warehouse.total_duration_year_month: COMMIT
[0m12:05:59.289215 [debug] [Thread-4  ]: SQL status: COMMIT in 0.0 seconds
[0m12:05:59.297158 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.total_duration_year_month"
[0m12:05:59.298351 [debug] [Thread-4  ]: On model.maker_warehouse.total_duration_year_month: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_duration_year_month"} */
drop table if exists "mydb"."dbt_warehouse"."total_duration_year_month__dbt_backup" cascade
[0m12:05:59.302762 [debug] [Thread-4  ]: SQL status: DROP TABLE in 0.0 seconds
[0m12:05:59.308788 [debug] [Thread-4  ]: Timing info for model.maker_warehouse.total_duration_year_month (execute): 12:05:53.949566 => 12:05:59.307597
[0m12:05:59.310394 [debug] [Thread-4  ]: On model.maker_warehouse.total_duration_year_month: Close
[0m12:05:59.312751 [debug] [Thread-4  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '09660a19-88ee-43af-bcf5-b3d79f743d9f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10737ea30>]}
[0m12:05:59.314337 [info ] [Thread-4  ]: 4 of 9 OK created sql table model dbt_warehouse.total_duration_year_month ...... [[32mSELECT 30[0m in 5.58s]
[0m12:05:59.317197 [debug] [Thread-4  ]: Finished running node model.maker_warehouse.total_duration_year_month
[0m12:05:59.319189 [debug] [Thread-4  ]: Began running node model.maker_warehouse.user_engagement
[0m12:05:59.320609 [info ] [Thread-4  ]: 8 of 9 START sql table model dbt_warehouse.user_engagement ..................... [RUN]
[0m12:05:59.323440 [debug] [Thread-4  ]: Re-using an available connection from the pool (formerly model.maker_warehouse.total_duration_year_month, now model.maker_warehouse.user_engagement)
[0m12:05:59.324473 [debug] [Thread-4  ]: Began compiling node model.maker_warehouse.user_engagement
[0m12:05:59.333921 [debug] [Thread-4  ]: Writing injected SQL for node "model.maker_warehouse.user_engagement"
[0m12:05:59.341526 [debug] [Thread-4  ]: Timing info for model.maker_warehouse.user_engagement (compile): 12:05:59.325019 => 12:05:59.337644
[0m12:05:59.343219 [debug] [Thread-4  ]: Began executing node model.maker_warehouse.user_engagement
[0m12:05:59.360507 [debug] [Thread-4  ]: Writing runtime sql for node "model.maker_warehouse.user_engagement"
[0m12:05:59.363398 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.user_engagement"
[0m12:05:59.364658 [debug] [Thread-4  ]: On model.maker_warehouse.user_engagement: BEGIN
[0m12:05:59.366429 [debug] [Thread-4  ]: Opening a new connection, currently in state closed
[0m12:05:59.434556 [debug] [Thread-4  ]: SQL status: BEGIN in 0.0 seconds
[0m12:05:59.435895 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.user_engagement"
[0m12:05:59.436517 [debug] [Thread-4  ]: On model.maker_warehouse.user_engagement: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.user_engagement"} */

  
    

  create  table "mydb"."dbt_warehouse"."user_engagement__dbt_tmp"
  
  
    as
  
  (
    
SELECT 
DISTINCT(user_id),
COUNT(DISTINCT(title)) AS total_titles,
SUM(duration) AS total_duration
FROM mydb.public.raw_netflix
GROUP BY user_id
  );
  
[0m12:05:59.523836 [debug] [Thread-2  ]: SQL status: SELECT 8472 in 5.0 seconds
[0m12:05:59.534998 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.movies"
[0m12:05:59.536322 [debug] [Thread-2  ]: On model.maker_warehouse.movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.movies"} */
alter table "mydb"."dbt_warehouse"."movies" rename to "movies__dbt_backup"
[0m12:05:59.542987 [debug] [Thread-2  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:05:59.551901 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.movies"
[0m12:05:59.552967 [debug] [Thread-2  ]: On model.maker_warehouse.movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.movies"} */
alter table "mydb"."dbt_warehouse"."movies__dbt_tmp" rename to "movies"
[0m12:05:59.556774 [debug] [Thread-2  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:05:59.562629 [debug] [Thread-2  ]: On model.maker_warehouse.movies: COMMIT
[0m12:05:59.563753 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.movies"
[0m12:05:59.564791 [debug] [Thread-2  ]: On model.maker_warehouse.movies: COMMIT
[0m12:05:59.571826 [debug] [Thread-2  ]: SQL status: COMMIT in 0.0 seconds
[0m12:05:59.579265 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.movies"
[0m12:05:59.580367 [debug] [Thread-2  ]: On model.maker_warehouse.movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.movies"} */
drop table if exists "mydb"."dbt_warehouse"."movies__dbt_backup" cascade
[0m12:05:59.601021 [debug] [Thread-2  ]: SQL status: DROP TABLE in 0.0 seconds
[0m12:05:59.605250 [debug] [Thread-2  ]: Timing info for model.maker_warehouse.movies (execute): 12:05:53.789922 => 12:05:59.604606
[0m12:05:59.606778 [debug] [Thread-2  ]: On model.maker_warehouse.movies: Close
[0m12:05:59.609192 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '09660a19-88ee-43af-bcf5-b3d79f743d9f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10740ba00>]}
[0m12:05:59.611116 [info ] [Thread-2  ]: 2 of 9 OK created sql table model dbt_warehouse.movies ......................... [[32mSELECT 8472[0m in 5.88s]
[0m12:05:59.613342 [debug] [Thread-2  ]: Finished running node model.maker_warehouse.movies
[0m12:05:59.614928 [debug] [Thread-2  ]: Began running node model.maker_warehouse.all_movies
[0m12:05:59.616265 [info ] [Thread-2  ]: 9 of 9 START sql table model dbt_warehouse.all_movies .......................... [RUN]
[0m12:05:59.618412 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly model.maker_warehouse.movies, now model.maker_warehouse.all_movies)
[0m12:05:59.619534 [debug] [Thread-2  ]: Began compiling node model.maker_warehouse.all_movies
[0m12:05:59.632409 [debug] [Thread-2  ]: Writing injected SQL for node "model.maker_warehouse.all_movies"
[0m12:05:59.635180 [debug] [Thread-2  ]: Timing info for model.maker_warehouse.all_movies (compile): 12:05:59.620484 => 12:05:59.634534
[0m12:05:59.636226 [debug] [Thread-2  ]: Began executing node model.maker_warehouse.all_movies
[0m12:05:59.656297 [debug] [Thread-2  ]: Writing runtime sql for node "model.maker_warehouse.all_movies"
[0m12:05:59.658165 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.all_movies"
[0m12:05:59.659481 [debug] [Thread-2  ]: On model.maker_warehouse.all_movies: BEGIN
[0m12:05:59.660559 [debug] [Thread-2  ]: Opening a new connection, currently in state closed
[0m12:05:59.722363 [debug] [Thread-2  ]: SQL status: BEGIN in 0.0 seconds
[0m12:05:59.723756 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.all_movies"
[0m12:05:59.725200 [debug] [Thread-2  ]: On model.maker_warehouse.all_movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.all_movies"} */

  
    

  create  table "mydb"."dbt_warehouse"."all_movies__dbt_tmp"
  
  
    as
  
  (
    
  
SELECT
*
FROM "mydb"."dbt_warehouse"."movies"
  );
  
[0m12:05:59.797516 [debug] [Thread-2  ]: SQL status: SELECT 8472 in 0.0 seconds
[0m12:05:59.809503 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.all_movies"
[0m12:05:59.810828 [debug] [Thread-2  ]: On model.maker_warehouse.all_movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.all_movies"} */
alter table "mydb"."dbt_warehouse"."all_movies" rename to "all_movies__dbt_backup"
[0m12:05:59.817770 [debug] [Thread-2  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:05:59.829542 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.all_movies"
[0m12:05:59.830673 [debug] [Thread-2  ]: On model.maker_warehouse.all_movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.all_movies"} */
alter table "mydb"."dbt_warehouse"."all_movies__dbt_tmp" rename to "all_movies"
[0m12:05:59.835297 [debug] [Thread-2  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:05:59.843458 [debug] [Thread-2  ]: On model.maker_warehouse.all_movies: COMMIT
[0m12:05:59.844804 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.all_movies"
[0m12:05:59.846176 [debug] [Thread-2  ]: On model.maker_warehouse.all_movies: COMMIT
[0m12:05:59.855022 [debug] [Thread-2  ]: SQL status: COMMIT in 0.0 seconds
[0m12:05:59.863368 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.all_movies"
[0m12:05:59.864895 [debug] [Thread-2  ]: On model.maker_warehouse.all_movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.all_movies"} */
drop table if exists "mydb"."dbt_warehouse"."all_movies__dbt_backup" cascade
[0m12:05:59.922448 [debug] [Thread-2  ]: SQL status: DROP TABLE in 0.0 seconds
[0m12:05:59.928260 [debug] [Thread-2  ]: Timing info for model.maker_warehouse.all_movies (execute): 12:05:59.637898 => 12:05:59.926707
[0m12:05:59.930104 [debug] [Thread-2  ]: On model.maker_warehouse.all_movies: Close
[0m12:05:59.932278 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '09660a19-88ee-43af-bcf5-b3d79f743d9f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1074913d0>]}
[0m12:05:59.934104 [info ] [Thread-2  ]: 9 of 9 OK created sql table model dbt_warehouse.all_movies ..................... [[32mSELECT 8472[0m in 0.31s]
[0m12:05:59.936251 [debug] [Thread-2  ]: Finished running node model.maker_warehouse.all_movies
[0m12:06:02.579686 [debug] [Thread-1  ]: SQL status: SELECT 30 in 5.0 seconds
[0m12:06:02.585978 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.total_viewings_year_month"
[0m12:06:02.587215 [debug] [Thread-1  ]: On model.maker_warehouse.total_viewings_year_month: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_viewings_year_month"} */
alter table "mydb"."dbt_warehouse"."total_viewings_year_month" rename to "total_viewings_year_month__dbt_backup"
[0m12:06:02.592061 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:06:02.597915 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.total_viewings_year_month"
[0m12:06:02.598575 [debug] [Thread-1  ]: On model.maker_warehouse.total_viewings_year_month: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_viewings_year_month"} */
alter table "mydb"."dbt_warehouse"."total_viewings_year_month__dbt_tmp" rename to "total_viewings_year_month"
[0m12:06:02.602582 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:06:02.608725 [debug] [Thread-1  ]: On model.maker_warehouse.total_viewings_year_month: COMMIT
[0m12:06:02.610084 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.total_viewings_year_month"
[0m12:06:02.611157 [debug] [Thread-1  ]: On model.maker_warehouse.total_viewings_year_month: COMMIT
[0m12:06:02.619332 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
[0m12:06:02.623755 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.total_viewings_year_month"
[0m12:06:02.624397 [debug] [Thread-1  ]: On model.maker_warehouse.total_viewings_year_month: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_viewings_year_month"} */
drop table if exists "mydb"."dbt_warehouse"."total_viewings_year_month__dbt_backup" cascade
[0m12:06:02.643283 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
[0m12:06:02.646853 [debug] [Thread-1  ]: Timing info for model.maker_warehouse.total_viewings_year_month (execute): 12:05:57.794095 => 12:06:02.646239
[0m12:06:02.647624 [debug] [Thread-1  ]: On model.maker_warehouse.total_viewings_year_month: Close
[0m12:06:02.649529 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '09660a19-88ee-43af-bcf5-b3d79f743d9f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1074308e0>]}
[0m12:06:02.651088 [info ] [Thread-1  ]: 7 of 9 OK created sql table model dbt_warehouse.total_viewings_year_month ...... [[32mSELECT 30[0m in 4.88s]
[0m12:06:02.653499 [debug] [Thread-1  ]: Finished running node model.maker_warehouse.total_viewings_year_month
[0m12:06:02.840856 [debug] [Thread-3  ]: SQL status: SELECT 1 in 7.0 seconds
[0m12:06:02.848556 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.total_unique_users"
[0m12:06:02.849756 [debug] [Thread-3  ]: On model.maker_warehouse.total_unique_users: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_unique_users"} */
alter table "mydb"."dbt_warehouse"."total_unique_users" rename to "total_unique_users__dbt_backup"
[0m12:06:02.853253 [debug] [Thread-3  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:06:02.863492 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.total_unique_users"
[0m12:06:02.864217 [debug] [Thread-3  ]: On model.maker_warehouse.total_unique_users: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_unique_users"} */
alter table "mydb"."dbt_warehouse"."total_unique_users__dbt_tmp" rename to "total_unique_users"
[0m12:06:02.868048 [debug] [Thread-3  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:06:02.872950 [debug] [Thread-3  ]: On model.maker_warehouse.total_unique_users: COMMIT
[0m12:06:02.873785 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.total_unique_users"
[0m12:06:02.874371 [debug] [Thread-3  ]: On model.maker_warehouse.total_unique_users: COMMIT
[0m12:06:02.878489 [debug] [Thread-3  ]: SQL status: COMMIT in 0.0 seconds
[0m12:06:02.884304 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.total_unique_users"
[0m12:06:02.885322 [debug] [Thread-3  ]: On model.maker_warehouse.total_unique_users: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_unique_users"} */
drop table if exists "mydb"."dbt_warehouse"."total_unique_users__dbt_backup" cascade
[0m12:06:02.899780 [debug] [Thread-3  ]: SQL status: DROP TABLE in 0.0 seconds
[0m12:06:02.903461 [debug] [Thread-3  ]: Timing info for model.maker_warehouse.total_unique_users (execute): 12:05:55.803065 => 12:06:02.902348
[0m12:06:02.904793 [debug] [Thread-3  ]: On model.maker_warehouse.total_unique_users: Close
[0m12:06:02.909318 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '09660a19-88ee-43af-bcf5-b3d79f743d9f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1074746d0>]}
[0m12:06:02.912397 [info ] [Thread-3  ]: 5 of 9 OK created sql table model dbt_warehouse.total_unique_users ............. [[32mSELECT 1[0m in 7.12s]
[0m12:06:02.914398 [debug] [Thread-3  ]: Finished running node model.maker_warehouse.total_unique_users
[0m12:06:05.107846 [debug] [Thread-4  ]: SQL status: SELECT 161918 in 6.0 seconds
[0m12:06:05.114398 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.user_engagement"
[0m12:06:05.115049 [debug] [Thread-4  ]: On model.maker_warehouse.user_engagement: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.user_engagement"} */
alter table "mydb"."dbt_warehouse"."user_engagement" rename to "user_engagement__dbt_backup"
[0m12:06:05.119228 [debug] [Thread-4  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:06:05.125596 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.user_engagement"
[0m12:06:05.127401 [debug] [Thread-4  ]: On model.maker_warehouse.user_engagement: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.user_engagement"} */
alter table "mydb"."dbt_warehouse"."user_engagement__dbt_tmp" rename to "user_engagement"
[0m12:06:05.131109 [debug] [Thread-4  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:06:05.136371 [debug] [Thread-4  ]: On model.maker_warehouse.user_engagement: COMMIT
[0m12:06:05.137032 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.user_engagement"
[0m12:06:05.137589 [debug] [Thread-4  ]: On model.maker_warehouse.user_engagement: COMMIT
[0m12:06:05.369240 [debug] [Thread-4  ]: SQL status: COMMIT in 0.0 seconds
[0m12:06:05.374124 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.user_engagement"
[0m12:06:05.374760 [debug] [Thread-4  ]: On model.maker_warehouse.user_engagement: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.user_engagement"} */
drop table if exists "mydb"."dbt_warehouse"."user_engagement__dbt_backup" cascade
[0m12:06:05.385992 [debug] [Thread-4  ]: SQL status: DROP TABLE in 0.0 seconds
[0m12:06:05.389394 [debug] [Thread-4  ]: Timing info for model.maker_warehouse.user_engagement (execute): 12:05:59.344389 => 12:06:05.389071
[0m12:06:05.390071 [debug] [Thread-4  ]: On model.maker_warehouse.user_engagement: Close
[0m12:06:05.391473 [debug] [Thread-4  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '09660a19-88ee-43af-bcf5-b3d79f743d9f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1072bf220>]}
[0m12:06:05.392704 [info ] [Thread-4  ]: 8 of 9 OK created sql table model dbt_warehouse.user_engagement ................ [[32mSELECT 161918[0m in 6.07s]
[0m12:06:05.395206 [debug] [Thread-4  ]: Finished running node model.maker_warehouse.user_engagement
[0m12:06:05.398406 [debug] [MainThread]: Using postgres connection "master"
[0m12:06:05.399026 [debug] [MainThread]: On master: BEGIN
[0m12:06:05.399500 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m12:06:05.435906 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m12:06:05.436583 [debug] [MainThread]: On master: COMMIT
[0m12:06:05.437068 [debug] [MainThread]: Using postgres connection "master"
[0m12:06:05.437528 [debug] [MainThread]: On master: COMMIT
[0m12:06:05.439357 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m12:06:05.439969 [debug] [MainThread]: On master: Close
[0m12:06:05.441029 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:06:05.441693 [debug] [MainThread]: Connection 'model.maker_warehouse.total_viewings_year_month' was properly closed.
[0m12:06:05.442483 [debug] [MainThread]: Connection 'model.maker_warehouse.all_movies' was properly closed.
[0m12:06:05.443224 [debug] [MainThread]: Connection 'model.maker_warehouse.total_unique_users' was properly closed.
[0m12:06:05.444246 [debug] [MainThread]: Connection 'model.maker_warehouse.user_engagement' was properly closed.
[0m12:06:05.445005 [info ] [MainThread]: 
[0m12:06:05.446154 [info ] [MainThread]: Finished running 9 table models in 0 hours 0 minutes and 12.11 seconds (12.11s).
[0m12:06:05.453572 [debug] [MainThread]: Command end result
[0m12:06:05.471039 [info ] [MainThread]: 
[0m12:06:05.472297 [info ] [MainThread]: [32mCompleted successfully[0m
[0m12:06:05.473038 [info ] [MainThread]: 
[0m12:06:05.474013 [info ] [MainThread]: Done. PASS=9 WARN=0 ERROR=0 SKIP=0 TOTAL=9
[0m12:06:05.476492 [debug] [MainThread]: Command `dbt run` succeeded at 12:06:05.476057 after 12.83 seconds
[0m12:06:05.480121 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105a144f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1073f0a30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107014a00>]}
[0m12:06:05.481008 [debug] [MainThread]: Flushing usage events
[0m12:08:58.146031 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109f0cf40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b2a62b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107a9f790>]}


============================== 12:08:58.155170 | 35415c32-438d-4eff-9892-74500dc034c5 ==============================
[0m12:08:58.155170 [info ] [MainThread]: Running with dbt=1.5.4
[0m12:08:58.156860 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/Users/denisechan/Documents/Makers/Data_Engineering/Week_6/dbt_warehouse/logs', 'debug': 'False', 'profiles_dir': '/Users/denisechan/Documents/Makers/Data_Engineering/Week_6/dbt_warehouse', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'send_anonymous_usage_stats': 'True'}
[0m12:08:58.305882 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '35415c32-438d-4eff-9892-74500dc034c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b2a6a00>]}
[0m12:08:58.349214 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '35415c32-438d-4eff-9892-74500dc034c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b50c700>]}
[0m12:08:58.352092 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m12:08:58.392242 [debug] [MainThread]: checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, vars: {}, profile: , target: , version: 1.5.4
[0m12:08:58.567260 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
[0m12:08:58.568173 [debug] [MainThread]: Partial parsing: added file: maker_warehouse://models/summary/avg_duration_year_month.sql
[0m12:08:58.623430 [debug] [MainThread]: 1699: static parser successfully parsed summary/avg_duration_year_month.sql
[0m12:08:58.661810 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '35415c32-438d-4eff-9892-74500dc034c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b7e40d0>]}
[0m12:08:58.676809 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '35415c32-438d-4eff-9892-74500dc034c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b727e50>]}
[0m12:08:58.677741 [info ] [MainThread]: Found 10 models, 0 tests, 0 snapshots, 0 analyses, 307 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics, 0 groups
[0m12:08:58.678604 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '35415c32-438d-4eff-9892-74500dc034c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b727df0>]}
[0m12:08:58.681989 [info ] [MainThread]: 
[0m12:08:58.683483 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m12:08:58.685816 [debug] [ThreadPool]: Acquiring new postgres connection 'list_mydb'
[0m12:08:58.705005 [debug] [ThreadPool]: Using postgres connection "list_mydb"
[0m12:08:58.705901 [debug] [ThreadPool]: On list_mydb: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "connection_name": "list_mydb"} */

    select distinct nspname from pg_namespace
  
[0m12:08:58.707193 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:08:58.908616 [debug] [ThreadPool]: SQL status: SELECT 5 in 0.0 seconds
[0m12:08:58.914983 [debug] [ThreadPool]: On list_mydb: Close
[0m12:08:58.919232 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_mydb, now list_mydb_dbt_warehouse)
[0m12:08:58.936202 [debug] [ThreadPool]: Using postgres connection "list_mydb_dbt_warehouse"
[0m12:08:58.936936 [debug] [ThreadPool]: On list_mydb_dbt_warehouse: BEGIN
[0m12:08:58.937585 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:08:58.971820 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m12:08:58.973278 [debug] [ThreadPool]: Using postgres connection "list_mydb_dbt_warehouse"
[0m12:08:58.974261 [debug] [ThreadPool]: On list_mydb_dbt_warehouse: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "connection_name": "list_mydb_dbt_warehouse"} */
select
      'mydb' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_warehouse'
    union all
    select
      'mydb' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_warehouse'
  
[0m12:08:58.992387 [debug] [ThreadPool]: SQL status: SELECT 10 in 0.0 seconds
[0m12:08:58.995202 [debug] [ThreadPool]: On list_mydb_dbt_warehouse: ROLLBACK
[0m12:08:58.997993 [debug] [ThreadPool]: On list_mydb_dbt_warehouse: Close
[0m12:08:59.020102 [debug] [MainThread]: Using postgres connection "master"
[0m12:08:59.020807 [debug] [MainThread]: On master: BEGIN
[0m12:08:59.021561 [debug] [MainThread]: Opening a new connection, currently in state init
[0m12:08:59.054289 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m12:08:59.055146 [debug] [MainThread]: Using postgres connection "master"
[0m12:08:59.055806 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m12:08:59.079056 [debug] [MainThread]: SQL status: SELECT 5 in 0.0 seconds
[0m12:08:59.081196 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '35415c32-438d-4eff-9892-74500dc034c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b7f4df0>]}
[0m12:08:59.081895 [debug] [MainThread]: On master: ROLLBACK
[0m12:08:59.083604 [debug] [MainThread]: Using postgres connection "master"
[0m12:08:59.084264 [debug] [MainThread]: On master: BEGIN
[0m12:08:59.088618 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m12:08:59.089501 [debug] [MainThread]: On master: COMMIT
[0m12:08:59.090313 [debug] [MainThread]: Using postgres connection "master"
[0m12:08:59.091453 [debug] [MainThread]: On master: COMMIT
[0m12:08:59.093882 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m12:08:59.094729 [debug] [MainThread]: On master: Close
[0m12:08:59.096425 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m12:08:59.097514 [info ] [MainThread]: 
[0m12:08:59.108519 [debug] [Thread-1  ]: Began running node model.maker_warehouse.avg_duration_year_month
[0m12:08:59.109295 [debug] [Thread-2  ]: Began running node model.maker_warehouse.avg_viewing_time
[0m12:08:59.110054 [debug] [Thread-3  ]: Began running node model.maker_warehouse.movies
[0m12:08:59.110956 [debug] [Thread-4  ]: Began running node model.maker_warehouse.no_of_viewings
[0m12:08:59.112686 [info ] [Thread-1  ]: 1 of 10 START sql table model dbt_warehouse.avg_duration_year_month ............ [RUN]
[0m12:08:59.114166 [info ] [Thread-2  ]: 2 of 10 START sql table model dbt_warehouse.avg_viewing_time ................... [RUN]
[0m12:08:59.115437 [info ] [Thread-3  ]: 3 of 10 START sql table model dbt_warehouse.movies ............................. [RUN]
[0m12:08:59.116468 [info ] [Thread-4  ]: 4 of 10 START sql table model dbt_warehouse.no_of_viewings ..................... [RUN]
[0m12:08:59.117785 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_mydb_dbt_warehouse, now model.maker_warehouse.avg_duration_year_month)
[0m12:08:59.118997 [debug] [Thread-2  ]: Acquiring new postgres connection 'model.maker_warehouse.avg_viewing_time'
[0m12:08:59.120235 [debug] [Thread-3  ]: Acquiring new postgres connection 'model.maker_warehouse.movies'
[0m12:08:59.121317 [debug] [Thread-4  ]: Acquiring new postgres connection 'model.maker_warehouse.no_of_viewings'
[0m12:08:59.121961 [debug] [Thread-1  ]: Began compiling node model.maker_warehouse.avg_duration_year_month
[0m12:08:59.122691 [debug] [Thread-2  ]: Began compiling node model.maker_warehouse.avg_viewing_time
[0m12:08:59.123593 [debug] [Thread-3  ]: Began compiling node model.maker_warehouse.movies
[0m12:08:59.124411 [debug] [Thread-4  ]: Began compiling node model.maker_warehouse.no_of_viewings
[0m12:08:59.142594 [debug] [Thread-1  ]: Writing injected SQL for node "model.maker_warehouse.avg_duration_year_month"
[0m12:08:59.149913 [debug] [Thread-2  ]: Writing injected SQL for node "model.maker_warehouse.avg_viewing_time"
[0m12:08:59.168650 [debug] [Thread-4  ]: Writing injected SQL for node "model.maker_warehouse.no_of_viewings"
[0m12:08:59.170655 [debug] [Thread-3  ]: Writing injected SQL for node "model.maker_warehouse.movies"
[0m12:08:59.173351 [debug] [Thread-1  ]: Timing info for model.maker_warehouse.avg_duration_year_month (compile): 12:08:59.125077 => 12:08:59.172681
[0m12:08:59.174784 [debug] [Thread-1  ]: Began executing node model.maker_warehouse.avg_duration_year_month
[0m12:08:59.198214 [debug] [Thread-2  ]: Timing info for model.maker_warehouse.avg_viewing_time (compile): 12:08:59.143015 => 12:08:59.197770
[0m12:08:59.216053 [debug] [Thread-2  ]: Began executing node model.maker_warehouse.avg_viewing_time
[0m12:08:59.216986 [debug] [Thread-4  ]: Timing info for model.maker_warehouse.no_of_viewings (compile): 12:08:59.159775 => 12:08:59.216536
[0m12:08:59.217618 [debug] [Thread-3  ]: Timing info for model.maker_warehouse.movies (compile): 12:08:59.151527 => 12:08:59.217318
[0m12:08:59.272716 [debug] [Thread-4  ]: Began executing node model.maker_warehouse.no_of_viewings
[0m12:08:59.273896 [debug] [Thread-1  ]: Writing runtime sql for node "model.maker_warehouse.avg_duration_year_month"
[0m12:08:59.277904 [debug] [Thread-2  ]: Writing runtime sql for node "model.maker_warehouse.avg_viewing_time"
[0m12:08:59.278658 [debug] [Thread-3  ]: Began executing node model.maker_warehouse.movies
[0m12:08:59.286190 [debug] [Thread-4  ]: Writing runtime sql for node "model.maker_warehouse.no_of_viewings"
[0m12:08:59.287553 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.avg_duration_year_month"
[0m12:08:59.296874 [debug] [Thread-3  ]: Writing runtime sql for node "model.maker_warehouse.movies"
[0m12:08:59.297927 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.avg_viewing_time"
[0m12:08:59.298678 [debug] [Thread-1  ]: On model.maker_warehouse.avg_duration_year_month: BEGIN
[0m12:08:59.299529 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.no_of_viewings"
[0m12:08:59.300456 [debug] [Thread-2  ]: On model.maker_warehouse.avg_viewing_time: BEGIN
[0m12:08:59.301017 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.movies"
[0m12:08:59.301573 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m12:08:59.302128 [debug] [Thread-4  ]: On model.maker_warehouse.no_of_viewings: BEGIN
[0m12:08:59.303008 [debug] [Thread-2  ]: Opening a new connection, currently in state init
[0m12:08:59.303704 [debug] [Thread-3  ]: On model.maker_warehouse.movies: BEGIN
[0m12:08:59.304794 [debug] [Thread-4  ]: Opening a new connection, currently in state init
[0m12:08:59.306487 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m12:08:59.359478 [debug] [Thread-4  ]: SQL status: BEGIN in 0.0 seconds
[0m12:08:59.360898 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.no_of_viewings"
[0m12:08:59.362656 [debug] [Thread-2  ]: SQL status: BEGIN in 0.0 seconds
[0m12:08:59.363974 [debug] [Thread-4  ]: On model.maker_warehouse.no_of_viewings: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.no_of_viewings"} */

  
    

  create  table "mydb"."dbt_warehouse"."no_of_viewings__dbt_tmp"
  
  
    as
  
  (
    
SELECT
  title,
  COUNT(*) as total_views
FROM mydb.public.raw_netflix
GROUP BY title
ORDER BY total_views DESC
  );
  
[0m12:08:59.365810 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.avg_viewing_time"
[0m12:08:59.367722 [debug] [Thread-2  ]: On model.maker_warehouse.avg_viewing_time: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.avg_viewing_time"} */

  
    

  create  table "mydb"."dbt_warehouse"."avg_viewing_time__dbt_tmp"
  
  
    as
  
  (
    
SELECT
title,
ROUND(CAST(AVG(duration) AS NUMERIC), 2) as avg_duration
FROM mydb.public.raw_netflix
GROUP BY title
ORDER BY avg_duration DESC
  );
  
[0m12:08:59.368376 [debug] [Thread-3  ]: SQL status: BEGIN in 0.0 seconds
[0m12:08:59.369605 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.movies"
[0m12:08:59.370604 [debug] [Thread-3  ]: On model.maker_warehouse.movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.movies"} */

  
    

  create  table "mydb"."dbt_warehouse"."movies__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    DISTINCT
    title,
    genres,
    release_date,
    movie_id
FROM mydb.public.raw_netflix
  );
  
[0m12:08:59.373352 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
[0m12:08:59.374662 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.avg_duration_year_month"
[0m12:08:59.375836 [debug] [Thread-1  ]: On model.maker_warehouse.avg_duration_year_month: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.avg_duration_year_month"} */

  
    

  create  table "mydb"."dbt_warehouse"."avg_duration_year_month__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    EXTRACT(YEAR FROM CAST("datetime" AS DATE)) AS "Year",
    EXTRACT(MONTH FROM CAST("datetime" AS DATE)) AS "Month",
    ROUND(CAST(AVG(duration) AS NUMERIC), 2) AS "Average_Duration"
FROM
    mydb.public.raw_netflix
GROUP BY
    EXTRACT(YEAR FROM CAST("datetime" AS DATE)),
    EXTRACT(MONTH FROM CAST("datetime" AS DATE))
ORDER BY
    "Year", "Month"
  );
  
[0m12:09:00.091286 [debug] [Thread-4  ]: SQL status: SELECT 7925 in 1.0 seconds
[0m12:09:00.109974 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.no_of_viewings"
[0m12:09:00.111264 [debug] [Thread-4  ]: On model.maker_warehouse.no_of_viewings: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.no_of_viewings"} */
alter table "mydb"."dbt_warehouse"."no_of_viewings" rename to "no_of_viewings__dbt_backup"
[0m12:09:00.116267 [debug] [Thread-4  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:09:00.125006 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.no_of_viewings"
[0m12:09:00.125844 [debug] [Thread-4  ]: On model.maker_warehouse.no_of_viewings: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.no_of_viewings"} */
alter table "mydb"."dbt_warehouse"."no_of_viewings__dbt_tmp" rename to "no_of_viewings"
[0m12:09:00.130423 [debug] [Thread-4  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:09:00.209822 [debug] [Thread-4  ]: On model.maker_warehouse.no_of_viewings: COMMIT
[0m12:09:00.211681 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.no_of_viewings"
[0m12:09:00.212931 [debug] [Thread-4  ]: On model.maker_warehouse.no_of_viewings: COMMIT
[0m12:09:00.334241 [debug] [Thread-4  ]: SQL status: COMMIT in 0.0 seconds
[0m12:09:00.353618 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.no_of_viewings"
[0m12:09:00.354873 [debug] [Thread-4  ]: On model.maker_warehouse.no_of_viewings: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.no_of_viewings"} */
drop table if exists "mydb"."dbt_warehouse"."no_of_viewings__dbt_backup" cascade
[0m12:09:00.387475 [debug] [Thread-4  ]: SQL status: DROP TABLE in 0.0 seconds
[0m12:09:00.392924 [debug] [Thread-4  ]: Timing info for model.maker_warehouse.no_of_viewings (execute): 12:08:59.279332 => 12:09:00.392412
[0m12:09:00.393975 [debug] [Thread-4  ]: On model.maker_warehouse.no_of_viewings: Close
[0m12:09:00.397365 [debug] [Thread-4  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '35415c32-438d-4eff-9892-74500dc034c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b8fe850>]}
[0m12:09:00.399182 [info ] [Thread-4  ]: 4 of 10 OK created sql table model dbt_warehouse.no_of_viewings ................ [[32mSELECT 7925[0m in 1.28s]
[0m12:09:00.401849 [debug] [Thread-4  ]: Finished running node model.maker_warehouse.no_of_viewings
[0m12:09:00.403377 [debug] [Thread-4  ]: Began running node model.maker_warehouse.total_duration_year_month
[0m12:09:00.404667 [info ] [Thread-4  ]: 5 of 10 START sql table model dbt_warehouse.total_duration_year_month .......... [RUN]
[0m12:09:00.405815 [debug] [Thread-4  ]: Re-using an available connection from the pool (formerly model.maker_warehouse.no_of_viewings, now model.maker_warehouse.total_duration_year_month)
[0m12:09:00.406668 [debug] [Thread-4  ]: Began compiling node model.maker_warehouse.total_duration_year_month
[0m12:09:00.416726 [debug] [Thread-4  ]: Writing injected SQL for node "model.maker_warehouse.total_duration_year_month"
[0m12:09:00.419865 [debug] [Thread-4  ]: Timing info for model.maker_warehouse.total_duration_year_month (compile): 12:09:00.407711 => 12:09:00.419125
[0m12:09:00.421777 [debug] [Thread-4  ]: Began executing node model.maker_warehouse.total_duration_year_month
[0m12:09:00.442502 [debug] [Thread-4  ]: Writing runtime sql for node "model.maker_warehouse.total_duration_year_month"
[0m12:09:00.446611 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.total_duration_year_month"
[0m12:09:00.448547 [debug] [Thread-4  ]: On model.maker_warehouse.total_duration_year_month: BEGIN
[0m12:09:00.449678 [debug] [Thread-4  ]: Opening a new connection, currently in state closed
[0m12:09:00.516734 [debug] [Thread-4  ]: SQL status: BEGIN in 0.0 seconds
[0m12:09:00.518180 [debug] [Thread-2  ]: SQL status: SELECT 7925 in 1.0 seconds
[0m12:09:00.519564 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.total_duration_year_month"
[0m12:09:00.532687 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.avg_viewing_time"
[0m12:09:00.533832 [debug] [Thread-4  ]: On model.maker_warehouse.total_duration_year_month: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_duration_year_month"} */

  
    

  create  table "mydb"."dbt_warehouse"."total_duration_year_month__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    EXTRACT(YEAR FROM CAST("datetime" AS DATE)) AS "Year",
    EXTRACT(MONTH FROM CAST("datetime" AS DATE)) AS "Month",
    SUM(duration) AS "Total_Duration"
FROM
    mydb.public.raw_netflix
GROUP BY
    EXTRACT(YEAR FROM CAST("datetime" AS DATE)),
    EXTRACT(MONTH FROM CAST("datetime" AS DATE))
ORDER BY
    "Year", "Month"
  );
  
[0m12:09:00.534900 [debug] [Thread-2  ]: On model.maker_warehouse.avg_viewing_time: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.avg_viewing_time"} */
alter table "mydb"."dbt_warehouse"."avg_viewing_time" rename to "avg_viewing_time__dbt_backup"
[0m12:09:00.543742 [debug] [Thread-2  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:09:00.556915 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.avg_viewing_time"
[0m12:09:00.558171 [debug] [Thread-2  ]: On model.maker_warehouse.avg_viewing_time: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.avg_viewing_time"} */
alter table "mydb"."dbt_warehouse"."avg_viewing_time__dbt_tmp" rename to "avg_viewing_time"
[0m12:09:00.562698 [debug] [Thread-2  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:09:00.569985 [debug] [Thread-2  ]: On model.maker_warehouse.avg_viewing_time: COMMIT
[0m12:09:00.571450 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.avg_viewing_time"
[0m12:09:00.572842 [debug] [Thread-2  ]: On model.maker_warehouse.avg_viewing_time: COMMIT
[0m12:09:00.585232 [debug] [Thread-2  ]: SQL status: COMMIT in 0.0 seconds
[0m12:09:00.593642 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.avg_viewing_time"
[0m12:09:00.595135 [debug] [Thread-2  ]: On model.maker_warehouse.avg_viewing_time: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.avg_viewing_time"} */
drop table if exists "mydb"."dbt_warehouse"."avg_viewing_time__dbt_backup" cascade
[0m12:09:00.614406 [debug] [Thread-2  ]: SQL status: DROP TABLE in 0.0 seconds
[0m12:09:00.618892 [debug] [Thread-2  ]: Timing info for model.maker_warehouse.avg_viewing_time (execute): 12:08:59.240744 => 12:09:00.618140
[0m12:09:00.619979 [debug] [Thread-2  ]: On model.maker_warehouse.avg_viewing_time: Close
[0m12:09:00.621492 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '35415c32-438d-4eff-9892-74500dc034c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b889cd0>]}
[0m12:09:00.622498 [info ] [Thread-2  ]: 2 of 10 OK created sql table model dbt_warehouse.avg_viewing_time .............. [[32mSELECT 7925[0m in 1.50s]
[0m12:09:00.623618 [debug] [Thread-2  ]: Finished running node model.maker_warehouse.avg_viewing_time
[0m12:09:00.627456 [debug] [Thread-2  ]: Began running node model.maker_warehouse.total_unique_users
[0m12:09:00.629099 [info ] [Thread-2  ]: 6 of 10 START sql table model dbt_warehouse.total_unique_users ................. [RUN]
[0m12:09:00.631597 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly model.maker_warehouse.avg_viewing_time, now model.maker_warehouse.total_unique_users)
[0m12:09:00.632742 [debug] [Thread-2  ]: Began compiling node model.maker_warehouse.total_unique_users
[0m12:09:00.644915 [debug] [Thread-2  ]: Writing injected SQL for node "model.maker_warehouse.total_unique_users"
[0m12:09:00.648031 [debug] [Thread-2  ]: Timing info for model.maker_warehouse.total_unique_users (compile): 12:09:00.633651 => 12:09:00.647282
[0m12:09:00.649534 [debug] [Thread-2  ]: Began executing node model.maker_warehouse.total_unique_users
[0m12:09:00.671257 [debug] [Thread-2  ]: Writing runtime sql for node "model.maker_warehouse.total_unique_users"
[0m12:09:00.673475 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.total_unique_users"
[0m12:09:00.674608 [debug] [Thread-2  ]: On model.maker_warehouse.total_unique_users: BEGIN
[0m12:09:00.675582 [debug] [Thread-2  ]: Opening a new connection, currently in state closed
[0m12:09:00.737836 [debug] [Thread-2  ]: SQL status: BEGIN in 0.0 seconds
[0m12:09:00.739682 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.total_unique_users"
[0m12:09:00.740806 [debug] [Thread-2  ]: On model.maker_warehouse.total_unique_users: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_unique_users"} */

  
    

  create  table "mydb"."dbt_warehouse"."total_unique_users__dbt_tmp"
  
  
    as
  
  (
    
SELECT 
COUNT(DISTINCT(user_id)) AS total_unique_users
FROM mydb.public.raw_netflix
  );
  
[0m12:09:06.996999 [debug] [Thread-1  ]: SQL status: SELECT 30 in 8.0 seconds
[0m12:09:07.008716 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.avg_duration_year_month"
[0m12:09:07.009985 [debug] [Thread-1  ]: On model.maker_warehouse.avg_duration_year_month: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.avg_duration_year_month"} */
alter table "mydb"."dbt_warehouse"."avg_duration_year_month__dbt_tmp" rename to "avg_duration_year_month"
[0m12:09:07.017141 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:09:07.025631 [debug] [Thread-1  ]: On model.maker_warehouse.avg_duration_year_month: COMMIT
[0m12:09:07.027015 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.avg_duration_year_month"
[0m12:09:07.028203 [debug] [Thread-1  ]: On model.maker_warehouse.avg_duration_year_month: COMMIT
[0m12:09:07.041142 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
[0m12:09:07.048041 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.avg_duration_year_month"
[0m12:09:07.049369 [debug] [Thread-1  ]: On model.maker_warehouse.avg_duration_year_month: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.avg_duration_year_month"} */
drop table if exists "mydb"."dbt_warehouse"."avg_duration_year_month__dbt_backup" cascade
[0m12:09:07.051354 [debug] [Thread-3  ]: SQL status: SELECT 8472 in 8.0 seconds
[0m12:09:07.060388 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.movies"
[0m12:09:07.062709 [debug] [Thread-3  ]: On model.maker_warehouse.movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.movies"} */
alter table "mydb"."dbt_warehouse"."movies" rename to "movies__dbt_backup"
[0m12:09:07.065968 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
[0m12:09:07.071146 [debug] [Thread-1  ]: Timing info for model.maker_warehouse.avg_duration_year_month (execute): 12:08:59.175257 => 12:09:07.069868
[0m12:09:07.072897 [debug] [Thread-1  ]: On model.maker_warehouse.avg_duration_year_month: Close
[0m12:09:07.074073 [debug] [Thread-3  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:09:07.075970 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '35415c32-438d-4eff-9892-74500dc034c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b8f60a0>]}
[0m12:09:07.083248 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.movies"
[0m12:09:07.085437 [debug] [Thread-3  ]: On model.maker_warehouse.movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.movies"} */
alter table "mydb"."dbt_warehouse"."movies__dbt_tmp" rename to "movies"
[0m12:09:07.084370 [info ] [Thread-1  ]: 1 of 10 OK created sql table model dbt_warehouse.avg_duration_year_month ....... [[32mSELECT 30[0m in 7.96s]
[0m12:09:07.087589 [debug] [Thread-1  ]: Finished running node model.maker_warehouse.avg_duration_year_month
[0m12:09:07.088260 [debug] [Thread-1  ]: Began running node model.maker_warehouse.total_viewing_time
[0m12:09:07.088939 [info ] [Thread-1  ]: 7 of 10 START sql table model dbt_warehouse.total_viewing_time ................. [RUN]
[0m12:09:07.093020 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.maker_warehouse.avg_duration_year_month, now model.maker_warehouse.total_viewing_time)
[0m12:09:07.094108 [debug] [Thread-1  ]: Began compiling node model.maker_warehouse.total_viewing_time
[0m12:09:07.104659 [debug] [Thread-3  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:09:07.113387 [debug] [Thread-3  ]: On model.maker_warehouse.movies: COMMIT
[0m12:09:07.114572 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.movies"
[0m12:09:07.116022 [debug] [Thread-3  ]: On model.maker_warehouse.movies: COMMIT
[0m12:09:07.119879 [debug] [Thread-1  ]: Writing injected SQL for node "model.maker_warehouse.total_viewing_time"
[0m12:09:07.129798 [debug] [Thread-1  ]: Timing info for model.maker_warehouse.total_viewing_time (compile): 12:09:07.094967 => 12:09:07.128835
[0m12:09:07.132036 [debug] [Thread-1  ]: Began executing node model.maker_warehouse.total_viewing_time
[0m12:09:07.205946 [debug] [Thread-3  ]: SQL status: COMMIT in 0.0 seconds
[0m12:09:07.217417 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.movies"
[0m12:09:07.218868 [debug] [Thread-3  ]: On model.maker_warehouse.movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.movies"} */
drop table if exists "mydb"."dbt_warehouse"."movies__dbt_backup" cascade
[0m12:09:07.220851 [debug] [Thread-1  ]: Writing runtime sql for node "model.maker_warehouse.total_viewing_time"
[0m12:09:07.222379 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.total_viewing_time"
[0m12:09:07.223300 [debug] [Thread-1  ]: On model.maker_warehouse.total_viewing_time: BEGIN
[0m12:09:07.224493 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m12:09:07.247243 [debug] [Thread-3  ]: SQL status: DROP TABLE in 0.0 seconds
[0m12:09:07.256307 [debug] [Thread-3  ]: Timing info for model.maker_warehouse.movies (execute): 12:08:59.287957 => 12:09:07.255823
[0m12:09:07.257323 [debug] [Thread-3  ]: On model.maker_warehouse.movies: Close
[0m12:09:07.259687 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '35415c32-438d-4eff-9892-74500dc034c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b94fac0>]}
[0m12:09:07.263283 [info ] [Thread-3  ]: 3 of 10 OK created sql table model dbt_warehouse.movies ........................ [[32mSELECT 8472[0m in 8.14s]
[0m12:09:07.266922 [debug] [Thread-3  ]: Finished running node model.maker_warehouse.movies
[0m12:09:07.269038 [debug] [Thread-3  ]: Began running node model.maker_warehouse.total_viewings_year_month
[0m12:09:07.283388 [info ] [Thread-3  ]: 8 of 10 START sql table model dbt_warehouse.total_viewings_year_month .......... [RUN]
[0m12:09:07.288657 [debug] [Thread-3  ]: Re-using an available connection from the pool (formerly model.maker_warehouse.movies, now model.maker_warehouse.total_viewings_year_month)
[0m12:09:07.290098 [debug] [Thread-3  ]: Began compiling node model.maker_warehouse.total_viewings_year_month
[0m12:09:07.306209 [debug] [Thread-3  ]: Writing injected SQL for node "model.maker_warehouse.total_viewings_year_month"
[0m12:09:07.308804 [debug] [Thread-3  ]: Timing info for model.maker_warehouse.total_viewings_year_month (compile): 12:09:07.292333 => 12:09:07.308265
[0m12:09:07.315200 [debug] [Thread-3  ]: Began executing node model.maker_warehouse.total_viewings_year_month
[0m12:09:07.357907 [debug] [Thread-3  ]: Writing runtime sql for node "model.maker_warehouse.total_viewings_year_month"
[0m12:09:07.360102 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.total_viewings_year_month"
[0m12:09:07.361092 [debug] [Thread-3  ]: On model.maker_warehouse.total_viewings_year_month: BEGIN
[0m12:09:07.376511 [debug] [Thread-3  ]: Opening a new connection, currently in state closed
[0m12:09:07.414495 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
[0m12:09:07.415735 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.total_viewing_time"
[0m12:09:07.416803 [debug] [Thread-1  ]: On model.maker_warehouse.total_viewing_time: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_viewing_time"} */

  
    

  create  table "mydb"."dbt_warehouse"."total_viewing_time__dbt_tmp"
  
  
    as
  
  (
    
SELECT
title,
SUM(duration) as total_duration
FROM mydb.public.raw_netflix
GROUP BY title
ORDER BY total_duration DESC
  );
  
[0m12:09:07.468696 [debug] [Thread-3  ]: SQL status: BEGIN in 0.0 seconds
[0m12:09:07.469955 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.total_viewings_year_month"
[0m12:09:07.472069 [debug] [Thread-3  ]: On model.maker_warehouse.total_viewings_year_month: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_viewings_year_month"} */

  
    

  create  table "mydb"."dbt_warehouse"."total_viewings_year_month__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    EXTRACT(YEAR FROM CAST("datetime" AS DATE)) AS "Year",
    EXTRACT(MONTH FROM CAST("datetime" AS DATE)) AS "Month",
    COUNT(*) AS "Total_Views"
FROM mydb.public.raw_netflix
GROUP BY
    EXTRACT(YEAR FROM CAST("datetime" AS DATE)),
    EXTRACT(MONTH FROM CAST("datetime" AS DATE))
ORDER BY
    "Year", "Month"
  );
  
[0m12:09:08.081349 [debug] [Thread-4  ]: SQL status: SELECT 30 in 8.0 seconds
[0m12:09:08.091753 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.total_duration_year_month"
[0m12:09:08.093138 [debug] [Thread-4  ]: On model.maker_warehouse.total_duration_year_month: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_duration_year_month"} */
alter table "mydb"."dbt_warehouse"."total_duration_year_month" rename to "total_duration_year_month__dbt_backup"
[0m12:09:08.098941 [debug] [Thread-4  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:09:08.111303 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.total_duration_year_month"
[0m12:09:08.112970 [debug] [Thread-4  ]: On model.maker_warehouse.total_duration_year_month: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_duration_year_month"} */
alter table "mydb"."dbt_warehouse"."total_duration_year_month__dbt_tmp" rename to "total_duration_year_month"
[0m12:09:08.116830 [debug] [Thread-4  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:09:08.124193 [debug] [Thread-4  ]: On model.maker_warehouse.total_duration_year_month: COMMIT
[0m12:09:08.125544 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.total_duration_year_month"
[0m12:09:08.127037 [debug] [Thread-4  ]: On model.maker_warehouse.total_duration_year_month: COMMIT
[0m12:09:08.134513 [debug] [Thread-4  ]: SQL status: COMMIT in 0.0 seconds
[0m12:09:08.143499 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.total_duration_year_month"
[0m12:09:08.144421 [debug] [Thread-4  ]: On model.maker_warehouse.total_duration_year_month: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_duration_year_month"} */
drop table if exists "mydb"."dbt_warehouse"."total_duration_year_month__dbt_backup" cascade
[0m12:09:08.159719 [debug] [Thread-4  ]: SQL status: DROP TABLE in 0.0 seconds
[0m12:09:08.163893 [debug] [Thread-4  ]: Timing info for model.maker_warehouse.total_duration_year_month (execute): 12:09:00.422550 => 12:09:08.163390
[0m12:09:08.165124 [debug] [Thread-4  ]: On model.maker_warehouse.total_duration_year_month: Close
[0m12:09:08.167358 [debug] [Thread-4  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '35415c32-438d-4eff-9892-74500dc034c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b808880>]}
[0m12:09:08.169273 [info ] [Thread-4  ]: 5 of 10 OK created sql table model dbt_warehouse.total_duration_year_month ..... [[32mSELECT 30[0m in 7.76s]
[0m12:09:08.173355 [debug] [Thread-4  ]: Finished running node model.maker_warehouse.total_duration_year_month
[0m12:09:08.174993 [debug] [Thread-4  ]: Began running node model.maker_warehouse.user_engagement
[0m12:09:08.176299 [info ] [Thread-4  ]: 9 of 10 START sql table model dbt_warehouse.user_engagement .................... [RUN]
[0m12:09:08.177447 [debug] [Thread-4  ]: Re-using an available connection from the pool (formerly model.maker_warehouse.total_duration_year_month, now model.maker_warehouse.user_engagement)
[0m12:09:08.178718 [debug] [Thread-4  ]: Began compiling node model.maker_warehouse.user_engagement
[0m12:09:08.196433 [debug] [Thread-4  ]: Writing injected SQL for node "model.maker_warehouse.user_engagement"
[0m12:09:08.199654 [debug] [Thread-4  ]: Timing info for model.maker_warehouse.user_engagement (compile): 12:09:08.179635 => 12:09:08.198654
[0m12:09:08.201038 [debug] [Thread-4  ]: Began executing node model.maker_warehouse.user_engagement
[0m12:09:08.221192 [debug] [Thread-4  ]: Writing runtime sql for node "model.maker_warehouse.user_engagement"
[0m12:09:08.228496 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.user_engagement"
[0m12:09:08.232700 [debug] [Thread-4  ]: On model.maker_warehouse.user_engagement: BEGIN
[0m12:09:08.239398 [debug] [Thread-4  ]: Opening a new connection, currently in state closed
[0m12:09:08.261486 [debug] [Thread-1  ]: SQL status: SELECT 7925 in 1.0 seconds
[0m12:09:08.274375 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.total_viewing_time"
[0m12:09:08.275668 [debug] [Thread-1  ]: On model.maker_warehouse.total_viewing_time: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_viewing_time"} */
alter table "mydb"."dbt_warehouse"."total_viewing_time" rename to "total_viewing_time__dbt_backup"
[0m12:09:08.282673 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:09:08.293142 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.total_viewing_time"
[0m12:09:08.295393 [debug] [Thread-1  ]: On model.maker_warehouse.total_viewing_time: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_viewing_time"} */
alter table "mydb"."dbt_warehouse"."total_viewing_time__dbt_tmp" rename to "total_viewing_time"
[0m12:09:08.299690 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:09:08.306311 [debug] [Thread-1  ]: On model.maker_warehouse.total_viewing_time: COMMIT
[0m12:09:08.308050 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.total_viewing_time"
[0m12:09:08.309218 [debug] [Thread-1  ]: On model.maker_warehouse.total_viewing_time: COMMIT
[0m12:09:08.315820 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
[0m12:09:08.324471 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.total_viewing_time"
[0m12:09:08.325674 [debug] [Thread-1  ]: On model.maker_warehouse.total_viewing_time: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_viewing_time"} */
drop table if exists "mydb"."dbt_warehouse"."total_viewing_time__dbt_backup" cascade
[0m12:09:08.335186 [debug] [Thread-4  ]: SQL status: BEGIN in 0.0 seconds
[0m12:09:08.336515 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.user_engagement"
[0m12:09:08.338012 [debug] [Thread-4  ]: On model.maker_warehouse.user_engagement: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.user_engagement"} */

  
    

  create  table "mydb"."dbt_warehouse"."user_engagement__dbt_tmp"
  
  
    as
  
  (
    
SELECT 
DISTINCT(user_id),
COUNT(DISTINCT(title)) AS total_titles,
SUM(duration) AS total_duration
FROM mydb.public.raw_netflix
GROUP BY user_id
  );
  
[0m12:09:08.344735 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
[0m12:09:08.355333 [debug] [Thread-1  ]: Timing info for model.maker_warehouse.total_viewing_time (execute): 12:09:07.133043 => 12:09:08.354557
[0m12:09:08.356548 [debug] [Thread-1  ]: On model.maker_warehouse.total_viewing_time: Close
[0m12:09:08.358651 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '35415c32-438d-4eff-9892-74500dc034c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b7f3280>]}
[0m12:09:08.360442 [info ] [Thread-1  ]: 7 of 10 OK created sql table model dbt_warehouse.total_viewing_time ............ [[32mSELECT 7925[0m in 1.27s]
[0m12:09:08.362804 [debug] [Thread-1  ]: Finished running node model.maker_warehouse.total_viewing_time
[0m12:09:08.364319 [debug] [Thread-1  ]: Began running node model.maker_warehouse.all_movies
[0m12:09:08.365755 [info ] [Thread-1  ]: 10 of 10 START sql table model dbt_warehouse.all_movies ........................ [RUN]
[0m12:09:08.367794 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.maker_warehouse.total_viewing_time, now model.maker_warehouse.all_movies)
[0m12:09:08.369432 [debug] [Thread-1  ]: Began compiling node model.maker_warehouse.all_movies
[0m12:09:08.380736 [debug] [Thread-1  ]: Writing injected SQL for node "model.maker_warehouse.all_movies"
[0m12:09:08.383778 [debug] [Thread-1  ]: Timing info for model.maker_warehouse.all_movies (compile): 12:09:08.370315 => 12:09:08.382853
[0m12:09:08.385004 [debug] [Thread-1  ]: Began executing node model.maker_warehouse.all_movies
[0m12:09:08.405545 [debug] [Thread-1  ]: Writing runtime sql for node "model.maker_warehouse.all_movies"
[0m12:09:08.407338 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.all_movies"
[0m12:09:08.408523 [debug] [Thread-1  ]: On model.maker_warehouse.all_movies: BEGIN
[0m12:09:08.409607 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m12:09:08.476088 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
[0m12:09:08.477335 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.all_movies"
[0m12:09:08.479482 [debug] [Thread-1  ]: On model.maker_warehouse.all_movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.all_movies"} */

  
    

  create  table "mydb"."dbt_warehouse"."all_movies__dbt_tmp"
  
  
    as
  
  (
    
  
SELECT
*
FROM "mydb"."dbt_warehouse"."movies"
  );
  
[0m12:09:08.545892 [debug] [Thread-1  ]: SQL status: SELECT 8472 in 0.0 seconds
[0m12:09:08.555785 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.all_movies"
[0m12:09:08.557010 [debug] [Thread-1  ]: On model.maker_warehouse.all_movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.all_movies"} */
alter table "mydb"."dbt_warehouse"."all_movies" rename to "all_movies__dbt_backup"
[0m12:09:08.561328 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:09:08.569425 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.all_movies"
[0m12:09:08.570835 [debug] [Thread-1  ]: On model.maker_warehouse.all_movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.all_movies"} */
alter table "mydb"."dbt_warehouse"."all_movies__dbt_tmp" rename to "all_movies"
[0m12:09:08.578444 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:09:08.584685 [debug] [Thread-1  ]: On model.maker_warehouse.all_movies: COMMIT
[0m12:09:08.585863 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.all_movies"
[0m12:09:08.586998 [debug] [Thread-1  ]: On model.maker_warehouse.all_movies: COMMIT
[0m12:09:08.615895 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
[0m12:09:08.622959 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.all_movies"
[0m12:09:08.624136 [debug] [Thread-1  ]: On model.maker_warehouse.all_movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.all_movies"} */
drop table if exists "mydb"."dbt_warehouse"."all_movies__dbt_backup" cascade
[0m12:09:08.642321 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
[0m12:09:08.646062 [debug] [Thread-1  ]: Timing info for model.maker_warehouse.all_movies (execute): 12:09:08.385783 => 12:09:08.645237
[0m12:09:08.647330 [debug] [Thread-1  ]: On model.maker_warehouse.all_movies: Close
[0m12:09:08.649005 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '35415c32-438d-4eff-9892-74500dc034c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b808040>]}
[0m12:09:08.649994 [info ] [Thread-1  ]: 10 of 10 OK created sql table model dbt_warehouse.all_movies ................... [[32mSELECT 8472[0m in 0.28s]
[0m12:09:08.652323 [debug] [Thread-1  ]: Finished running node model.maker_warehouse.all_movies
[0m12:09:10.985709 [debug] [Thread-2  ]: SQL status: SELECT 1 in 10.0 seconds
[0m12:09:10.997342 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.total_unique_users"
[0m12:09:10.998072 [debug] [Thread-2  ]: On model.maker_warehouse.total_unique_users: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_unique_users"} */
alter table "mydb"."dbt_warehouse"."total_unique_users" rename to "total_unique_users__dbt_backup"
[0m12:09:11.005056 [debug] [Thread-2  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:09:11.019363 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.total_unique_users"
[0m12:09:11.021926 [debug] [Thread-2  ]: On model.maker_warehouse.total_unique_users: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_unique_users"} */
alter table "mydb"."dbt_warehouse"."total_unique_users__dbt_tmp" rename to "total_unique_users"
[0m12:09:11.029023 [debug] [Thread-2  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:09:11.037434 [debug] [Thread-2  ]: On model.maker_warehouse.total_unique_users: COMMIT
[0m12:09:11.038892 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.total_unique_users"
[0m12:09:11.039717 [debug] [Thread-2  ]: On model.maker_warehouse.total_unique_users: COMMIT
[0m12:09:11.044559 [debug] [Thread-2  ]: SQL status: COMMIT in 0.0 seconds
[0m12:09:11.055090 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.total_unique_users"
[0m12:09:11.056827 [debug] [Thread-2  ]: On model.maker_warehouse.total_unique_users: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_unique_users"} */
drop table if exists "mydb"."dbt_warehouse"."total_unique_users__dbt_backup" cascade
[0m12:09:11.078107 [debug] [Thread-2  ]: SQL status: DROP TABLE in 0.0 seconds
[0m12:09:11.082284 [debug] [Thread-2  ]: Timing info for model.maker_warehouse.total_unique_users (execute): 12:09:00.651231 => 12:09:11.081714
[0m12:09:11.083314 [debug] [Thread-2  ]: On model.maker_warehouse.total_unique_users: Close
[0m12:09:11.085512 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '35415c32-438d-4eff-9892-74500dc034c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b7f3040>]}
[0m12:09:11.087385 [info ] [Thread-2  ]: 6 of 10 OK created sql table model dbt_warehouse.total_unique_users ............ [[32mSELECT 1[0m in 10.45s]
[0m12:09:11.089582 [debug] [Thread-2  ]: Finished running node model.maker_warehouse.total_unique_users
[0m12:09:11.414582 [debug] [Thread-3  ]: SQL status: SELECT 30 in 4.0 seconds
[0m12:09:11.422999 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.total_viewings_year_month"
[0m12:09:11.424304 [debug] [Thread-3  ]: On model.maker_warehouse.total_viewings_year_month: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_viewings_year_month"} */
alter table "mydb"."dbt_warehouse"."total_viewings_year_month" rename to "total_viewings_year_month__dbt_backup"
[0m12:09:11.434026 [debug] [Thread-3  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:09:11.441187 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.total_viewings_year_month"
[0m12:09:11.442121 [debug] [Thread-3  ]: On model.maker_warehouse.total_viewings_year_month: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_viewings_year_month"} */
alter table "mydb"."dbt_warehouse"."total_viewings_year_month__dbt_tmp" rename to "total_viewings_year_month"
[0m12:09:11.448620 [debug] [Thread-3  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:09:11.455178 [debug] [Thread-3  ]: On model.maker_warehouse.total_viewings_year_month: COMMIT
[0m12:09:11.456377 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.total_viewings_year_month"
[0m12:09:11.457521 [debug] [Thread-3  ]: On model.maker_warehouse.total_viewings_year_month: COMMIT
[0m12:09:11.463131 [debug] [Thread-3  ]: SQL status: COMMIT in 0.0 seconds
[0m12:09:11.469737 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.total_viewings_year_month"
[0m12:09:11.471088 [debug] [Thread-3  ]: On model.maker_warehouse.total_viewings_year_month: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_viewings_year_month"} */
drop table if exists "mydb"."dbt_warehouse"."total_viewings_year_month__dbt_backup" cascade
[0m12:09:11.486057 [debug] [Thread-3  ]: SQL status: DROP TABLE in 0.0 seconds
[0m12:09:11.489741 [debug] [Thread-3  ]: Timing info for model.maker_warehouse.total_viewings_year_month (execute): 12:09:07.319249 => 12:09:11.489132
[0m12:09:11.491130 [debug] [Thread-3  ]: On model.maker_warehouse.total_viewings_year_month: Close
[0m12:09:11.493332 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '35415c32-438d-4eff-9892-74500dc034c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b7b9340>]}
[0m12:09:11.495330 [info ] [Thread-3  ]: 8 of 10 OK created sql table model dbt_warehouse.total_viewings_year_month ..... [[32mSELECT 30[0m in 4.21s]
[0m12:09:11.497638 [debug] [Thread-3  ]: Finished running node model.maker_warehouse.total_viewings_year_month
[0m12:09:14.546955 [debug] [Thread-4  ]: SQL status: SELECT 161918 in 6.0 seconds
[0m12:09:14.558020 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.user_engagement"
[0m12:09:14.560666 [debug] [Thread-4  ]: On model.maker_warehouse.user_engagement: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.user_engagement"} */
alter table "mydb"."dbt_warehouse"."user_engagement" rename to "user_engagement__dbt_backup"
[0m12:09:14.565242 [debug] [Thread-4  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:09:14.574264 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.user_engagement"
[0m12:09:14.575843 [debug] [Thread-4  ]: On model.maker_warehouse.user_engagement: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.user_engagement"} */
alter table "mydb"."dbt_warehouse"."user_engagement__dbt_tmp" rename to "user_engagement"
[0m12:09:14.579141 [debug] [Thread-4  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:09:14.584315 [debug] [Thread-4  ]: On model.maker_warehouse.user_engagement: COMMIT
[0m12:09:14.585370 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.user_engagement"
[0m12:09:14.586031 [debug] [Thread-4  ]: On model.maker_warehouse.user_engagement: COMMIT
[0m12:09:14.607641 [debug] [Thread-4  ]: SQL status: COMMIT in 0.0 seconds
[0m12:09:14.615205 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.user_engagement"
[0m12:09:14.615926 [debug] [Thread-4  ]: On model.maker_warehouse.user_engagement: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.user_engagement"} */
drop table if exists "mydb"."dbt_warehouse"."user_engagement__dbt_backup" cascade
[0m12:09:14.631355 [debug] [Thread-4  ]: SQL status: DROP TABLE in 0.0 seconds
[0m12:09:14.634539 [debug] [Thread-4  ]: Timing info for model.maker_warehouse.user_engagement (execute): 12:09:08.201860 => 12:09:14.634208
[0m12:09:14.635490 [debug] [Thread-4  ]: On model.maker_warehouse.user_engagement: Close
[0m12:09:14.637090 [debug] [Thread-4  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '35415c32-438d-4eff-9892-74500dc034c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b9f9070>]}
[0m12:09:14.638707 [info ] [Thread-4  ]: 9 of 10 OK created sql table model dbt_warehouse.user_engagement ............... [[32mSELECT 161918[0m in 6.46s]
[0m12:09:14.640637 [debug] [Thread-4  ]: Finished running node model.maker_warehouse.user_engagement
[0m12:09:14.644897 [debug] [MainThread]: Using postgres connection "master"
[0m12:09:14.645835 [debug] [MainThread]: On master: BEGIN
[0m12:09:14.646931 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m12:09:14.676746 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m12:09:14.677969 [debug] [MainThread]: On master: COMMIT
[0m12:09:14.678679 [debug] [MainThread]: Using postgres connection "master"
[0m12:09:14.679646 [debug] [MainThread]: On master: COMMIT
[0m12:09:14.681538 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m12:09:14.682167 [debug] [MainThread]: On master: Close
[0m12:09:14.683485 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:09:14.684465 [debug] [MainThread]: Connection 'model.maker_warehouse.all_movies' was properly closed.
[0m12:09:14.685253 [debug] [MainThread]: Connection 'model.maker_warehouse.total_unique_users' was properly closed.
[0m12:09:14.686026 [debug] [MainThread]: Connection 'model.maker_warehouse.total_viewings_year_month' was properly closed.
[0m12:09:14.687062 [debug] [MainThread]: Connection 'model.maker_warehouse.user_engagement' was properly closed.
[0m12:09:14.687911 [info ] [MainThread]: 
[0m12:09:14.688789 [info ] [MainThread]: Finished running 10 table models in 0 hours 0 minutes and 16.00 seconds (16.00s).
[0m12:09:14.693669 [debug] [MainThread]: Command end result
[0m12:09:14.712098 [info ] [MainThread]: 
[0m12:09:14.713990 [info ] [MainThread]: [32mCompleted successfully[0m
[0m12:09:14.715137 [info ] [MainThread]: 
[0m12:09:14.716570 [info ] [MainThread]: Done. PASS=10 WARN=0 ERROR=0 SKIP=0 TOTAL=10
[0m12:09:14.720420 [debug] [MainThread]: Command `dbt run` succeeded at 12:09:14.719685 after 16.61 seconds
[0m12:09:14.722241 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109f0cf40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b50c700>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107a9f670>]}
[0m12:09:14.723657 [debug] [MainThread]: Flushing usage events
[0m12:14:41.798643 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109111550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a4ac2b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106ca4790>]}


============================== 12:14:41.807288 | 4665367a-1401-45c5-8ab6-b42423104c39 ==============================
[0m12:14:41.807288 [info ] [MainThread]: Running with dbt=1.5.4
[0m12:14:41.810127 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': '/Users/denisechan/Documents/Makers/Data_Engineering/Week_6/dbt_warehouse', 'log_path': '/Users/denisechan/Documents/Makers/Data_Engineering/Week_6/dbt_warehouse/logs', 'version_check': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'send_anonymous_usage_stats': 'True'}
[0m12:14:42.113206 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '4665367a-1401-45c5-8ab6-b42423104c39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a4ac9d0>]}
[0m12:14:42.151582 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '4665367a-1401-45c5-8ab6-b42423104c39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a7116d0>]}
[0m12:14:42.154675 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m12:14:42.202649 [debug] [MainThread]: checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, vars: {}, profile: , target: , version: 1.5.4
[0m12:14:42.386825 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 3 files changed.
[0m12:14:42.387775 [debug] [MainThread]: Partial parsing: updated file: maker_warehouse://models/summary/avg_duration_year_month.sql
[0m12:14:42.388444 [debug] [MainThread]: Partial parsing: updated file: maker_warehouse://models/summary/total_duration_year_month.sql
[0m12:14:42.389083 [debug] [MainThread]: Partial parsing: updated file: maker_warehouse://models/summary/total_viewings_year_month.sql
[0m12:14:42.449412 [debug] [MainThread]: 1699: static parser successfully parsed summary/avg_duration_year_month.sql
[0m12:14:42.477508 [debug] [MainThread]: 1699: static parser successfully parsed summary/total_duration_year_month.sql
[0m12:14:42.483884 [debug] [MainThread]: 1699: static parser successfully parsed summary/total_viewings_year_month.sql
[0m12:14:42.505251 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '4665367a-1401-45c5-8ab6-b42423104c39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a9ea0d0>]}
[0m12:14:42.517456 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '4665367a-1401-45c5-8ab6-b42423104c39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a8d4d60>]}
[0m12:14:42.518376 [info ] [MainThread]: Found 10 models, 0 tests, 0 snapshots, 0 analyses, 307 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics, 0 groups
[0m12:14:42.519516 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4665367a-1401-45c5-8ab6-b42423104c39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a8d4cd0>]}
[0m12:14:42.523594 [info ] [MainThread]: 
[0m12:14:42.526194 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m12:14:42.528670 [debug] [ThreadPool]: Acquiring new postgres connection 'list_mydb'
[0m12:14:42.551679 [debug] [ThreadPool]: Using postgres connection "list_mydb"
[0m12:14:42.552441 [debug] [ThreadPool]: On list_mydb: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "connection_name": "list_mydb"} */

    select distinct nspname from pg_namespace
  
[0m12:14:42.552991 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:14:42.735035 [debug] [ThreadPool]: SQL status: SELECT 5 in 0.0 seconds
[0m12:14:42.738041 [debug] [ThreadPool]: On list_mydb: Close
[0m12:14:42.745892 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_mydb, now list_mydb_dbt_warehouse)
[0m12:14:42.758744 [debug] [ThreadPool]: Using postgres connection "list_mydb_dbt_warehouse"
[0m12:14:42.759709 [debug] [ThreadPool]: On list_mydb_dbt_warehouse: BEGIN
[0m12:14:42.760798 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:14:42.786957 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m12:14:42.788335 [debug] [ThreadPool]: Using postgres connection "list_mydb_dbt_warehouse"
[0m12:14:42.789679 [debug] [ThreadPool]: On list_mydb_dbt_warehouse: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "connection_name": "list_mydb_dbt_warehouse"} */
select
      'mydb' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_warehouse'
    union all
    select
      'mydb' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_warehouse'
  
[0m12:14:42.809145 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.0 seconds
[0m12:14:42.812499 [debug] [ThreadPool]: On list_mydb_dbt_warehouse: ROLLBACK
[0m12:14:42.815332 [debug] [ThreadPool]: On list_mydb_dbt_warehouse: Close
[0m12:14:42.831491 [debug] [MainThread]: Using postgres connection "master"
[0m12:14:42.833345 [debug] [MainThread]: On master: BEGIN
[0m12:14:42.834818 [debug] [MainThread]: Opening a new connection, currently in state init
[0m12:14:42.882513 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m12:14:42.883249 [debug] [MainThread]: Using postgres connection "master"
[0m12:14:42.883880 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m12:14:42.913303 [debug] [MainThread]: SQL status: SELECT 5 in 0.0 seconds
[0m12:14:42.916082 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4665367a-1401-45c5-8ab6-b42423104c39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a8d40a0>]}
[0m12:14:42.916948 [debug] [MainThread]: On master: ROLLBACK
[0m12:14:42.920869 [debug] [MainThread]: Using postgres connection "master"
[0m12:14:42.922077 [debug] [MainThread]: On master: BEGIN
[0m12:14:42.929648 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m12:14:42.930740 [debug] [MainThread]: On master: COMMIT
[0m12:14:42.931284 [debug] [MainThread]: Using postgres connection "master"
[0m12:14:42.931750 [debug] [MainThread]: On master: COMMIT
[0m12:14:42.935174 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m12:14:42.936146 [debug] [MainThread]: On master: Close
[0m12:14:42.937805 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m12:14:42.939832 [info ] [MainThread]: 
[0m12:14:42.954361 [debug] [Thread-1  ]: Began running node model.maker_warehouse.avg_duration_year_month
[0m12:14:42.955266 [debug] [Thread-2  ]: Began running node model.maker_warehouse.avg_viewing_time
[0m12:14:42.955869 [debug] [Thread-3  ]: Began running node model.maker_warehouse.movies
[0m12:14:42.956554 [debug] [Thread-4  ]: Began running node model.maker_warehouse.no_of_viewings
[0m12:14:42.963291 [info ] [Thread-4  ]: 4 of 10 START sql table model dbt_warehouse.no_of_viewings ..................... [RUN]
[0m12:14:42.964769 [debug] [Thread-4  ]: Acquiring new postgres connection 'model.maker_warehouse.no_of_viewings'
[0m12:14:42.965411 [debug] [Thread-4  ]: Began compiling node model.maker_warehouse.no_of_viewings
[0m12:14:42.957368 [info ] [Thread-1  ]: 1 of 10 START sql table model dbt_warehouse.avg_duration_year_month ............ [RUN]
[0m12:14:42.997475 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_mydb_dbt_warehouse, now model.maker_warehouse.avg_duration_year_month)
[0m12:14:42.998181 [debug] [Thread-1  ]: Began compiling node model.maker_warehouse.avg_duration_year_month
[0m12:14:42.958956 [info ] [Thread-2  ]: 2 of 10 START sql table model dbt_warehouse.avg_viewing_time ................... [RUN]
[0m12:14:42.961850 [info ] [Thread-3  ]: 3 of 10 START sql table model dbt_warehouse.movies ............................. [RUN]
[0m12:14:42.995339 [debug] [Thread-4  ]: Writing injected SQL for node "model.maker_warehouse.no_of_viewings"
[0m12:14:43.017766 [debug] [Thread-1  ]: Writing injected SQL for node "model.maker_warehouse.avg_duration_year_month"
[0m12:14:43.020121 [debug] [Thread-2  ]: Acquiring new postgres connection 'model.maker_warehouse.avg_viewing_time'
[0m12:14:43.022239 [debug] [Thread-3  ]: Acquiring new postgres connection 'model.maker_warehouse.movies'
[0m12:14:43.026446 [debug] [Thread-2  ]: Began compiling node model.maker_warehouse.avg_viewing_time
[0m12:14:43.027648 [debug] [Thread-4  ]: Timing info for model.maker_warehouse.no_of_viewings (compile): 12:14:42.966138 => 12:14:43.027032
[0m12:14:43.028755 [debug] [Thread-3  ]: Began compiling node model.maker_warehouse.movies
[0m12:14:43.035685 [debug] [Thread-1  ]: Timing info for model.maker_warehouse.avg_duration_year_month (compile): 12:14:42.998965 => 12:14:43.035022
[0m12:14:43.042185 [debug] [Thread-2  ]: Writing injected SQL for node "model.maker_warehouse.avg_viewing_time"
[0m12:14:43.043368 [debug] [Thread-4  ]: Began executing node model.maker_warehouse.no_of_viewings
[0m12:14:43.051285 [debug] [Thread-3  ]: Writing injected SQL for node "model.maker_warehouse.movies"
[0m12:14:43.052451 [debug] [Thread-1  ]: Began executing node model.maker_warehouse.avg_duration_year_month
[0m12:14:43.071678 [debug] [Thread-2  ]: Timing info for model.maker_warehouse.avg_viewing_time (compile): 12:14:43.029557 => 12:14:43.071253
[0m12:14:43.107432 [debug] [Thread-2  ]: Began executing node model.maker_warehouse.avg_viewing_time
[0m12:14:43.160089 [debug] [Thread-3  ]: Timing info for model.maker_warehouse.movies (compile): 12:14:43.044039 => 12:14:43.159151
[0m12:14:43.201393 [debug] [Thread-1  ]: Writing runtime sql for node "model.maker_warehouse.avg_duration_year_month"
[0m12:14:43.205455 [debug] [Thread-4  ]: Writing runtime sql for node "model.maker_warehouse.no_of_viewings"
[0m12:14:43.213315 [debug] [Thread-3  ]: Began executing node model.maker_warehouse.movies
[0m12:14:43.213924 [debug] [Thread-2  ]: Writing runtime sql for node "model.maker_warehouse.avg_viewing_time"
[0m12:14:43.223007 [debug] [Thread-3  ]: Writing runtime sql for node "model.maker_warehouse.movies"
[0m12:14:43.223772 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.avg_duration_year_month"
[0m12:14:43.224513 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.no_of_viewings"
[0m12:14:43.226063 [debug] [Thread-1  ]: On model.maker_warehouse.avg_duration_year_month: BEGIN
[0m12:14:43.226845 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.avg_viewing_time"
[0m12:14:43.227340 [debug] [Thread-4  ]: On model.maker_warehouse.no_of_viewings: BEGIN
[0m12:14:43.227858 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.movies"
[0m12:14:43.228416 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m12:14:43.228973 [debug] [Thread-2  ]: On model.maker_warehouse.avg_viewing_time: BEGIN
[0m12:14:43.229526 [debug] [Thread-4  ]: Opening a new connection, currently in state init
[0m12:14:43.230077 [debug] [Thread-3  ]: On model.maker_warehouse.movies: BEGIN
[0m12:14:43.231059 [debug] [Thread-2  ]: Opening a new connection, currently in state init
[0m12:14:43.232624 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m12:14:43.279815 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
[0m12:14:43.281285 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.avg_duration_year_month"
[0m12:14:43.282470 [debug] [Thread-1  ]: On model.maker_warehouse.avg_duration_year_month: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.avg_duration_year_month"} */

  
    

  create  table "mydb"."dbt_warehouse"."avg_duration_year_month__dbt_tmp"
  
  
    as
  
  (
    
CREATE VIEW avg_viewing_time_year_month AS
SELECT
    EXTRACT(YEAR FROM CAST("datetime" AS DATE)) AS "Year",
    EXTRACT(MONTH FROM CAST("datetime" AS DATE)) AS "Month",
    ROUND(CAST(AVG(duration) AS NUMERIC), 2) AS "Average_Duration"
FROM
    mydb.public.raw_netflix
GROUP BY
    EXTRACT(YEAR FROM CAST("datetime" AS DATE)),
    EXTRACT(MONTH FROM CAST("datetime" AS DATE))
ORDER BY
    "Year", "Month"
  );
  
[0m12:14:43.289576 [debug] [Thread-1  ]: Postgres adapter: Postgres error: syntax error at or near "CREATE"
LINE 13: CREATE VIEW avg_viewing_time_year_month AS
         ^

[0m12:14:43.291186 [debug] [Thread-1  ]: On model.maker_warehouse.avg_duration_year_month: ROLLBACK
[0m12:14:43.294771 [debug] [Thread-4  ]: SQL status: BEGIN in 0.0 seconds
[0m12:14:43.295454 [debug] [Thread-2  ]: SQL status: BEGIN in 0.0 seconds
[0m12:14:43.296558 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.no_of_viewings"
[0m12:14:43.298279 [debug] [Thread-1  ]: Timing info for model.maker_warehouse.avg_duration_year_month (execute): 12:14:43.094806 => 12:14:43.297627
[0m12:14:43.299876 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.avg_viewing_time"
[0m12:14:43.301417 [debug] [Thread-4  ]: On model.maker_warehouse.no_of_viewings: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.no_of_viewings"} */

  
    

  create  table "mydb"."dbt_warehouse"."no_of_viewings__dbt_tmp"
  
  
    as
  
  (
    
SELECT
  title,
  COUNT(*) as total_views
FROM mydb.public.raw_netflix
GROUP BY title
ORDER BY total_views DESC
  );
  
[0m12:14:43.302713 [debug] [Thread-1  ]: On model.maker_warehouse.avg_duration_year_month: Close
[0m12:14:43.303799 [debug] [Thread-2  ]: On model.maker_warehouse.avg_viewing_time: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.avg_viewing_time"} */

  
    

  create  table "mydb"."dbt_warehouse"."avg_viewing_time__dbt_tmp"
  
  
    as
  
  (
    
SELECT
title,
ROUND(CAST(AVG(duration) AS NUMERIC), 2) as avg_duration
FROM mydb.public.raw_netflix
GROUP BY title
ORDER BY avg_duration DESC
  );
  
[0m12:14:43.304836 [debug] [Thread-3  ]: SQL status: BEGIN in 0.0 seconds
[0m12:14:43.307423 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.movies"
[0m12:14:43.309605 [debug] [Thread-3  ]: On model.maker_warehouse.movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.movies"} */

  
    

  create  table "mydb"."dbt_warehouse"."movies__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    DISTINCT
    title,
    genres,
    release_date,
    movie_id
FROM mydb.public.raw_netflix
  );
  
[0m12:14:43.321260 [debug] [Thread-1  ]: Database Error in model avg_duration_year_month (models/summary/avg_duration_year_month.sql)
  syntax error at or near "CREATE"
  LINE 13: CREATE VIEW avg_viewing_time_year_month AS
           ^
  compiled Code at target/run/maker_warehouse/models/summary/avg_duration_year_month.sql
[0m12:14:43.322390 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4665367a-1401-45c5-8ab6-b42423104c39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10aaf3070>]}
[0m12:14:43.323916 [error] [Thread-1  ]: 1 of 10 ERROR creating sql table model dbt_warehouse.avg_duration_year_month ... [[31mERROR[0m in 0.33s]
[0m12:14:43.325465 [debug] [Thread-1  ]: Finished running node model.maker_warehouse.avg_duration_year_month
[0m12:14:43.326709 [debug] [Thread-1  ]: Began running node model.maker_warehouse.total_duration_year_month
[0m12:14:43.328329 [info ] [Thread-1  ]: 5 of 10 START sql table model dbt_warehouse.total_duration_year_month .......... [RUN]
[0m12:14:43.330239 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.maker_warehouse.avg_duration_year_month, now model.maker_warehouse.total_duration_year_month)
[0m12:14:43.330972 [debug] [Thread-1  ]: Began compiling node model.maker_warehouse.total_duration_year_month
[0m12:14:43.338264 [debug] [Thread-1  ]: Writing injected SQL for node "model.maker_warehouse.total_duration_year_month"
[0m12:14:43.344071 [debug] [Thread-1  ]: Timing info for model.maker_warehouse.total_duration_year_month (compile): 12:14:43.331421 => 12:14:43.341950
[0m12:14:43.345399 [debug] [Thread-1  ]: Began executing node model.maker_warehouse.total_duration_year_month
[0m12:14:43.365100 [debug] [Thread-1  ]: Writing runtime sql for node "model.maker_warehouse.total_duration_year_month"
[0m12:14:43.367080 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.total_duration_year_month"
[0m12:14:43.368181 [debug] [Thread-1  ]: On model.maker_warehouse.total_duration_year_month: BEGIN
[0m12:14:43.369321 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m12:14:43.432673 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
[0m12:14:43.434053 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.total_duration_year_month"
[0m12:14:43.435657 [debug] [Thread-1  ]: On model.maker_warehouse.total_duration_year_month: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_duration_year_month"} */

  
    

  create  table "mydb"."dbt_warehouse"."total_duration_year_month__dbt_tmp"
  
  
    as
  
  (
    
CREATE VIEW total_viewing_time_year_month AS
SELECT
    EXTRACT(YEAR FROM CAST("datetime" AS DATE)) AS "Year",
    EXTRACT(MONTH FROM CAST("datetime" AS DATE)) AS "Month",
    SUM(duration) AS "Total_Duration"
FROM
    mydb.public.raw_netflix
GROUP BY
    EXTRACT(YEAR FROM CAST("datetime" AS DATE)),
    EXTRACT(MONTH FROM CAST("datetime" AS DATE))
ORDER BY
    "Year", "Month"
  );
  
[0m12:14:43.440996 [debug] [Thread-1  ]: Postgres adapter: Postgres error: syntax error at or near "CREATE"
LINE 13: CREATE VIEW total_viewing_time_year_month AS
         ^

[0m12:14:43.442798 [debug] [Thread-1  ]: On model.maker_warehouse.total_duration_year_month: ROLLBACK
[0m12:14:43.446780 [debug] [Thread-1  ]: Timing info for model.maker_warehouse.total_duration_year_month (execute): 12:14:43.346289 => 12:14:43.446054
[0m12:14:43.448376 [debug] [Thread-1  ]: On model.maker_warehouse.total_duration_year_month: Close
[0m12:14:43.452182 [debug] [Thread-1  ]: Database Error in model total_duration_year_month (models/summary/total_duration_year_month.sql)
  syntax error at or near "CREATE"
  LINE 13: CREATE VIEW total_viewing_time_year_month AS
           ^
  compiled Code at target/run/maker_warehouse/models/summary/total_duration_year_month.sql
[0m12:14:43.454000 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4665367a-1401-45c5-8ab6-b42423104c39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10aaea700>]}
[0m12:14:43.456087 [error] [Thread-1  ]: 5 of 10 ERROR creating sql table model dbt_warehouse.total_duration_year_month . [[31mERROR[0m in 0.12s]
[0m12:14:43.458120 [debug] [Thread-1  ]: Finished running node model.maker_warehouse.total_duration_year_month
[0m12:14:43.464633 [debug] [Thread-1  ]: Began running node model.maker_warehouse.total_unique_users
[0m12:14:43.466117 [info ] [Thread-1  ]: 6 of 10 START sql table model dbt_warehouse.total_unique_users ................. [RUN]
[0m12:14:43.468252 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.maker_warehouse.total_duration_year_month, now model.maker_warehouse.total_unique_users)
[0m12:14:43.469291 [debug] [Thread-1  ]: Began compiling node model.maker_warehouse.total_unique_users
[0m12:14:43.483585 [debug] [Thread-1  ]: Writing injected SQL for node "model.maker_warehouse.total_unique_users"
[0m12:14:43.486838 [debug] [Thread-1  ]: Timing info for model.maker_warehouse.total_unique_users (compile): 12:14:43.469931 => 12:14:43.485550
[0m12:14:43.487851 [debug] [Thread-1  ]: Began executing node model.maker_warehouse.total_unique_users
[0m12:14:43.512871 [debug] [Thread-1  ]: Writing runtime sql for node "model.maker_warehouse.total_unique_users"
[0m12:14:43.515770 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.total_unique_users"
[0m12:14:43.517380 [debug] [Thread-1  ]: On model.maker_warehouse.total_unique_users: BEGIN
[0m12:14:43.518791 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m12:14:43.602934 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
[0m12:14:43.604978 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.total_unique_users"
[0m12:14:43.610018 [debug] [Thread-1  ]: On model.maker_warehouse.total_unique_users: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_unique_users"} */

  
    

  create  table "mydb"."dbt_warehouse"."total_unique_users__dbt_tmp"
  
  
    as
  
  (
    
SELECT 
COUNT(DISTINCT(user_id)) AS total_unique_users
FROM mydb.public.raw_netflix
  );
  
[0m12:14:44.435639 [debug] [Thread-4  ]: SQL status: SELECT 7925 in 1.0 seconds
[0m12:14:44.455962 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.no_of_viewings"
[0m12:14:44.457224 [debug] [Thread-4  ]: On model.maker_warehouse.no_of_viewings: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.no_of_viewings"} */
alter table "mydb"."dbt_warehouse"."no_of_viewings" rename to "no_of_viewings__dbt_backup"
[0m12:14:44.472220 [debug] [Thread-4  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:14:44.481696 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.no_of_viewings"
[0m12:14:44.483110 [debug] [Thread-4  ]: On model.maker_warehouse.no_of_viewings: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.no_of_viewings"} */
alter table "mydb"."dbt_warehouse"."no_of_viewings__dbt_tmp" rename to "no_of_viewings"
[0m12:14:44.492762 [debug] [Thread-4  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:14:44.539284 [debug] [Thread-2  ]: SQL status: SELECT 7925 in 1.0 seconds
[0m12:14:44.557725 [debug] [Thread-4  ]: On model.maker_warehouse.no_of_viewings: COMMIT
[0m12:14:44.563145 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.avg_viewing_time"
[0m12:14:44.564378 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.no_of_viewings"
[0m12:14:44.565513 [debug] [Thread-2  ]: On model.maker_warehouse.avg_viewing_time: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.avg_viewing_time"} */
alter table "mydb"."dbt_warehouse"."avg_viewing_time" rename to "avg_viewing_time__dbt_backup"
[0m12:14:44.566807 [debug] [Thread-4  ]: On model.maker_warehouse.no_of_viewings: COMMIT
[0m12:14:44.575272 [debug] [Thread-2  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:14:44.582620 [debug] [Thread-4  ]: SQL status: COMMIT in 0.0 seconds
[0m12:14:44.584738 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.avg_viewing_time"
[0m12:14:44.599258 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.no_of_viewings"
[0m12:14:44.600358 [debug] [Thread-2  ]: On model.maker_warehouse.avg_viewing_time: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.avg_viewing_time"} */
alter table "mydb"."dbt_warehouse"."avg_viewing_time__dbt_tmp" rename to "avg_viewing_time"
[0m12:14:44.601985 [debug] [Thread-4  ]: On model.maker_warehouse.no_of_viewings: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.no_of_viewings"} */
drop table if exists "mydb"."dbt_warehouse"."no_of_viewings__dbt_backup" cascade
[0m12:14:44.609759 [debug] [Thread-2  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:14:44.617918 [debug] [Thread-4  ]: SQL status: DROP TABLE in 0.0 seconds
[0m12:14:44.617305 [debug] [Thread-2  ]: On model.maker_warehouse.avg_viewing_time: COMMIT
[0m12:14:44.623583 [debug] [Thread-4  ]: Timing info for model.maker_warehouse.no_of_viewings (execute): 12:14:43.053580 => 12:14:44.622855
[0m12:14:44.624739 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.avg_viewing_time"
[0m12:14:44.625766 [debug] [Thread-4  ]: On model.maker_warehouse.no_of_viewings: Close
[0m12:14:44.626754 [debug] [Thread-2  ]: On model.maker_warehouse.avg_viewing_time: COMMIT
[0m12:14:44.629013 [debug] [Thread-4  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4665367a-1401-45c5-8ab6-b42423104c39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ab03eb0>]}
[0m12:14:44.630219 [info ] [Thread-4  ]: 4 of 10 OK created sql table model dbt_warehouse.no_of_viewings ................ [[32mSELECT 7925[0m in 1.66s]
[0m12:14:44.634335 [debug] [Thread-4  ]: Finished running node model.maker_warehouse.no_of_viewings
[0m12:14:44.635911 [debug] [Thread-2  ]: SQL status: COMMIT in 0.0 seconds
[0m12:14:44.637106 [debug] [Thread-4  ]: Began running node model.maker_warehouse.total_viewing_time
[0m12:14:44.647544 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.avg_viewing_time"
[0m12:14:44.648725 [debug] [Thread-2  ]: On model.maker_warehouse.avg_viewing_time: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.avg_viewing_time"} */
drop table if exists "mydb"."dbt_warehouse"."avg_viewing_time__dbt_backup" cascade
[0m12:14:44.645979 [info ] [Thread-4  ]: 7 of 10 START sql table model dbt_warehouse.total_viewing_time ................. [RUN]
[0m12:14:44.651342 [debug] [Thread-4  ]: Re-using an available connection from the pool (formerly model.maker_warehouse.no_of_viewings, now model.maker_warehouse.total_viewing_time)
[0m12:14:44.652586 [debug] [Thread-4  ]: Began compiling node model.maker_warehouse.total_viewing_time
[0m12:14:44.665822 [debug] [Thread-4  ]: Writing injected SQL for node "model.maker_warehouse.total_viewing_time"
[0m12:14:44.669807 [debug] [Thread-4  ]: Timing info for model.maker_warehouse.total_viewing_time (compile): 12:14:44.653316 => 12:14:44.668520
[0m12:14:44.671102 [debug] [Thread-2  ]: SQL status: DROP TABLE in 0.0 seconds
[0m12:14:44.673145 [debug] [Thread-4  ]: Began executing node model.maker_warehouse.total_viewing_time
[0m12:14:44.677900 [debug] [Thread-2  ]: Timing info for model.maker_warehouse.avg_viewing_time (execute): 12:14:43.118781 => 12:14:44.677548
[0m12:14:44.692226 [debug] [Thread-2  ]: On model.maker_warehouse.avg_viewing_time: Close
[0m12:14:44.695291 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4665367a-1401-45c5-8ab6-b42423104c39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ac41e80>]}
[0m12:14:44.700692 [info ] [Thread-2  ]: 2 of 10 OK created sql table model dbt_warehouse.avg_viewing_time .............. [[32mSELECT 7925[0m in 1.68s]
[0m12:14:44.703822 [debug] [Thread-4  ]: Writing runtime sql for node "model.maker_warehouse.total_viewing_time"
[0m12:14:44.707132 [debug] [Thread-2  ]: Finished running node model.maker_warehouse.avg_viewing_time
[0m12:14:44.709301 [debug] [Thread-2  ]: Began running node model.maker_warehouse.total_viewings_year_month
[0m12:14:44.711128 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.total_viewing_time"
[0m12:14:44.712934 [info ] [Thread-2  ]: 8 of 10 START sql table model dbt_warehouse.total_viewings_year_month .......... [RUN]
[0m12:14:44.714811 [debug] [Thread-4  ]: On model.maker_warehouse.total_viewing_time: BEGIN
[0m12:14:44.717232 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly model.maker_warehouse.avg_viewing_time, now model.maker_warehouse.total_viewings_year_month)
[0m12:14:44.719767 [debug] [Thread-4  ]: Opening a new connection, currently in state closed
[0m12:14:44.721933 [debug] [Thread-2  ]: Began compiling node model.maker_warehouse.total_viewings_year_month
[0m12:14:44.733715 [debug] [Thread-2  ]: Writing injected SQL for node "model.maker_warehouse.total_viewings_year_month"
[0m12:14:44.737014 [debug] [Thread-2  ]: Timing info for model.maker_warehouse.total_viewings_year_month (compile): 12:14:44.723275 => 12:14:44.735974
[0m12:14:44.738146 [debug] [Thread-2  ]: Began executing node model.maker_warehouse.total_viewings_year_month
[0m12:14:44.756382 [debug] [Thread-2  ]: Writing runtime sql for node "model.maker_warehouse.total_viewings_year_month"
[0m12:14:44.758555 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.total_viewings_year_month"
[0m12:14:44.764376 [debug] [Thread-2  ]: On model.maker_warehouse.total_viewings_year_month: BEGIN
[0m12:14:44.765488 [debug] [Thread-2  ]: Opening a new connection, currently in state closed
[0m12:14:44.784839 [debug] [Thread-4  ]: SQL status: BEGIN in 0.0 seconds
[0m12:14:44.786187 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.total_viewing_time"
[0m12:14:44.787418 [debug] [Thread-4  ]: On model.maker_warehouse.total_viewing_time: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_viewing_time"} */

  
    

  create  table "mydb"."dbt_warehouse"."total_viewing_time__dbt_tmp"
  
  
    as
  
  (
    
SELECT
title,
SUM(duration) as total_duration
FROM mydb.public.raw_netflix
GROUP BY title
ORDER BY total_duration DESC
  );
  
[0m12:14:44.827674 [debug] [Thread-2  ]: SQL status: BEGIN in 0.0 seconds
[0m12:14:44.828896 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.total_viewings_year_month"
[0m12:14:44.830088 [debug] [Thread-2  ]: On model.maker_warehouse.total_viewings_year_month: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_viewings_year_month"} */

  
    

  create  table "mydb"."dbt_warehouse"."total_viewings_year_month__dbt_tmp"
  
  
    as
  
  (
    
CREATE VIEW total_viewings_year_month AS
SELECT
    EXTRACT(YEAR FROM CAST("datetime" AS DATE)) AS "Year",
    EXTRACT(MONTH FROM CAST("datetime" AS DATE)) AS "Month",
    COUNT(*) AS "Total_Views"
FROM mydb.public.raw_netflix
GROUP BY
    EXTRACT(YEAR FROM CAST("datetime" AS DATE)),
    EXTRACT(MONTH FROM CAST("datetime" AS DATE))
ORDER BY
    "Year", "Month"
  );
  
[0m12:14:44.834808 [debug] [Thread-2  ]: Postgres adapter: Postgres error: syntax error at or near "CREATE"
LINE 13: CREATE VIEW total_viewings_year_month AS
         ^

[0m12:14:44.836041 [debug] [Thread-2  ]: On model.maker_warehouse.total_viewings_year_month: ROLLBACK
[0m12:14:44.839135 [debug] [Thread-2  ]: Timing info for model.maker_warehouse.total_viewings_year_month (execute): 12:14:44.739647 => 12:14:44.838480
[0m12:14:44.840268 [debug] [Thread-2  ]: On model.maker_warehouse.total_viewings_year_month: Close
[0m12:14:44.844954 [debug] [Thread-2  ]: Database Error in model total_viewings_year_month (models/summary/total_viewings_year_month.sql)
  syntax error at or near "CREATE"
  LINE 13: CREATE VIEW total_viewings_year_month AS
           ^
  compiled Code at target/run/maker_warehouse/models/summary/total_viewings_year_month.sql
[0m12:14:44.846413 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4665367a-1401-45c5-8ab6-b42423104c39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10abcb730>]}
[0m12:14:44.848508 [error] [Thread-2  ]: 8 of 10 ERROR creating sql table model dbt_warehouse.total_viewings_year_month . [[31mERROR[0m in 0.13s]
[0m12:14:44.850954 [debug] [Thread-2  ]: Finished running node model.maker_warehouse.total_viewings_year_month
[0m12:14:44.852146 [debug] [Thread-2  ]: Began running node model.maker_warehouse.user_engagement
[0m12:14:44.853589 [info ] [Thread-2  ]: 9 of 10 START sql table model dbt_warehouse.user_engagement .................... [RUN]
[0m12:14:44.856548 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly model.maker_warehouse.total_viewings_year_month, now model.maker_warehouse.user_engagement)
[0m12:14:44.857829 [debug] [Thread-2  ]: Began compiling node model.maker_warehouse.user_engagement
[0m12:14:44.870054 [debug] [Thread-2  ]: Writing injected SQL for node "model.maker_warehouse.user_engagement"
[0m12:14:44.872841 [debug] [Thread-2  ]: Timing info for model.maker_warehouse.user_engagement (compile): 12:14:44.859828 => 12:14:44.872171
[0m12:14:44.874581 [debug] [Thread-2  ]: Began executing node model.maker_warehouse.user_engagement
[0m12:14:44.890675 [debug] [Thread-2  ]: Writing runtime sql for node "model.maker_warehouse.user_engagement"
[0m12:14:44.892918 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.user_engagement"
[0m12:14:44.894223 [debug] [Thread-2  ]: On model.maker_warehouse.user_engagement: BEGIN
[0m12:14:44.895466 [debug] [Thread-2  ]: Opening a new connection, currently in state closed
[0m12:14:44.968685 [debug] [Thread-2  ]: SQL status: BEGIN in 0.0 seconds
[0m12:14:44.969869 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.user_engagement"
[0m12:14:44.971423 [debug] [Thread-2  ]: On model.maker_warehouse.user_engagement: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.user_engagement"} */

  
    

  create  table "mydb"."dbt_warehouse"."user_engagement__dbt_tmp"
  
  
    as
  
  (
    
SELECT 
DISTINCT(user_id),
COUNT(DISTINCT(title)) AS total_titles,
SUM(duration) AS total_duration
FROM mydb.public.raw_netflix
GROUP BY user_id
  );
  
[0m12:14:45.456104 [debug] [Thread-4  ]: SQL status: SELECT 7925 in 1.0 seconds
[0m12:14:45.464296 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.total_viewing_time"
[0m12:14:45.465459 [debug] [Thread-4  ]: On model.maker_warehouse.total_viewing_time: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_viewing_time"} */
alter table "mydb"."dbt_warehouse"."total_viewing_time" rename to "total_viewing_time__dbt_backup"
[0m12:14:45.469331 [debug] [Thread-4  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:14:45.477403 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.total_viewing_time"
[0m12:14:45.478898 [debug] [Thread-4  ]: On model.maker_warehouse.total_viewing_time: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_viewing_time"} */
alter table "mydb"."dbt_warehouse"."total_viewing_time__dbt_tmp" rename to "total_viewing_time"
[0m12:14:45.483932 [debug] [Thread-4  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:14:45.490795 [debug] [Thread-4  ]: On model.maker_warehouse.total_viewing_time: COMMIT
[0m12:14:45.491923 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.total_viewing_time"
[0m12:14:45.492833 [debug] [Thread-4  ]: On model.maker_warehouse.total_viewing_time: COMMIT
[0m12:14:45.497797 [debug] [Thread-4  ]: SQL status: COMMIT in 0.0 seconds
[0m12:14:45.505744 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.total_viewing_time"
[0m12:14:45.507005 [debug] [Thread-4  ]: On model.maker_warehouse.total_viewing_time: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_viewing_time"} */
drop table if exists "mydb"."dbt_warehouse"."total_viewing_time__dbt_backup" cascade
[0m12:14:45.518606 [debug] [Thread-4  ]: SQL status: DROP TABLE in 0.0 seconds
[0m12:14:45.524720 [debug] [Thread-4  ]: Timing info for model.maker_warehouse.total_viewing_time (execute): 12:14:44.678594 => 12:14:45.524034
[0m12:14:45.526295 [debug] [Thread-4  ]: On model.maker_warehouse.total_viewing_time: Close
[0m12:14:45.528222 [debug] [Thread-4  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4665367a-1401-45c5-8ab6-b42423104c39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10aadee50>]}
[0m12:14:45.529967 [info ] [Thread-4  ]: 7 of 10 OK created sql table model dbt_warehouse.total_viewing_time ............ [[32mSELECT 7925[0m in 0.88s]
[0m12:14:45.532003 [debug] [Thread-4  ]: Finished running node model.maker_warehouse.total_viewing_time
[0m12:14:45.954183 [debug] [Thread-3  ]: SQL status: SELECT 8472 in 3.0 seconds
[0m12:14:45.967245 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.movies"
[0m12:14:45.967956 [debug] [Thread-3  ]: On model.maker_warehouse.movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.movies"} */
alter table "mydb"."dbt_warehouse"."movies" rename to "movies__dbt_backup"
[0m12:14:45.976099 [debug] [Thread-3  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:14:45.991318 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.movies"
[0m12:14:45.992299 [debug] [Thread-3  ]: On model.maker_warehouse.movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.movies"} */
alter table "mydb"."dbt_warehouse"."movies__dbt_tmp" rename to "movies"
[0m12:14:46.004237 [debug] [Thread-3  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:14:46.016533 [debug] [Thread-3  ]: On model.maker_warehouse.movies: COMMIT
[0m12:14:46.017880 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.movies"
[0m12:14:46.019044 [debug] [Thread-3  ]: On model.maker_warehouse.movies: COMMIT
[0m12:14:46.029285 [debug] [Thread-3  ]: SQL status: COMMIT in 0.0 seconds
[0m12:14:46.037193 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.movies"
[0m12:14:46.039016 [debug] [Thread-3  ]: On model.maker_warehouse.movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.movies"} */
drop table if exists "mydb"."dbt_warehouse"."movies__dbt_backup" cascade
[0m12:14:46.060088 [debug] [Thread-3  ]: SQL status: DROP TABLE in 0.0 seconds
[0m12:14:46.064302 [debug] [Thread-3  ]: Timing info for model.maker_warehouse.movies (execute): 12:14:43.215022 => 12:14:46.063545
[0m12:14:46.065365 [debug] [Thread-3  ]: On model.maker_warehouse.movies: Close
[0m12:14:46.067245 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4665367a-1401-45c5-8ab6-b42423104c39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ac50d00>]}
[0m12:14:46.068846 [info ] [Thread-3  ]: 3 of 10 OK created sql table model dbt_warehouse.movies ........................ [[32mSELECT 8472[0m in 3.05s]
[0m12:14:46.072174 [debug] [Thread-3  ]: Finished running node model.maker_warehouse.movies
[0m12:14:46.073916 [debug] [Thread-4  ]: Began running node model.maker_warehouse.all_movies
[0m12:14:46.075371 [info ] [Thread-4  ]: 10 of 10 START sql table model dbt_warehouse.all_movies ........................ [RUN]
[0m12:14:46.077415 [debug] [Thread-4  ]: Re-using an available connection from the pool (formerly model.maker_warehouse.total_viewing_time, now model.maker_warehouse.all_movies)
[0m12:14:46.078507 [debug] [Thread-4  ]: Began compiling node model.maker_warehouse.all_movies
[0m12:14:46.086643 [debug] [Thread-4  ]: Writing injected SQL for node "model.maker_warehouse.all_movies"
[0m12:14:46.090784 [debug] [Thread-4  ]: Timing info for model.maker_warehouse.all_movies (compile): 12:14:46.079222 => 12:14:46.089847
[0m12:14:46.092289 [debug] [Thread-4  ]: Began executing node model.maker_warehouse.all_movies
[0m12:14:46.110187 [debug] [Thread-4  ]: Writing runtime sql for node "model.maker_warehouse.all_movies"
[0m12:14:46.112346 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.all_movies"
[0m12:14:46.113285 [debug] [Thread-4  ]: On model.maker_warehouse.all_movies: BEGIN
[0m12:14:46.114277 [debug] [Thread-4  ]: Opening a new connection, currently in state closed
[0m12:14:46.179785 [debug] [Thread-4  ]: SQL status: BEGIN in 0.0 seconds
[0m12:14:46.180997 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.all_movies"
[0m12:14:46.182071 [debug] [Thread-4  ]: On model.maker_warehouse.all_movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.all_movies"} */

  
    

  create  table "mydb"."dbt_warehouse"."all_movies__dbt_tmp"
  
  
    as
  
  (
    
  
SELECT
*
FROM "mydb"."dbt_warehouse"."movies"
  );
  
[0m12:14:46.245292 [debug] [Thread-4  ]: SQL status: SELECT 8472 in 0.0 seconds
[0m12:14:46.251988 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.all_movies"
[0m12:14:46.253155 [debug] [Thread-4  ]: On model.maker_warehouse.all_movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.all_movies"} */
alter table "mydb"."dbt_warehouse"."all_movies" rename to "all_movies__dbt_backup"
[0m12:14:46.258282 [debug] [Thread-4  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:14:46.266822 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.all_movies"
[0m12:14:46.267863 [debug] [Thread-4  ]: On model.maker_warehouse.all_movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.all_movies"} */
alter table "mydb"."dbt_warehouse"."all_movies__dbt_tmp" rename to "all_movies"
[0m12:14:46.271873 [debug] [Thread-4  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:14:46.279734 [debug] [Thread-4  ]: On model.maker_warehouse.all_movies: COMMIT
[0m12:14:46.280871 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.all_movies"
[0m12:14:46.281928 [debug] [Thread-4  ]: On model.maker_warehouse.all_movies: COMMIT
[0m12:14:46.285876 [debug] [Thread-4  ]: SQL status: COMMIT in 0.0 seconds
[0m12:14:46.292683 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.all_movies"
[0m12:14:46.294230 [debug] [Thread-4  ]: On model.maker_warehouse.all_movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.all_movies"} */
drop table if exists "mydb"."dbt_warehouse"."all_movies__dbt_backup" cascade
[0m12:14:46.314849 [debug] [Thread-4  ]: SQL status: DROP TABLE in 0.0 seconds
[0m12:14:46.319896 [debug] [Thread-4  ]: Timing info for model.maker_warehouse.all_movies (execute): 12:14:46.092999 => 12:14:46.318427
[0m12:14:46.321802 [debug] [Thread-4  ]: On model.maker_warehouse.all_movies: Close
[0m12:14:46.323717 [debug] [Thread-4  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4665367a-1401-45c5-8ab6-b42423104c39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a72df70>]}
[0m12:14:46.325101 [info ] [Thread-4  ]: 10 of 10 OK created sql table model dbt_warehouse.all_movies ................... [[32mSELECT 8472[0m in 0.25s]
[0m12:14:46.327779 [debug] [Thread-4  ]: Finished running node model.maker_warehouse.all_movies
[0m12:14:47.952025 [debug] [Thread-1  ]: SQL status: SELECT 1 in 4.0 seconds
[0m12:14:47.958734 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.total_unique_users"
[0m12:14:47.960033 [debug] [Thread-1  ]: On model.maker_warehouse.total_unique_users: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_unique_users"} */
alter table "mydb"."dbt_warehouse"."total_unique_users" rename to "total_unique_users__dbt_backup"
[0m12:14:47.965774 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:14:47.973688 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.total_unique_users"
[0m12:14:47.974416 [debug] [Thread-1  ]: On model.maker_warehouse.total_unique_users: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_unique_users"} */
alter table "mydb"."dbt_warehouse"."total_unique_users__dbt_tmp" rename to "total_unique_users"
[0m12:14:47.978300 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:14:47.984468 [debug] [Thread-1  ]: On model.maker_warehouse.total_unique_users: COMMIT
[0m12:14:47.985136 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.total_unique_users"
[0m12:14:47.985688 [debug] [Thread-1  ]: On model.maker_warehouse.total_unique_users: COMMIT
[0m12:14:47.993519 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
[0m12:14:47.998963 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.total_unique_users"
[0m12:14:48.000030 [debug] [Thread-1  ]: On model.maker_warehouse.total_unique_users: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_unique_users"} */
drop table if exists "mydb"."dbt_warehouse"."total_unique_users__dbt_backup" cascade
[0m12:14:48.015555 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
[0m12:14:48.021149 [debug] [Thread-1  ]: Timing info for model.maker_warehouse.total_unique_users (execute): 12:14:43.488488 => 12:14:48.020386
[0m12:14:48.022348 [debug] [Thread-1  ]: On model.maker_warehouse.total_unique_users: Close
[0m12:14:48.023937 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4665367a-1401-45c5-8ab6-b42423104c39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10aadd580>]}
[0m12:14:48.025699 [info ] [Thread-1  ]: 6 of 10 OK created sql table model dbt_warehouse.total_unique_users ............ [[32mSELECT 1[0m in 4.56s]
[0m12:14:48.028932 [debug] [Thread-1  ]: Finished running node model.maker_warehouse.total_unique_users
[0m12:14:50.107119 [debug] [Thread-2  ]: SQL status: SELECT 161918 in 5.0 seconds
[0m12:14:50.115489 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.user_engagement"
[0m12:14:50.116191 [debug] [Thread-2  ]: On model.maker_warehouse.user_engagement: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.user_engagement"} */
alter table "mydb"."dbt_warehouse"."user_engagement" rename to "user_engagement__dbt_backup"
[0m12:14:50.119690 [debug] [Thread-2  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:14:50.127839 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.user_engagement"
[0m12:14:50.128626 [debug] [Thread-2  ]: On model.maker_warehouse.user_engagement: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.user_engagement"} */
alter table "mydb"."dbt_warehouse"."user_engagement__dbt_tmp" rename to "user_engagement"
[0m12:14:50.131287 [debug] [Thread-2  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:14:50.135649 [debug] [Thread-2  ]: On model.maker_warehouse.user_engagement: COMMIT
[0m12:14:50.136339 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.user_engagement"
[0m12:14:50.136897 [debug] [Thread-2  ]: On model.maker_warehouse.user_engagement: COMMIT
[0m12:14:50.149178 [debug] [Thread-2  ]: SQL status: COMMIT in 0.0 seconds
[0m12:14:50.153344 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.user_engagement"
[0m12:14:50.153986 [debug] [Thread-2  ]: On model.maker_warehouse.user_engagement: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.user_engagement"} */
drop table if exists "mydb"."dbt_warehouse"."user_engagement__dbt_backup" cascade
[0m12:14:50.170159 [debug] [Thread-2  ]: SQL status: DROP TABLE in 0.0 seconds
[0m12:14:50.172943 [debug] [Thread-2  ]: Timing info for model.maker_warehouse.user_engagement (execute): 12:14:44.875335 => 12:14:50.172422
[0m12:14:50.174155 [debug] [Thread-2  ]: On model.maker_warehouse.user_engagement: Close
[0m12:14:50.176331 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4665367a-1401-45c5-8ab6-b42423104c39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10aba93d0>]}
[0m12:14:50.177543 [info ] [Thread-2  ]: 9 of 10 OK created sql table model dbt_warehouse.user_engagement ............... [[32mSELECT 161918[0m in 5.32s]
[0m12:14:50.179345 [debug] [Thread-2  ]: Finished running node model.maker_warehouse.user_engagement
[0m12:14:50.184284 [debug] [MainThread]: Using postgres connection "master"
[0m12:14:50.185507 [debug] [MainThread]: On master: BEGIN
[0m12:14:50.186252 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m12:14:50.222426 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m12:14:50.223398 [debug] [MainThread]: On master: COMMIT
[0m12:14:50.224424 [debug] [MainThread]: Using postgres connection "master"
[0m12:14:50.224981 [debug] [MainThread]: On master: COMMIT
[0m12:14:50.228823 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m12:14:50.229455 [debug] [MainThread]: On master: Close
[0m12:14:50.230694 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:14:50.231380 [debug] [MainThread]: Connection 'model.maker_warehouse.total_unique_users' was properly closed.
[0m12:14:50.232195 [debug] [MainThread]: Connection 'model.maker_warehouse.all_movies' was properly closed.
[0m12:14:50.232719 [debug] [MainThread]: Connection 'model.maker_warehouse.user_engagement' was properly closed.
[0m12:14:50.233200 [debug] [MainThread]: Connection 'model.maker_warehouse.movies' was properly closed.
[0m12:14:50.234111 [info ] [MainThread]: 
[0m12:14:50.235535 [info ] [MainThread]: Finished running 10 table models in 0 hours 0 minutes and 7.71 seconds (7.71s).
[0m12:14:50.239996 [debug] [MainThread]: Command end result
[0m12:14:50.254272 [info ] [MainThread]: 
[0m12:14:50.255664 [info ] [MainThread]: [31mCompleted with 3 errors and 0 warnings:[0m
[0m12:14:50.256644 [info ] [MainThread]: 
[0m12:14:50.261408 [error] [MainThread]: [33mDatabase Error in model avg_duration_year_month (models/summary/avg_duration_year_month.sql)[0m
[0m12:14:50.263822 [error] [MainThread]:   syntax error at or near "CREATE"
[0m12:14:50.265112 [error] [MainThread]:   LINE 13: CREATE VIEW avg_viewing_time_year_month AS
[0m12:14:50.265763 [error] [MainThread]:            ^
[0m12:14:50.267169 [error] [MainThread]:   compiled Code at target/run/maker_warehouse/models/summary/avg_duration_year_month.sql
[0m12:14:50.268025 [info ] [MainThread]: 
[0m12:14:50.268664 [error] [MainThread]: [33mDatabase Error in model total_duration_year_month (models/summary/total_duration_year_month.sql)[0m
[0m12:14:50.269239 [error] [MainThread]:   syntax error at or near "CREATE"
[0m12:14:50.269795 [error] [MainThread]:   LINE 13: CREATE VIEW total_viewing_time_year_month AS
[0m12:14:50.270349 [error] [MainThread]:            ^
[0m12:14:50.270900 [error] [MainThread]:   compiled Code at target/run/maker_warehouse/models/summary/total_duration_year_month.sql
[0m12:14:50.271495 [info ] [MainThread]: 
[0m12:14:50.272582 [error] [MainThread]: [33mDatabase Error in model total_viewings_year_month (models/summary/total_viewings_year_month.sql)[0m
[0m12:14:50.273633 [error] [MainThread]:   syntax error at or near "CREATE"
[0m12:14:50.274861 [error] [MainThread]:   LINE 13: CREATE VIEW total_viewings_year_month AS
[0m12:14:50.275649 [error] [MainThread]:            ^
[0m12:14:50.276382 [error] [MainThread]:   compiled Code at target/run/maker_warehouse/models/summary/total_viewings_year_month.sql
[0m12:14:50.277035 [info ] [MainThread]: 
[0m12:14:50.277695 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=3 SKIP=0 TOTAL=10
[0m12:14:50.279398 [debug] [MainThread]: Command `dbt run` failed at 12:14:50.278980 after 8.54 seconds
[0m12:14:50.283159 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109111550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a681400>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ac07ac0>]}
[0m12:14:50.285004 [debug] [MainThread]: Flushing usage events
[0m12:16:45.574519 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105442550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1067dd2b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102fd5790>]}


============================== 12:16:45.587482 | 1775c36f-d78d-46c0-9a39-b6bbfc9c75a7 ==============================
[0m12:16:45.587482 [info ] [MainThread]: Running with dbt=1.5.4
[0m12:16:45.589614 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/denisechan/Documents/Makers/Data_Engineering/Week_6/dbt_warehouse', 'debug': 'False', 'version_check': 'True', 'log_path': '/Users/denisechan/Documents/Makers/Data_Engineering/Week_6/dbt_warehouse/logs', 'warn_error': 'None', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'log_format': 'default', 'introspect': 'True', 'target_path': 'None', 'send_anonymous_usage_stats': 'True'}
[0m12:16:45.786741 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '1775c36f-d78d-46c0-9a39-b6bbfc9c75a7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1067dd9d0>]}
[0m12:16:45.828420 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '1775c36f-d78d-46c0-9a39-b6bbfc9c75a7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106a416d0>]}
[0m12:16:45.830072 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m12:16:45.874441 [debug] [MainThread]: checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, vars: {}, profile: , target: , version: 1.5.4
[0m12:16:46.078846 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m12:16:46.079884 [debug] [MainThread]: Partial parsing: updated file: maker_warehouse://models/summary/avg_duration_year_month.sql
[0m12:16:46.135666 [debug] [MainThread]: 1699: static parser successfully parsed summary/avg_duration_year_month.sql
[0m12:16:46.188615 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1775c36f-d78d-46c0-9a39-b6bbfc9c75a7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106d170d0>]}
[0m12:16:46.208577 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1775c36f-d78d-46c0-9a39-b6bbfc9c75a7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106c0ad90>]}
[0m12:16:46.209961 [info ] [MainThread]: Found 10 models, 0 tests, 0 snapshots, 0 analyses, 307 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics, 0 groups
[0m12:16:46.211011 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1775c36f-d78d-46c0-9a39-b6bbfc9c75a7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106c0ad30>]}
[0m12:16:46.214086 [info ] [MainThread]: 
[0m12:16:46.215496 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m12:16:46.217882 [debug] [ThreadPool]: Acquiring new postgres connection 'list_mydb'
[0m12:16:46.237935 [debug] [ThreadPool]: Using postgres connection "list_mydb"
[0m12:16:46.238559 [debug] [ThreadPool]: On list_mydb: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "connection_name": "list_mydb"} */

    select distinct nspname from pg_namespace
  
[0m12:16:46.239112 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:16:46.453419 [debug] [ThreadPool]: SQL status: SELECT 5 in 0.0 seconds
[0m12:16:46.456558 [debug] [ThreadPool]: On list_mydb: Close
[0m12:16:46.464805 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_mydb, now list_mydb_dbt_warehouse)
[0m12:16:46.481191 [debug] [ThreadPool]: Using postgres connection "list_mydb_dbt_warehouse"
[0m12:16:46.482158 [debug] [ThreadPool]: On list_mydb_dbt_warehouse: BEGIN
[0m12:16:46.482812 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:16:46.511420 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m12:16:46.512665 [debug] [ThreadPool]: Using postgres connection "list_mydb_dbt_warehouse"
[0m12:16:46.513946 [debug] [ThreadPool]: On list_mydb_dbt_warehouse: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "connection_name": "list_mydb_dbt_warehouse"} */
select
      'mydb' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_warehouse'
    union all
    select
      'mydb' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_warehouse'
  
[0m12:16:46.532823 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.0 seconds
[0m12:16:46.535424 [debug] [ThreadPool]: On list_mydb_dbt_warehouse: ROLLBACK
[0m12:16:46.538085 [debug] [ThreadPool]: On list_mydb_dbt_warehouse: Close
[0m12:16:46.554372 [debug] [MainThread]: Using postgres connection "master"
[0m12:16:46.555292 [debug] [MainThread]: On master: BEGIN
[0m12:16:46.555795 [debug] [MainThread]: Opening a new connection, currently in state init
[0m12:16:46.585704 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m12:16:46.586552 [debug] [MainThread]: Using postgres connection "master"
[0m12:16:46.587426 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m12:16:46.618503 [debug] [MainThread]: SQL status: SELECT 5 in 0.0 seconds
[0m12:16:46.621620 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1775c36f-d78d-46c0-9a39-b6bbfc9c75a7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106cd27c0>]}
[0m12:16:46.622705 [debug] [MainThread]: On master: ROLLBACK
[0m12:16:46.625380 [debug] [MainThread]: Using postgres connection "master"
[0m12:16:46.626423 [debug] [MainThread]: On master: BEGIN
[0m12:16:46.630729 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m12:16:46.631578 [debug] [MainThread]: On master: COMMIT
[0m12:16:46.632534 [debug] [MainThread]: Using postgres connection "master"
[0m12:16:46.633428 [debug] [MainThread]: On master: COMMIT
[0m12:16:46.635362 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m12:16:46.636267 [debug] [MainThread]: On master: Close
[0m12:16:46.637692 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m12:16:46.639305 [info ] [MainThread]: 
[0m12:16:46.651115 [debug] [Thread-1  ]: Began running node model.maker_warehouse.avg_duration_year_month
[0m12:16:46.651843 [debug] [Thread-2  ]: Began running node model.maker_warehouse.avg_viewing_time
[0m12:16:46.652551 [debug] [Thread-3  ]: Began running node model.maker_warehouse.movies
[0m12:16:46.653385 [debug] [Thread-4  ]: Began running node model.maker_warehouse.no_of_viewings
[0m12:16:46.654274 [info ] [Thread-1  ]: 1 of 10 START sql view model dbt_warehouse.avg_duration_year_month ............. [RUN]
[0m12:16:46.655668 [info ] [Thread-2  ]: 2 of 10 START sql table model dbt_warehouse.avg_viewing_time ................... [RUN]
[0m12:16:46.656770 [info ] [Thread-3  ]: 3 of 10 START sql table model dbt_warehouse.movies ............................. [RUN]
[0m12:16:46.658069 [info ] [Thread-4  ]: 4 of 10 START sql table model dbt_warehouse.no_of_viewings ..................... [RUN]
[0m12:16:46.659944 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_mydb_dbt_warehouse, now model.maker_warehouse.avg_duration_year_month)
[0m12:16:46.662015 [debug] [Thread-2  ]: Acquiring new postgres connection 'model.maker_warehouse.avg_viewing_time'
[0m12:16:46.665361 [debug] [Thread-3  ]: Acquiring new postgres connection 'model.maker_warehouse.movies'
[0m12:16:46.667554 [debug] [Thread-4  ]: Acquiring new postgres connection 'model.maker_warehouse.no_of_viewings'
[0m12:16:46.668326 [debug] [Thread-1  ]: Began compiling node model.maker_warehouse.avg_duration_year_month
[0m12:16:46.668960 [debug] [Thread-2  ]: Began compiling node model.maker_warehouse.avg_viewing_time
[0m12:16:46.669575 [debug] [Thread-3  ]: Began compiling node model.maker_warehouse.movies
[0m12:16:46.670200 [debug] [Thread-4  ]: Began compiling node model.maker_warehouse.no_of_viewings
[0m12:16:46.692056 [debug] [Thread-2  ]: Writing injected SQL for node "model.maker_warehouse.avg_viewing_time"
[0m12:16:46.698057 [debug] [Thread-1  ]: Writing injected SQL for node "model.maker_warehouse.avg_duration_year_month"
[0m12:16:46.713390 [debug] [Thread-3  ]: Writing injected SQL for node "model.maker_warehouse.movies"
[0m12:16:46.724855 [debug] [Thread-4  ]: Writing injected SQL for node "model.maker_warehouse.no_of_viewings"
[0m12:16:46.730267 [debug] [Thread-1  ]: Timing info for model.maker_warehouse.avg_duration_year_month (compile): 12:16:46.670687 => 12:16:46.727543
[0m12:16:46.732528 [debug] [Thread-2  ]: Timing info for model.maker_warehouse.avg_viewing_time (compile): 12:16:46.686044 => 12:16:46.731108
[0m12:16:46.733882 [debug] [Thread-1  ]: Began executing node model.maker_warehouse.avg_duration_year_month
[0m12:16:46.735114 [debug] [Thread-4  ]: Timing info for model.maker_warehouse.no_of_viewings (compile): 12:16:46.713986 => 12:16:46.734507
[0m12:16:46.736016 [debug] [Thread-3  ]: Timing info for model.maker_warehouse.movies (compile): 12:16:46.700512 => 12:16:46.735634
[0m12:16:46.736789 [debug] [Thread-2  ]: Began executing node model.maker_warehouse.avg_viewing_time
[0m12:16:46.762906 [debug] [Thread-4  ]: Began executing node model.maker_warehouse.no_of_viewings
[0m12:16:46.800871 [debug] [Thread-3  ]: Began executing node model.maker_warehouse.movies
[0m12:16:46.943114 [debug] [Thread-1  ]: Writing runtime sql for node "model.maker_warehouse.avg_duration_year_month"
[0m12:16:46.960169 [debug] [Thread-2  ]: Writing runtime sql for node "model.maker_warehouse.avg_viewing_time"
[0m12:16:46.963084 [debug] [Thread-4  ]: Writing runtime sql for node "model.maker_warehouse.no_of_viewings"
[0m12:16:46.970308 [debug] [Thread-3  ]: Writing runtime sql for node "model.maker_warehouse.movies"
[0m12:16:46.979834 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.avg_viewing_time"
[0m12:16:46.980725 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.movies"
[0m12:16:46.981420 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.no_of_viewings"
[0m12:16:46.982354 [debug] [Thread-2  ]: On model.maker_warehouse.avg_viewing_time: BEGIN
[0m12:16:46.983979 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.avg_duration_year_month"
[0m12:16:46.985186 [debug] [Thread-3  ]: On model.maker_warehouse.movies: BEGIN
[0m12:16:46.985837 [debug] [Thread-4  ]: On model.maker_warehouse.no_of_viewings: BEGIN
[0m12:16:46.986747 [debug] [Thread-2  ]: Opening a new connection, currently in state init
[0m12:16:46.987400 [debug] [Thread-1  ]: On model.maker_warehouse.avg_duration_year_month: BEGIN
[0m12:16:46.988283 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m12:16:46.988876 [debug] [Thread-4  ]: Opening a new connection, currently in state init
[0m12:16:46.989992 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m12:16:47.047882 [debug] [Thread-4  ]: SQL status: BEGIN in 0.0 seconds
[0m12:16:47.049165 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.no_of_viewings"
[0m12:16:47.050943 [debug] [Thread-4  ]: On model.maker_warehouse.no_of_viewings: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.no_of_viewings"} */

  
    

  create  table "mydb"."dbt_warehouse"."no_of_viewings__dbt_tmp"
  
  
    as
  
  (
    
SELECT
  title,
  COUNT(*) as total_views
FROM mydb.public.raw_netflix
GROUP BY title
ORDER BY total_views DESC
  );
  
[0m12:16:47.055779 [debug] [Thread-3  ]: SQL status: BEGIN in 0.0 seconds
[0m12:16:47.057625 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.movies"
[0m12:16:47.059296 [debug] [Thread-3  ]: On model.maker_warehouse.movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.movies"} */

  
    

  create  table "mydb"."dbt_warehouse"."movies__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    DISTINCT
    title,
    genres,
    release_date,
    movie_id
FROM mydb.public.raw_netflix
  );
  
[0m12:16:47.061030 [debug] [Thread-2  ]: SQL status: BEGIN in 0.0 seconds
[0m12:16:47.063181 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.avg_viewing_time"
[0m12:16:47.066298 [debug] [Thread-2  ]: On model.maker_warehouse.avg_viewing_time: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.avg_viewing_time"} */

  
    

  create  table "mydb"."dbt_warehouse"."avg_viewing_time__dbt_tmp"
  
  
    as
  
  (
    
SELECT
title,
ROUND(CAST(AVG(duration) AS NUMERIC), 2) as avg_duration
FROM mydb.public.raw_netflix
GROUP BY title
ORDER BY avg_duration DESC
  );
  
[0m12:16:47.078782 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
[0m12:16:47.079672 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.avg_duration_year_month"
[0m12:16:47.080757 [debug] [Thread-1  ]: On model.maker_warehouse.avg_duration_year_month: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.avg_duration_year_month"} */

  create view "mydb"."dbt_warehouse"."avg_duration_year_month__dbt_tmp"
    
    
  as (
    CREATE VIEW avg_viewing_time_year_month AS
SELECT
    EXTRACT(YEAR FROM CAST("datetime" AS DATE)) AS "Year",
    EXTRACT(MONTH FROM CAST("datetime" AS DATE)) AS "Month",
    ROUND(CAST(AVG(duration) AS NUMERIC), 2) AS "Average_Duration"
FROM
    mydb.public.raw_netflix
GROUP BY
    EXTRACT(YEAR FROM CAST("datetime" AS DATE)),
    EXTRACT(MONTH FROM CAST("datetime" AS DATE))
ORDER BY
    "Year", "Month"
  );
[0m12:16:47.087390 [debug] [Thread-1  ]: Postgres adapter: Postgres error: syntax error at or near "CREATE"
LINE 7:     CREATE VIEW avg_viewing_time_year_month AS
            ^

[0m12:16:47.089065 [debug] [Thread-1  ]: On model.maker_warehouse.avg_duration_year_month: ROLLBACK
[0m12:16:47.093574 [debug] [Thread-1  ]: Timing info for model.maker_warehouse.avg_duration_year_month (execute): 12:16:46.737337 => 12:16:47.092973
[0m12:16:47.094654 [debug] [Thread-1  ]: On model.maker_warehouse.avg_duration_year_month: Close
[0m12:16:47.109807 [debug] [Thread-1  ]: Database Error in model avg_duration_year_month (models/summary/avg_duration_year_month.sql)
  syntax error at or near "CREATE"
  LINE 7:     CREATE VIEW avg_viewing_time_year_month AS
              ^
  compiled Code at target/run/maker_warehouse/models/summary/avg_duration_year_month.sql
[0m12:16:47.110857 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1775c36f-d78d-46c0-9a39-b6bbfc9c75a7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e39eb0>]}
[0m12:16:47.112673 [error] [Thread-1  ]: 1 of 10 ERROR creating sql view model dbt_warehouse.avg_duration_year_month .... [[31mERROR[0m in 0.45s]
[0m12:16:47.114629 [debug] [Thread-1  ]: Finished running node model.maker_warehouse.avg_duration_year_month
[0m12:16:47.115692 [debug] [Thread-1  ]: Began running node model.maker_warehouse.total_duration_year_month
[0m12:16:47.116714 [info ] [Thread-1  ]: 5 of 10 START sql table model dbt_warehouse.total_duration_year_month .......... [RUN]
[0m12:16:47.118649 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.maker_warehouse.avg_duration_year_month, now model.maker_warehouse.total_duration_year_month)
[0m12:16:47.119914 [debug] [Thread-1  ]: Began compiling node model.maker_warehouse.total_duration_year_month
[0m12:16:47.130408 [debug] [Thread-1  ]: Writing injected SQL for node "model.maker_warehouse.total_duration_year_month"
[0m12:16:47.136656 [debug] [Thread-1  ]: Timing info for model.maker_warehouse.total_duration_year_month (compile): 12:16:47.120727 => 12:16:47.135969
[0m12:16:47.137997 [debug] [Thread-1  ]: Began executing node model.maker_warehouse.total_duration_year_month
[0m12:16:47.159206 [debug] [Thread-1  ]: Writing runtime sql for node "model.maker_warehouse.total_duration_year_month"
[0m12:16:47.160959 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.total_duration_year_month"
[0m12:16:47.162781 [debug] [Thread-1  ]: On model.maker_warehouse.total_duration_year_month: BEGIN
[0m12:16:47.165600 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m12:16:47.222149 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
[0m12:16:47.223353 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.total_duration_year_month"
[0m12:16:47.224551 [debug] [Thread-1  ]: On model.maker_warehouse.total_duration_year_month: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_duration_year_month"} */

  
    

  create  table "mydb"."dbt_warehouse"."total_duration_year_month__dbt_tmp"
  
  
    as
  
  (
    
CREATE VIEW total_viewing_time_year_month AS
SELECT
    EXTRACT(YEAR FROM CAST("datetime" AS DATE)) AS "Year",
    EXTRACT(MONTH FROM CAST("datetime" AS DATE)) AS "Month",
    SUM(duration) AS "Total_Duration"
FROM
    mydb.public.raw_netflix
GROUP BY
    EXTRACT(YEAR FROM CAST("datetime" AS DATE)),
    EXTRACT(MONTH FROM CAST("datetime" AS DATE))
ORDER BY
    "Year", "Month"
  );
  
[0m12:16:47.229807 [debug] [Thread-1  ]: Postgres adapter: Postgres error: syntax error at or near "CREATE"
LINE 13: CREATE VIEW total_viewing_time_year_month AS
         ^

[0m12:16:47.231791 [debug] [Thread-1  ]: On model.maker_warehouse.total_duration_year_month: ROLLBACK
[0m12:16:47.235333 [debug] [Thread-1  ]: Timing info for model.maker_warehouse.total_duration_year_month (execute): 12:16:47.138727 => 12:16:47.234702
[0m12:16:47.236435 [debug] [Thread-1  ]: On model.maker_warehouse.total_duration_year_month: Close
[0m12:16:47.241259 [debug] [Thread-1  ]: Database Error in model total_duration_year_month (models/summary/total_duration_year_month.sql)
  syntax error at or near "CREATE"
  LINE 13: CREATE VIEW total_viewing_time_year_month AS
           ^
  compiled Code at target/run/maker_warehouse/models/summary/total_duration_year_month.sql
[0m12:16:47.244539 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1775c36f-d78d-46c0-9a39-b6bbfc9c75a7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106da45e0>]}
[0m12:16:47.246531 [error] [Thread-1  ]: 5 of 10 ERROR creating sql table model dbt_warehouse.total_duration_year_month . [[31mERROR[0m in 0.13s]
[0m12:16:47.249287 [debug] [Thread-1  ]: Finished running node model.maker_warehouse.total_duration_year_month
[0m12:16:47.250564 [debug] [Thread-1  ]: Began running node model.maker_warehouse.total_unique_users
[0m12:16:47.252295 [info ] [Thread-1  ]: 6 of 10 START sql table model dbt_warehouse.total_unique_users ................. [RUN]
[0m12:16:47.254478 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.maker_warehouse.total_duration_year_month, now model.maker_warehouse.total_unique_users)
[0m12:16:47.255637 [debug] [Thread-1  ]: Began compiling node model.maker_warehouse.total_unique_users
[0m12:16:47.269488 [debug] [Thread-1  ]: Writing injected SQL for node "model.maker_warehouse.total_unique_users"
[0m12:16:47.271942 [debug] [Thread-1  ]: Timing info for model.maker_warehouse.total_unique_users (compile): 12:16:47.256691 => 12:16:47.271180
[0m12:16:47.272990 [debug] [Thread-1  ]: Began executing node model.maker_warehouse.total_unique_users
[0m12:16:47.296784 [debug] [Thread-1  ]: Writing runtime sql for node "model.maker_warehouse.total_unique_users"
[0m12:16:47.304008 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.total_unique_users"
[0m12:16:47.305322 [debug] [Thread-1  ]: On model.maker_warehouse.total_unique_users: BEGIN
[0m12:16:47.306263 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m12:16:47.471253 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
[0m12:16:47.474742 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.total_unique_users"
[0m12:16:47.475951 [debug] [Thread-1  ]: On model.maker_warehouse.total_unique_users: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_unique_users"} */

  
    

  create  table "mydb"."dbt_warehouse"."total_unique_users__dbt_tmp"
  
  
    as
  
  (
    
SELECT 
COUNT(DISTINCT(user_id)) AS total_unique_users
FROM mydb.public.raw_netflix
  );
  
[0m12:16:48.155102 [debug] [Thread-4  ]: SQL status: SELECT 7925 in 1.0 seconds
[0m12:16:48.173479 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.no_of_viewings"
[0m12:16:48.174732 [debug] [Thread-4  ]: On model.maker_warehouse.no_of_viewings: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.no_of_viewings"} */
alter table "mydb"."dbt_warehouse"."no_of_viewings" rename to "no_of_viewings__dbt_backup"
[0m12:16:48.179367 [debug] [Thread-4  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:16:48.187864 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.no_of_viewings"
[0m12:16:48.188528 [debug] [Thread-4  ]: On model.maker_warehouse.no_of_viewings: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.no_of_viewings"} */
alter table "mydb"."dbt_warehouse"."no_of_viewings__dbt_tmp" rename to "no_of_viewings"
[0m12:16:48.192072 [debug] [Thread-4  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:16:48.255626 [debug] [Thread-4  ]: On model.maker_warehouse.no_of_viewings: COMMIT
[0m12:16:48.256720 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.no_of_viewings"
[0m12:16:48.257936 [debug] [Thread-4  ]: On model.maker_warehouse.no_of_viewings: COMMIT
[0m12:16:48.267835 [debug] [Thread-4  ]: SQL status: COMMIT in 0.0 seconds
[0m12:16:48.286346 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.no_of_viewings"
[0m12:16:48.287361 [debug] [Thread-4  ]: On model.maker_warehouse.no_of_viewings: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.no_of_viewings"} */
drop table if exists "mydb"."dbt_warehouse"."no_of_viewings__dbt_backup" cascade
[0m12:16:48.301079 [debug] [Thread-4  ]: SQL status: DROP TABLE in 0.0 seconds
[0m12:16:48.304954 [debug] [Thread-4  ]: Timing info for model.maker_warehouse.no_of_viewings (execute): 12:16:46.842297 => 12:16:48.304372
[0m12:16:48.305833 [debug] [Thread-4  ]: On model.maker_warehouse.no_of_viewings: Close
[0m12:16:48.308026 [debug] [Thread-4  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1775c36f-d78d-46c0-9a39-b6bbfc9c75a7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106dc3a90>]}
[0m12:16:48.310173 [info ] [Thread-4  ]: 4 of 10 OK created sql table model dbt_warehouse.no_of_viewings ................ [[32mSELECT 7925[0m in 1.64s]
[0m12:16:48.312826 [debug] [Thread-4  ]: Finished running node model.maker_warehouse.no_of_viewings
[0m12:16:48.313790 [debug] [Thread-4  ]: Began running node model.maker_warehouse.total_viewing_time
[0m12:16:48.315027 [info ] [Thread-4  ]: 7 of 10 START sql table model dbt_warehouse.total_viewing_time ................. [RUN]
[0m12:16:48.316853 [debug] [Thread-4  ]: Re-using an available connection from the pool (formerly model.maker_warehouse.no_of_viewings, now model.maker_warehouse.total_viewing_time)
[0m12:16:48.318109 [debug] [Thread-4  ]: Began compiling node model.maker_warehouse.total_viewing_time
[0m12:16:48.328467 [debug] [Thread-4  ]: Writing injected SQL for node "model.maker_warehouse.total_viewing_time"
[0m12:16:48.331363 [debug] [Thread-4  ]: Timing info for model.maker_warehouse.total_viewing_time (compile): 12:16:48.318859 => 12:16:48.330734
[0m12:16:48.332364 [debug] [Thread-4  ]: Began executing node model.maker_warehouse.total_viewing_time
[0m12:16:48.352043 [debug] [Thread-4  ]: Writing runtime sql for node "model.maker_warehouse.total_viewing_time"
[0m12:16:48.353937 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.total_viewing_time"
[0m12:16:48.354904 [debug] [Thread-4  ]: On model.maker_warehouse.total_viewing_time: BEGIN
[0m12:16:48.355861 [debug] [Thread-4  ]: Opening a new connection, currently in state closed
[0m12:16:48.406054 [debug] [Thread-2  ]: SQL status: SELECT 7925 in 1.0 seconds
[0m12:16:48.415508 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.avg_viewing_time"
[0m12:16:48.416684 [debug] [Thread-2  ]: On model.maker_warehouse.avg_viewing_time: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.avg_viewing_time"} */
alter table "mydb"."dbt_warehouse"."avg_viewing_time" rename to "avg_viewing_time__dbt_backup"
[0m12:16:48.425070 [debug] [Thread-2  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:16:48.435086 [debug] [Thread-4  ]: SQL status: BEGIN in 0.0 seconds
[0m12:16:48.437055 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.total_viewing_time"
[0m12:16:48.438993 [debug] [Thread-4  ]: On model.maker_warehouse.total_viewing_time: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_viewing_time"} */

  
    

  create  table "mydb"."dbt_warehouse"."total_viewing_time__dbt_tmp"
  
  
    as
  
  (
    
SELECT
title,
SUM(duration) as total_duration
FROM mydb.public.raw_netflix
GROUP BY title
ORDER BY total_duration DESC
  );
  
[0m12:16:48.441573 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.avg_viewing_time"
[0m12:16:48.442883 [debug] [Thread-2  ]: On model.maker_warehouse.avg_viewing_time: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.avg_viewing_time"} */
alter table "mydb"."dbt_warehouse"."avg_viewing_time__dbt_tmp" rename to "avg_viewing_time"
[0m12:16:48.451907 [debug] [Thread-2  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:16:48.457892 [debug] [Thread-2  ]: On model.maker_warehouse.avg_viewing_time: COMMIT
[0m12:16:48.459157 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.avg_viewing_time"
[0m12:16:48.460300 [debug] [Thread-2  ]: On model.maker_warehouse.avg_viewing_time: COMMIT
[0m12:16:48.467970 [debug] [Thread-2  ]: SQL status: COMMIT in 0.0 seconds
[0m12:16:48.477300 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.avg_viewing_time"
[0m12:16:48.478280 [debug] [Thread-2  ]: On model.maker_warehouse.avg_viewing_time: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.avg_viewing_time"} */
drop table if exists "mydb"."dbt_warehouse"."avg_viewing_time__dbt_backup" cascade
[0m12:16:48.497080 [debug] [Thread-2  ]: SQL status: DROP TABLE in 0.0 seconds
[0m12:16:48.500417 [debug] [Thread-2  ]: Timing info for model.maker_warehouse.avg_viewing_time (execute): 12:16:46.801576 => 12:16:48.499690
[0m12:16:48.501648 [debug] [Thread-2  ]: On model.maker_warehouse.avg_viewing_time: Close
[0m12:16:48.505065 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1775c36f-d78d-46c0-9a39-b6bbfc9c75a7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e67b50>]}
[0m12:16:48.506901 [info ] [Thread-2  ]: 2 of 10 OK created sql table model dbt_warehouse.avg_viewing_time .............. [[32mSELECT 7925[0m in 1.84s]
[0m12:16:48.509577 [debug] [Thread-2  ]: Finished running node model.maker_warehouse.avg_viewing_time
[0m12:16:48.511247 [debug] [Thread-2  ]: Began running node model.maker_warehouse.total_viewings_year_month
[0m12:16:48.512537 [info ] [Thread-2  ]: 8 of 10 START sql table model dbt_warehouse.total_viewings_year_month .......... [RUN]
[0m12:16:48.515001 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly model.maker_warehouse.avg_viewing_time, now model.maker_warehouse.total_viewings_year_month)
[0m12:16:48.516185 [debug] [Thread-2  ]: Began compiling node model.maker_warehouse.total_viewings_year_month
[0m12:16:48.524519 [debug] [Thread-2  ]: Writing injected SQL for node "model.maker_warehouse.total_viewings_year_month"
[0m12:16:48.526800 [debug] [Thread-2  ]: Timing info for model.maker_warehouse.total_viewings_year_month (compile): 12:16:48.516907 => 12:16:48.526087
[0m12:16:48.528459 [debug] [Thread-2  ]: Began executing node model.maker_warehouse.total_viewings_year_month
[0m12:16:48.539722 [debug] [Thread-2  ]: Writing runtime sql for node "model.maker_warehouse.total_viewings_year_month"
[0m12:16:48.541780 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.total_viewings_year_month"
[0m12:16:48.543378 [debug] [Thread-2  ]: On model.maker_warehouse.total_viewings_year_month: BEGIN
[0m12:16:48.544407 [debug] [Thread-2  ]: Opening a new connection, currently in state closed
[0m12:16:48.595884 [debug] [Thread-2  ]: SQL status: BEGIN in 0.0 seconds
[0m12:16:48.597235 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.total_viewings_year_month"
[0m12:16:48.600695 [debug] [Thread-2  ]: On model.maker_warehouse.total_viewings_year_month: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_viewings_year_month"} */

  
    

  create  table "mydb"."dbt_warehouse"."total_viewings_year_month__dbt_tmp"
  
  
    as
  
  (
    
CREATE VIEW total_viewings_year_month AS
SELECT
    EXTRACT(YEAR FROM CAST("datetime" AS DATE)) AS "Year",
    EXTRACT(MONTH FROM CAST("datetime" AS DATE)) AS "Month",
    COUNT(*) AS "Total_Views"
FROM mydb.public.raw_netflix
GROUP BY
    EXTRACT(YEAR FROM CAST("datetime" AS DATE)),
    EXTRACT(MONTH FROM CAST("datetime" AS DATE))
ORDER BY
    "Year", "Month"
  );
  
[0m12:16:48.606335 [debug] [Thread-2  ]: Postgres adapter: Postgres error: syntax error at or near "CREATE"
LINE 13: CREATE VIEW total_viewings_year_month AS
         ^

[0m12:16:48.607896 [debug] [Thread-2  ]: On model.maker_warehouse.total_viewings_year_month: ROLLBACK
[0m12:16:48.612643 [debug] [Thread-2  ]: Timing info for model.maker_warehouse.total_viewings_year_month (execute): 12:16:48.529203 => 12:16:48.611817
[0m12:16:48.613913 [debug] [Thread-2  ]: On model.maker_warehouse.total_viewings_year_month: Close
[0m12:16:48.617633 [debug] [Thread-2  ]: Database Error in model total_viewings_year_month (models/summary/total_viewings_year_month.sql)
  syntax error at or near "CREATE"
  LINE 13: CREATE VIEW total_viewings_year_month AS
           ^
  compiled Code at target/run/maker_warehouse/models/summary/total_viewings_year_month.sql
[0m12:16:48.618562 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1775c36f-d78d-46c0-9a39-b6bbfc9c75a7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106dd10d0>]}
[0m12:16:48.619785 [error] [Thread-2  ]: 8 of 10 ERROR creating sql table model dbt_warehouse.total_viewings_year_month . [[31mERROR[0m in 0.10s]
[0m12:16:48.621834 [debug] [Thread-2  ]: Finished running node model.maker_warehouse.total_viewings_year_month
[0m12:16:48.623126 [debug] [Thread-2  ]: Began running node model.maker_warehouse.user_engagement
[0m12:16:48.624531 [info ] [Thread-2  ]: 9 of 10 START sql table model dbt_warehouse.user_engagement .................... [RUN]
[0m12:16:48.628286 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly model.maker_warehouse.total_viewings_year_month, now model.maker_warehouse.user_engagement)
[0m12:16:48.629219 [debug] [Thread-2  ]: Began compiling node model.maker_warehouse.user_engagement
[0m12:16:48.637336 [debug] [Thread-2  ]: Writing injected SQL for node "model.maker_warehouse.user_engagement"
[0m12:16:48.639641 [debug] [Thread-2  ]: Timing info for model.maker_warehouse.user_engagement (compile): 12:16:48.629734 => 12:16:48.639042
[0m12:16:48.640615 [debug] [Thread-2  ]: Began executing node model.maker_warehouse.user_engagement
[0m12:16:48.659298 [debug] [Thread-2  ]: Writing runtime sql for node "model.maker_warehouse.user_engagement"
[0m12:16:48.661328 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.user_engagement"
[0m12:16:48.662722 [debug] [Thread-2  ]: On model.maker_warehouse.user_engagement: BEGIN
[0m12:16:48.663805 [debug] [Thread-2  ]: Opening a new connection, currently in state closed
[0m12:16:48.738240 [debug] [Thread-2  ]: SQL status: BEGIN in 0.0 seconds
[0m12:16:48.739101 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.user_engagement"
[0m12:16:48.740166 [debug] [Thread-2  ]: On model.maker_warehouse.user_engagement: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.user_engagement"} */

  
    

  create  table "mydb"."dbt_warehouse"."user_engagement__dbt_tmp"
  
  
    as
  
  (
    
SELECT 
DISTINCT(user_id),
COUNT(DISTINCT(title)) AS total_titles,
SUM(duration) AS total_duration
FROM mydb.public.raw_netflix
GROUP BY user_id
  );
  
[0m12:16:49.295436 [debug] [Thread-4  ]: SQL status: SELECT 7925 in 1.0 seconds
[0m12:16:49.304709 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.total_viewing_time"
[0m12:16:49.305942 [debug] [Thread-4  ]: On model.maker_warehouse.total_viewing_time: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_viewing_time"} */
alter table "mydb"."dbt_warehouse"."total_viewing_time" rename to "total_viewing_time__dbt_backup"
[0m12:16:49.309603 [debug] [Thread-4  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:16:49.318484 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.total_viewing_time"
[0m12:16:49.319478 [debug] [Thread-4  ]: On model.maker_warehouse.total_viewing_time: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_viewing_time"} */
alter table "mydb"."dbt_warehouse"."total_viewing_time__dbt_tmp" rename to "total_viewing_time"
[0m12:16:49.322984 [debug] [Thread-4  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:16:49.329554 [debug] [Thread-4  ]: On model.maker_warehouse.total_viewing_time: COMMIT
[0m12:16:49.331057 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.total_viewing_time"
[0m12:16:49.332004 [debug] [Thread-4  ]: On model.maker_warehouse.total_viewing_time: COMMIT
[0m12:16:49.338586 [debug] [Thread-4  ]: SQL status: COMMIT in 0.0 seconds
[0m12:16:49.347278 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.total_viewing_time"
[0m12:16:49.348366 [debug] [Thread-4  ]: On model.maker_warehouse.total_viewing_time: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_viewing_time"} */
drop table if exists "mydb"."dbt_warehouse"."total_viewing_time__dbt_backup" cascade
[0m12:16:49.356614 [debug] [Thread-4  ]: SQL status: DROP TABLE in 0.0 seconds
[0m12:16:49.361339 [debug] [Thread-4  ]: Timing info for model.maker_warehouse.total_viewing_time (execute): 12:16:48.333033 => 12:16:49.360736
[0m12:16:49.363034 [debug] [Thread-4  ]: On model.maker_warehouse.total_viewing_time: Close
[0m12:16:49.365770 [debug] [Thread-4  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1775c36f-d78d-46c0-9a39-b6bbfc9c75a7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e42af0>]}
[0m12:16:49.367589 [info ] [Thread-4  ]: 7 of 10 OK created sql table model dbt_warehouse.total_viewing_time ............ [[32mSELECT 7925[0m in 1.05s]
[0m12:16:49.369549 [debug] [Thread-4  ]: Finished running node model.maker_warehouse.total_viewing_time
[0m12:16:49.949459 [debug] [Thread-3  ]: SQL status: SELECT 8472 in 3.0 seconds
[0m12:16:49.956496 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.movies"
[0m12:16:49.957292 [debug] [Thread-3  ]: On model.maker_warehouse.movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.movies"} */
alter table "mydb"."dbt_warehouse"."movies" rename to "movies__dbt_backup"
[0m12:16:49.961754 [debug] [Thread-3  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:16:49.971237 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.movies"
[0m12:16:49.972689 [debug] [Thread-3  ]: On model.maker_warehouse.movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.movies"} */
alter table "mydb"."dbt_warehouse"."movies__dbt_tmp" rename to "movies"
[0m12:16:49.977859 [debug] [Thread-3  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:16:49.985474 [debug] [Thread-3  ]: On model.maker_warehouse.movies: COMMIT
[0m12:16:49.986256 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.movies"
[0m12:16:49.986887 [debug] [Thread-3  ]: On model.maker_warehouse.movies: COMMIT
[0m12:16:49.991119 [debug] [Thread-3  ]: SQL status: COMMIT in 0.0 seconds
[0m12:16:49.997361 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.movies"
[0m12:16:49.998881 [debug] [Thread-3  ]: On model.maker_warehouse.movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.movies"} */
drop table if exists "mydb"."dbt_warehouse"."movies__dbt_backup" cascade
[0m12:16:50.015963 [debug] [Thread-3  ]: SQL status: DROP TABLE in 0.0 seconds
[0m12:16:50.019486 [debug] [Thread-3  ]: Timing info for model.maker_warehouse.movies (execute): 12:16:46.885374 => 12:16:50.019070
[0m12:16:50.020751 [debug] [Thread-3  ]: On model.maker_warehouse.movies: Close
[0m12:16:50.023840 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1775c36f-d78d-46c0-9a39-b6bbfc9c75a7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106dafd60>]}
[0m12:16:50.025694 [info ] [Thread-3  ]: 3 of 10 OK created sql table model dbt_warehouse.movies ........................ [[32mSELECT 8472[0m in 3.36s]
[0m12:16:50.028603 [debug] [Thread-3  ]: Finished running node model.maker_warehouse.movies
[0m12:16:50.030192 [debug] [Thread-4  ]: Began running node model.maker_warehouse.all_movies
[0m12:16:50.031563 [info ] [Thread-4  ]: 10 of 10 START sql table model dbt_warehouse.all_movies ........................ [RUN]
[0m12:16:50.033589 [debug] [Thread-4  ]: Re-using an available connection from the pool (formerly model.maker_warehouse.total_viewing_time, now model.maker_warehouse.all_movies)
[0m12:16:50.035460 [debug] [Thread-4  ]: Began compiling node model.maker_warehouse.all_movies
[0m12:16:50.044489 [debug] [Thread-4  ]: Writing injected SQL for node "model.maker_warehouse.all_movies"
[0m12:16:50.049802 [debug] [Thread-4  ]: Timing info for model.maker_warehouse.all_movies (compile): 12:16:50.036295 => 12:16:50.048852
[0m12:16:50.051001 [debug] [Thread-4  ]: Began executing node model.maker_warehouse.all_movies
[0m12:16:50.067768 [debug] [Thread-4  ]: Writing runtime sql for node "model.maker_warehouse.all_movies"
[0m12:16:50.069565 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.all_movies"
[0m12:16:50.070449 [debug] [Thread-4  ]: On model.maker_warehouse.all_movies: BEGIN
[0m12:16:50.071258 [debug] [Thread-4  ]: Opening a new connection, currently in state closed
[0m12:16:50.122617 [debug] [Thread-4  ]: SQL status: BEGIN in 0.0 seconds
[0m12:16:50.124220 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.all_movies"
[0m12:16:50.125331 [debug] [Thread-4  ]: On model.maker_warehouse.all_movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.all_movies"} */

  
    

  create  table "mydb"."dbt_warehouse"."all_movies__dbt_tmp"
  
  
    as
  
  (
    
  
SELECT
*
FROM "mydb"."dbt_warehouse"."movies"
  );
  
[0m12:16:50.174157 [debug] [Thread-4  ]: SQL status: SELECT 8472 in 0.0 seconds
[0m12:16:50.185344 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.all_movies"
[0m12:16:50.186423 [debug] [Thread-4  ]: On model.maker_warehouse.all_movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.all_movies"} */
alter table "mydb"."dbt_warehouse"."all_movies" rename to "all_movies__dbt_backup"
[0m12:16:50.190335 [debug] [Thread-4  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:16:50.198888 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.all_movies"
[0m12:16:50.200191 [debug] [Thread-4  ]: On model.maker_warehouse.all_movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.all_movies"} */
alter table "mydb"."dbt_warehouse"."all_movies__dbt_tmp" rename to "all_movies"
[0m12:16:50.203460 [debug] [Thread-4  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:16:50.210276 [debug] [Thread-4  ]: On model.maker_warehouse.all_movies: COMMIT
[0m12:16:50.211115 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.all_movies"
[0m12:16:50.211948 [debug] [Thread-4  ]: On model.maker_warehouse.all_movies: COMMIT
[0m12:16:50.215583 [debug] [Thread-4  ]: SQL status: COMMIT in 0.0 seconds
[0m12:16:50.222587 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.all_movies"
[0m12:16:50.223862 [debug] [Thread-4  ]: On model.maker_warehouse.all_movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.all_movies"} */
drop table if exists "mydb"."dbt_warehouse"."all_movies__dbt_backup" cascade
[0m12:16:50.237923 [debug] [Thread-4  ]: SQL status: DROP TABLE in 0.0 seconds
[0m12:16:50.242280 [debug] [Thread-4  ]: Timing info for model.maker_warehouse.all_movies (execute): 12:16:50.051761 => 12:16:50.241328
[0m12:16:50.243905 [debug] [Thread-4  ]: On model.maker_warehouse.all_movies: Close
[0m12:16:50.245828 [debug] [Thread-4  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1775c36f-d78d-46c0-9a39-b6bbfc9c75a7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106f59130>]}
[0m12:16:50.247156 [info ] [Thread-4  ]: 10 of 10 OK created sql table model dbt_warehouse.all_movies ................... [[32mSELECT 8472[0m in 0.21s]
[0m12:16:50.250011 [debug] [Thread-4  ]: Finished running node model.maker_warehouse.all_movies
[0m12:16:51.838814 [debug] [Thread-1  ]: SQL status: SELECT 1 in 4.0 seconds
[0m12:16:51.847286 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.total_unique_users"
[0m12:16:51.848557 [debug] [Thread-1  ]: On model.maker_warehouse.total_unique_users: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_unique_users"} */
alter table "mydb"."dbt_warehouse"."total_unique_users" rename to "total_unique_users__dbt_backup"
[0m12:16:51.853592 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:16:51.861180 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.total_unique_users"
[0m12:16:51.862617 [debug] [Thread-1  ]: On model.maker_warehouse.total_unique_users: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_unique_users"} */
alter table "mydb"."dbt_warehouse"."total_unique_users__dbt_tmp" rename to "total_unique_users"
[0m12:16:51.869291 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:16:51.873764 [debug] [Thread-1  ]: On model.maker_warehouse.total_unique_users: COMMIT
[0m12:16:51.874478 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.total_unique_users"
[0m12:16:51.875178 [debug] [Thread-1  ]: On model.maker_warehouse.total_unique_users: COMMIT
[0m12:16:51.879850 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
[0m12:16:51.887095 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.total_unique_users"
[0m12:16:51.887821 [debug] [Thread-1  ]: On model.maker_warehouse.total_unique_users: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_unique_users"} */
drop table if exists "mydb"."dbt_warehouse"."total_unique_users__dbt_backup" cascade
[0m12:16:51.893922 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
[0m12:16:51.896621 [debug] [Thread-1  ]: Timing info for model.maker_warehouse.total_unique_users (execute): 12:16:47.274602 => 12:16:51.896300
[0m12:16:51.897247 [debug] [Thread-1  ]: On model.maker_warehouse.total_unique_users: Close
[0m12:16:51.899460 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1775c36f-d78d-46c0-9a39-b6bbfc9c75a7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106f107f0>]}
[0m12:16:51.900592 [info ] [Thread-1  ]: 6 of 10 OK created sql table model dbt_warehouse.total_unique_users ............ [[32mSELECT 1[0m in 4.65s]
[0m12:16:51.901788 [debug] [Thread-1  ]: Finished running node model.maker_warehouse.total_unique_users
[0m12:16:54.348478 [debug] [Thread-2  ]: SQL status: SELECT 161918 in 6.0 seconds
[0m12:16:54.355756 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.user_engagement"
[0m12:16:54.356409 [debug] [Thread-2  ]: On model.maker_warehouse.user_engagement: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.user_engagement"} */
alter table "mydb"."dbt_warehouse"."user_engagement" rename to "user_engagement__dbt_backup"
[0m12:16:54.359928 [debug] [Thread-2  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:16:54.367125 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.user_engagement"
[0m12:16:54.367981 [debug] [Thread-2  ]: On model.maker_warehouse.user_engagement: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.user_engagement"} */
alter table "mydb"."dbt_warehouse"."user_engagement__dbt_tmp" rename to "user_engagement"
[0m12:16:54.371104 [debug] [Thread-2  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:16:54.376281 [debug] [Thread-2  ]: On model.maker_warehouse.user_engagement: COMMIT
[0m12:16:54.376933 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.user_engagement"
[0m12:16:54.377661 [debug] [Thread-2  ]: On model.maker_warehouse.user_engagement: COMMIT
[0m12:16:54.390816 [debug] [Thread-2  ]: SQL status: COMMIT in 0.0 seconds
[0m12:16:54.395301 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.user_engagement"
[0m12:16:54.396087 [debug] [Thread-2  ]: On model.maker_warehouse.user_engagement: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.user_engagement"} */
drop table if exists "mydb"."dbt_warehouse"."user_engagement__dbt_backup" cascade
[0m12:16:54.419391 [debug] [Thread-2  ]: SQL status: DROP TABLE in 0.0 seconds
[0m12:16:54.421940 [debug] [Thread-2  ]: Timing info for model.maker_warehouse.user_engagement (execute): 12:16:48.641375 => 12:16:54.421625
[0m12:16:54.422740 [debug] [Thread-2  ]: On model.maker_warehouse.user_engagement: Close
[0m12:16:54.425500 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1775c36f-d78d-46c0-9a39-b6bbfc9c75a7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106c0a7c0>]}
[0m12:16:54.427150 [info ] [Thread-2  ]: 9 of 10 OK created sql table model dbt_warehouse.user_engagement ............... [[32mSELECT 161918[0m in 5.80s]
[0m12:16:54.430115 [debug] [Thread-2  ]: Finished running node model.maker_warehouse.user_engagement
[0m12:16:54.434827 [debug] [MainThread]: Using postgres connection "master"
[0m12:16:54.435888 [debug] [MainThread]: On master: BEGIN
[0m12:16:54.437110 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m12:16:54.484696 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m12:16:54.485959 [debug] [MainThread]: On master: COMMIT
[0m12:16:54.486786 [debug] [MainThread]: Using postgres connection "master"
[0m12:16:54.487484 [debug] [MainThread]: On master: COMMIT
[0m12:16:54.490144 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m12:16:54.491014 [debug] [MainThread]: On master: Close
[0m12:16:54.492860 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:16:54.494523 [debug] [MainThread]: Connection 'model.maker_warehouse.total_unique_users' was properly closed.
[0m12:16:54.497306 [debug] [MainThread]: Connection 'model.maker_warehouse.user_engagement' was properly closed.
[0m12:16:54.498704 [debug] [MainThread]: Connection 'model.maker_warehouse.movies' was properly closed.
[0m12:16:54.499686 [debug] [MainThread]: Connection 'model.maker_warehouse.all_movies' was properly closed.
[0m12:16:54.500662 [info ] [MainThread]: 
[0m12:16:54.501653 [info ] [MainThread]: Finished running 1 view model, 9 table models in 0 hours 0 minutes and 8.29 seconds (8.29s).
[0m12:16:54.506524 [debug] [MainThread]: Command end result
[0m12:16:54.519739 [info ] [MainThread]: 
[0m12:16:54.520537 [info ] [MainThread]: [31mCompleted with 3 errors and 0 warnings:[0m
[0m12:16:54.521221 [info ] [MainThread]: 
[0m12:16:54.522059 [error] [MainThread]: [33mDatabase Error in model avg_duration_year_month (models/summary/avg_duration_year_month.sql)[0m
[0m12:16:54.524764 [error] [MainThread]:   syntax error at or near "CREATE"
[0m12:16:54.525658 [error] [MainThread]:   LINE 7:     CREATE VIEW avg_viewing_time_year_month AS
[0m12:16:54.526264 [error] [MainThread]:               ^
[0m12:16:54.526842 [error] [MainThread]:   compiled Code at target/run/maker_warehouse/models/summary/avg_duration_year_month.sql
[0m12:16:54.527435 [info ] [MainThread]: 
[0m12:16:54.528321 [error] [MainThread]: [33mDatabase Error in model total_duration_year_month (models/summary/total_duration_year_month.sql)[0m
[0m12:16:54.529001 [error] [MainThread]:   syntax error at or near "CREATE"
[0m12:16:54.529649 [error] [MainThread]:   LINE 13: CREATE VIEW total_viewing_time_year_month AS
[0m12:16:54.530273 [error] [MainThread]:            ^
[0m12:16:54.530852 [error] [MainThread]:   compiled Code at target/run/maker_warehouse/models/summary/total_duration_year_month.sql
[0m12:16:54.532812 [info ] [MainThread]: 
[0m12:16:54.533770 [error] [MainThread]: [33mDatabase Error in model total_viewings_year_month (models/summary/total_viewings_year_month.sql)[0m
[0m12:16:54.534418 [error] [MainThread]:   syntax error at or near "CREATE"
[0m12:16:54.535097 [error] [MainThread]:   LINE 13: CREATE VIEW total_viewings_year_month AS
[0m12:16:54.535705 [error] [MainThread]:            ^
[0m12:16:54.536469 [error] [MainThread]:   compiled Code at target/run/maker_warehouse/models/summary/total_viewings_year_month.sql
[0m12:16:54.537164 [info ] [MainThread]: 
[0m12:16:54.538214 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=3 SKIP=0 TOTAL=10
[0m12:16:54.539435 [debug] [MainThread]: Command `dbt run` failed at 12:16:54.539250 after 9.07 seconds
[0m12:16:54.540125 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105442550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106a416d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1069b3400>]}
[0m12:16:54.541133 [debug] [MainThread]: Flushing usage events
[0m12:17:33.462985 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fc6a4f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1110052b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d7fd790>]}


============================== 12:17:33.474358 | 26337f95-5b8b-475d-ba49-efc6dc868b4e ==============================
[0m12:17:33.474358 [info ] [MainThread]: Running with dbt=1.5.4
[0m12:17:33.476299 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/Users/denisechan/Documents/Makers/Data_Engineering/Week_6/dbt_warehouse/logs', 'version_check': 'True', 'profiles_dir': '/Users/denisechan/Documents/Makers/Data_Engineering/Week_6/dbt_warehouse', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'log_format': 'default', 'target_path': 'None', 'send_anonymous_usage_stats': 'True'}
[0m12:17:33.671791 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '26337f95-5b8b-475d-ba49-efc6dc868b4e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111005a00>]}
[0m12:17:33.711579 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '26337f95-5b8b-475d-ba49-efc6dc868b4e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111269700>]}
[0m12:17:33.714463 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m12:17:33.763417 [debug] [MainThread]: checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, vars: {}, profile: , target: , version: 1.5.4
[0m12:17:33.950087 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m12:17:33.951020 [debug] [MainThread]: Partial parsing: updated file: maker_warehouse://models/summary/avg_duration_year_month.sql
[0m12:17:34.022253 [debug] [MainThread]: 1699: static parser successfully parsed summary/avg_duration_year_month.sql
[0m12:17:34.060078 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '26337f95-5b8b-475d-ba49-efc6dc868b4e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11153f0d0>]}
[0m12:17:34.079123 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '26337f95-5b8b-475d-ba49-efc6dc868b4e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11142edc0>]}
[0m12:17:34.079968 [info ] [MainThread]: Found 10 models, 0 tests, 0 snapshots, 0 analyses, 307 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics, 0 groups
[0m12:17:34.080862 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '26337f95-5b8b-475d-ba49-efc6dc868b4e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11142ed60>]}
[0m12:17:34.084213 [info ] [MainThread]: 
[0m12:17:34.085831 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m12:17:34.088027 [debug] [ThreadPool]: Acquiring new postgres connection 'list_mydb'
[0m12:17:34.114512 [debug] [ThreadPool]: Using postgres connection "list_mydb"
[0m12:17:34.115464 [debug] [ThreadPool]: On list_mydb: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "connection_name": "list_mydb"} */

    select distinct nspname from pg_namespace
  
[0m12:17:34.116012 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:17:34.282065 [debug] [ThreadPool]: SQL status: SELECT 5 in 0.0 seconds
[0m12:17:34.285960 [debug] [ThreadPool]: On list_mydb: Close
[0m12:17:34.290349 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_mydb, now list_mydb_dbt_warehouse)
[0m12:17:34.305186 [debug] [ThreadPool]: Using postgres connection "list_mydb_dbt_warehouse"
[0m12:17:34.305927 [debug] [ThreadPool]: On list_mydb_dbt_warehouse: BEGIN
[0m12:17:34.306438 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:17:34.335549 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m12:17:34.336498 [debug] [ThreadPool]: Using postgres connection "list_mydb_dbt_warehouse"
[0m12:17:34.337514 [debug] [ThreadPool]: On list_mydb_dbt_warehouse: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "connection_name": "list_mydb_dbt_warehouse"} */
select
      'mydb' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_warehouse'
    union all
    select
      'mydb' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_warehouse'
  
[0m12:17:34.353522 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.0 seconds
[0m12:17:34.355751 [debug] [ThreadPool]: On list_mydb_dbt_warehouse: ROLLBACK
[0m12:17:34.358247 [debug] [ThreadPool]: On list_mydb_dbt_warehouse: Close
[0m12:17:34.376654 [debug] [MainThread]: Using postgres connection "master"
[0m12:17:34.377689 [debug] [MainThread]: On master: BEGIN
[0m12:17:34.378354 [debug] [MainThread]: Opening a new connection, currently in state init
[0m12:17:34.405581 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m12:17:34.406499 [debug] [MainThread]: Using postgres connection "master"
[0m12:17:34.407300 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m12:17:34.464868 [debug] [MainThread]: SQL status: SELECT 5 in 0.0 seconds
[0m12:17:34.470272 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '26337f95-5b8b-475d-ba49-efc6dc868b4e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111557ac0>]}
[0m12:17:34.471210 [debug] [MainThread]: On master: ROLLBACK
[0m12:17:34.523179 [debug] [MainThread]: Using postgres connection "master"
[0m12:17:34.524547 [debug] [MainThread]: On master: BEGIN
[0m12:17:34.531962 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m12:17:34.532772 [debug] [MainThread]: On master: COMMIT
[0m12:17:34.533315 [debug] [MainThread]: Using postgres connection "master"
[0m12:17:34.533810 [debug] [MainThread]: On master: COMMIT
[0m12:17:34.556242 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m12:17:34.556905 [debug] [MainThread]: On master: Close
[0m12:17:34.558527 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m12:17:34.560406 [info ] [MainThread]: 
[0m12:17:34.571997 [debug] [Thread-1  ]: Began running node model.maker_warehouse.avg_duration_year_month
[0m12:17:34.572724 [debug] [Thread-2  ]: Began running node model.maker_warehouse.avg_viewing_time
[0m12:17:34.573585 [debug] [Thread-3  ]: Began running node model.maker_warehouse.movies
[0m12:17:34.574280 [debug] [Thread-4  ]: Began running node model.maker_warehouse.no_of_viewings
[0m12:17:34.575168 [info ] [Thread-1  ]: 1 of 10 START sql view model dbt_warehouse.avg_duration_year_month ............. [RUN]
[0m12:17:34.576331 [info ] [Thread-2  ]: 2 of 10 START sql table model dbt_warehouse.avg_viewing_time ................... [RUN]
[0m12:17:34.578008 [info ] [Thread-3  ]: 3 of 10 START sql table model dbt_warehouse.movies ............................. [RUN]
[0m12:17:34.581816 [info ] [Thread-4  ]: 4 of 10 START sql table model dbt_warehouse.no_of_viewings ..................... [RUN]
[0m12:17:34.584149 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_mydb_dbt_warehouse, now model.maker_warehouse.avg_duration_year_month)
[0m12:17:34.585761 [debug] [Thread-2  ]: Acquiring new postgres connection 'model.maker_warehouse.avg_viewing_time'
[0m12:17:34.587082 [debug] [Thread-3  ]: Acquiring new postgres connection 'model.maker_warehouse.movies'
[0m12:17:34.588532 [debug] [Thread-4  ]: Acquiring new postgres connection 'model.maker_warehouse.no_of_viewings'
[0m12:17:34.589935 [debug] [Thread-1  ]: Began compiling node model.maker_warehouse.avg_duration_year_month
[0m12:17:34.591297 [debug] [Thread-2  ]: Began compiling node model.maker_warehouse.avg_viewing_time
[0m12:17:34.592398 [debug] [Thread-3  ]: Began compiling node model.maker_warehouse.movies
[0m12:17:34.593606 [debug] [Thread-4  ]: Began compiling node model.maker_warehouse.no_of_viewings
[0m12:17:34.616792 [debug] [Thread-2  ]: Writing injected SQL for node "model.maker_warehouse.avg_viewing_time"
[0m12:17:34.618366 [debug] [Thread-1  ]: Writing injected SQL for node "model.maker_warehouse.avg_duration_year_month"
[0m12:17:34.628153 [debug] [Thread-3  ]: Writing injected SQL for node "model.maker_warehouse.movies"
[0m12:17:34.637877 [debug] [Thread-4  ]: Writing injected SQL for node "model.maker_warehouse.no_of_viewings"
[0m12:17:34.641422 [debug] [Thread-2  ]: Timing info for model.maker_warehouse.avg_viewing_time (compile): 12:17:34.612046 => 12:17:34.640952
[0m12:17:34.642111 [debug] [Thread-1  ]: Timing info for model.maker_warehouse.avg_duration_year_month (compile): 12:17:34.594262 => 12:17:34.641786
[0m12:17:34.642948 [debug] [Thread-3  ]: Timing info for model.maker_warehouse.movies (compile): 12:17:34.618926 => 12:17:34.642455
[0m12:17:34.644370 [debug] [Thread-2  ]: Began executing node model.maker_warehouse.avg_viewing_time
[0m12:17:34.646490 [debug] [Thread-1  ]: Began executing node model.maker_warehouse.avg_duration_year_month
[0m12:17:34.647361 [debug] [Thread-4  ]: Timing info for model.maker_warehouse.no_of_viewings (compile): 12:17:34.630869 => 12:17:34.646887
[0m12:17:34.648415 [debug] [Thread-3  ]: Began executing node model.maker_warehouse.movies
[0m12:17:34.732726 [debug] [Thread-4  ]: Began executing node model.maker_warehouse.no_of_viewings
[0m12:17:34.816647 [debug] [Thread-1  ]: Writing runtime sql for node "model.maker_warehouse.avg_duration_year_month"
[0m12:17:34.832980 [debug] [Thread-4  ]: Writing runtime sql for node "model.maker_warehouse.no_of_viewings"
[0m12:17:34.837848 [debug] [Thread-2  ]: Writing runtime sql for node "model.maker_warehouse.avg_viewing_time"
[0m12:17:34.841565 [debug] [Thread-3  ]: Writing runtime sql for node "model.maker_warehouse.movies"
[0m12:17:34.843613 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.avg_duration_year_month"
[0m12:17:34.845687 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.no_of_viewings"
[0m12:17:34.846732 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.avg_viewing_time"
[0m12:17:34.847547 [debug] [Thread-1  ]: On model.maker_warehouse.avg_duration_year_month: BEGIN
[0m12:17:34.848438 [debug] [Thread-4  ]: On model.maker_warehouse.no_of_viewings: BEGIN
[0m12:17:34.849197 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.movies"
[0m12:17:34.849952 [debug] [Thread-2  ]: On model.maker_warehouse.avg_viewing_time: BEGIN
[0m12:17:34.850558 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m12:17:34.851109 [debug] [Thread-4  ]: Opening a new connection, currently in state init
[0m12:17:34.851656 [debug] [Thread-3  ]: On model.maker_warehouse.movies: BEGIN
[0m12:17:34.852222 [debug] [Thread-2  ]: Opening a new connection, currently in state init
[0m12:17:34.854039 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m12:17:34.921401 [debug] [Thread-4  ]: SQL status: BEGIN in 0.0 seconds
[0m12:17:34.922936 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.no_of_viewings"
[0m12:17:34.924156 [debug] [Thread-4  ]: On model.maker_warehouse.no_of_viewings: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.no_of_viewings"} */

  
    

  create  table "mydb"."dbt_warehouse"."no_of_viewings__dbt_tmp"
  
  
    as
  
  (
    
SELECT
  title,
  COUNT(*) as total_views
FROM mydb.public.raw_netflix
GROUP BY title
ORDER BY total_views DESC
  );
  
[0m12:17:34.931281 [debug] [Thread-2  ]: SQL status: BEGIN in 0.0 seconds
[0m12:17:34.934993 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.avg_viewing_time"
[0m12:17:34.936871 [debug] [Thread-2  ]: On model.maker_warehouse.avg_viewing_time: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.avg_viewing_time"} */

  
    

  create  table "mydb"."dbt_warehouse"."avg_viewing_time__dbt_tmp"
  
  
    as
  
  (
    
SELECT
title,
ROUND(CAST(AVG(duration) AS NUMERIC), 2) as avg_duration
FROM mydb.public.raw_netflix
GROUP BY title
ORDER BY avg_duration DESC
  );
  
[0m12:17:34.941592 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
[0m12:17:34.942509 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.avg_duration_year_month"
[0m12:17:34.943813 [debug] [Thread-1  ]: On model.maker_warehouse.avg_duration_year_month: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.avg_duration_year_month"} */

  create view "mydb"."dbt_warehouse"."avg_duration_year_month__dbt_tmp"
    
    
  as (
    
SELECT
    EXTRACT(YEAR FROM CAST("datetime" AS DATE)) AS "Year",
    EXTRACT(MONTH FROM CAST("datetime" AS DATE)) AS "Month",
    ROUND(CAST(AVG(duration) AS NUMERIC), 2) AS "Average_Duration"
FROM
    mydb.public.raw_netflix
GROUP BY
    EXTRACT(YEAR FROM CAST("datetime" AS DATE)),
    EXTRACT(MONTH FROM CAST("datetime" AS DATE))
ORDER BY
    "Year", "Month"
  );
[0m12:17:34.955261 [debug] [Thread-3  ]: SQL status: BEGIN in 0.0 seconds
[0m12:17:34.956347 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.movies"
[0m12:17:34.957403 [debug] [Thread-3  ]: On model.maker_warehouse.movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.movies"} */

  
    

  create  table "mydb"."dbt_warehouse"."movies__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    DISTINCT
    title,
    genres,
    release_date,
    movie_id
FROM mydb.public.raw_netflix
  );
  
[0m12:17:35.019207 [debug] [Thread-1  ]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:17:35.040168 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.avg_duration_year_month"
[0m12:17:35.041493 [debug] [Thread-1  ]: On model.maker_warehouse.avg_duration_year_month: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.avg_duration_year_month"} */
alter table "mydb"."dbt_warehouse"."avg_duration_year_month__dbt_tmp" rename to "avg_duration_year_month"
[0m12:17:35.049781 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:17:35.112958 [debug] [Thread-1  ]: On model.maker_warehouse.avg_duration_year_month: COMMIT
[0m12:17:35.114707 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.avg_duration_year_month"
[0m12:17:35.116147 [debug] [Thread-1  ]: On model.maker_warehouse.avg_duration_year_month: COMMIT
[0m12:17:35.120047 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
[0m12:17:35.137590 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.avg_duration_year_month"
[0m12:17:35.138930 [debug] [Thread-1  ]: On model.maker_warehouse.avg_duration_year_month: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.avg_duration_year_month"} */
drop view if exists "mydb"."dbt_warehouse"."avg_duration_year_month__dbt_backup" cascade
[0m12:17:35.142323 [debug] [Thread-1  ]: SQL status: DROP VIEW in 0.0 seconds
[0m12:17:35.147081 [debug] [Thread-1  ]: Timing info for model.maker_warehouse.avg_duration_year_month (execute): 12:17:34.673755 => 12:17:35.146562
[0m12:17:35.148626 [debug] [Thread-1  ]: On model.maker_warehouse.avg_duration_year_month: Close
[0m12:17:35.151236 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '26337f95-5b8b-475d-ba49-efc6dc868b4e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111689c40>]}
[0m12:17:35.152813 [info ] [Thread-1  ]: 1 of 10 OK created sql view model dbt_warehouse.avg_duration_year_month ........ [[32mCREATE VIEW[0m in 0.57s]
[0m12:17:35.155764 [debug] [Thread-1  ]: Finished running node model.maker_warehouse.avg_duration_year_month
[0m12:17:35.156924 [debug] [Thread-1  ]: Began running node model.maker_warehouse.total_duration_year_month
[0m12:17:35.158369 [info ] [Thread-1  ]: 5 of 10 START sql table model dbt_warehouse.total_duration_year_month .......... [RUN]
[0m12:17:35.160883 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.maker_warehouse.avg_duration_year_month, now model.maker_warehouse.total_duration_year_month)
[0m12:17:35.162317 [debug] [Thread-1  ]: Began compiling node model.maker_warehouse.total_duration_year_month
[0m12:17:35.173464 [debug] [Thread-1  ]: Writing injected SQL for node "model.maker_warehouse.total_duration_year_month"
[0m12:17:35.179068 [debug] [Thread-1  ]: Timing info for model.maker_warehouse.total_duration_year_month (compile): 12:17:35.164002 => 12:17:35.177193
[0m12:17:35.180107 [debug] [Thread-1  ]: Began executing node model.maker_warehouse.total_duration_year_month
[0m12:17:35.205325 [debug] [Thread-1  ]: Writing runtime sql for node "model.maker_warehouse.total_duration_year_month"
[0m12:17:35.210751 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.total_duration_year_month"
[0m12:17:35.212297 [debug] [Thread-1  ]: On model.maker_warehouse.total_duration_year_month: BEGIN
[0m12:17:35.213341 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m12:17:35.318013 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
[0m12:17:35.319144 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.total_duration_year_month"
[0m12:17:35.320202 [debug] [Thread-1  ]: On model.maker_warehouse.total_duration_year_month: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_duration_year_month"} */

  
    

  create  table "mydb"."dbt_warehouse"."total_duration_year_month__dbt_tmp"
  
  
    as
  
  (
    
CREATE VIEW total_viewing_time_year_month AS
SELECT
    EXTRACT(YEAR FROM CAST("datetime" AS DATE)) AS "Year",
    EXTRACT(MONTH FROM CAST("datetime" AS DATE)) AS "Month",
    SUM(duration) AS "Total_Duration"
FROM
    mydb.public.raw_netflix
GROUP BY
    EXTRACT(YEAR FROM CAST("datetime" AS DATE)),
    EXTRACT(MONTH FROM CAST("datetime" AS DATE))
ORDER BY
    "Year", "Month"
  );
  
[0m12:17:35.328285 [debug] [Thread-1  ]: Postgres adapter: Postgres error: syntax error at or near "CREATE"
LINE 13: CREATE VIEW total_viewing_time_year_month AS
         ^

[0m12:17:35.329344 [debug] [Thread-1  ]: On model.maker_warehouse.total_duration_year_month: ROLLBACK
[0m12:17:35.334335 [debug] [Thread-1  ]: Timing info for model.maker_warehouse.total_duration_year_month (execute): 12:17:35.183763 => 12:17:35.333731
[0m12:17:35.335330 [debug] [Thread-1  ]: On model.maker_warehouse.total_duration_year_month: Close
[0m12:17:35.368413 [debug] [Thread-1  ]: Database Error in model total_duration_year_month (models/summary/total_duration_year_month.sql)
  syntax error at or near "CREATE"
  LINE 13: CREATE VIEW total_viewing_time_year_month AS
           ^
  compiled Code at target/run/maker_warehouse/models/summary/total_duration_year_month.sql
[0m12:17:35.369720 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '26337f95-5b8b-475d-ba49-efc6dc868b4e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1116ef6d0>]}
[0m12:17:35.371261 [error] [Thread-1  ]: 5 of 10 ERROR creating sql table model dbt_warehouse.total_duration_year_month . [[31mERROR[0m in 0.21s]
[0m12:17:35.373007 [debug] [Thread-1  ]: Finished running node model.maker_warehouse.total_duration_year_month
[0m12:17:35.374164 [debug] [Thread-1  ]: Began running node model.maker_warehouse.total_unique_users
[0m12:17:35.375934 [info ] [Thread-1  ]: 6 of 10 START sql table model dbt_warehouse.total_unique_users ................. [RUN]
[0m12:17:35.378658 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.maker_warehouse.total_duration_year_month, now model.maker_warehouse.total_unique_users)
[0m12:17:35.379787 [debug] [Thread-1  ]: Began compiling node model.maker_warehouse.total_unique_users
[0m12:17:35.389284 [debug] [Thread-1  ]: Writing injected SQL for node "model.maker_warehouse.total_unique_users"
[0m12:17:35.392439 [debug] [Thread-1  ]: Timing info for model.maker_warehouse.total_unique_users (compile): 12:17:35.380565 => 12:17:35.391794
[0m12:17:35.393454 [debug] [Thread-1  ]: Began executing node model.maker_warehouse.total_unique_users
[0m12:17:35.412013 [debug] [Thread-1  ]: Writing runtime sql for node "model.maker_warehouse.total_unique_users"
[0m12:17:35.413689 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.total_unique_users"
[0m12:17:35.415032 [debug] [Thread-1  ]: On model.maker_warehouse.total_unique_users: BEGIN
[0m12:17:35.416250 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m12:17:35.602074 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
[0m12:17:35.603542 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.total_unique_users"
[0m12:17:35.604535 [debug] [Thread-1  ]: On model.maker_warehouse.total_unique_users: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_unique_users"} */

  
    

  create  table "mydb"."dbt_warehouse"."total_unique_users__dbt_tmp"
  
  
    as
  
  (
    
SELECT 
COUNT(DISTINCT(user_id)) AS total_unique_users
FROM mydb.public.raw_netflix
  );
  
[0m12:17:36.029165 [debug] [Thread-4  ]: SQL status: SELECT 7925 in 1.0 seconds
[0m12:17:36.037017 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.no_of_viewings"
[0m12:17:36.037676 [debug] [Thread-4  ]: On model.maker_warehouse.no_of_viewings: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.no_of_viewings"} */
alter table "mydb"."dbt_warehouse"."no_of_viewings" rename to "no_of_viewings__dbt_backup"
[0m12:17:36.042721 [debug] [Thread-4  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:17:36.052180 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.no_of_viewings"
[0m12:17:36.053066 [debug] [Thread-4  ]: On model.maker_warehouse.no_of_viewings: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.no_of_viewings"} */
alter table "mydb"."dbt_warehouse"."no_of_viewings__dbt_tmp" rename to "no_of_viewings"
[0m12:17:36.056652 [debug] [Thread-4  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:17:36.083352 [debug] [Thread-4  ]: On model.maker_warehouse.no_of_viewings: COMMIT
[0m12:17:36.084576 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.no_of_viewings"
[0m12:17:36.086165 [debug] [Thread-4  ]: On model.maker_warehouse.no_of_viewings: COMMIT
[0m12:17:36.093410 [debug] [Thread-4  ]: SQL status: COMMIT in 0.0 seconds
[0m12:17:36.101891 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.no_of_viewings"
[0m12:17:36.103080 [debug] [Thread-4  ]: On model.maker_warehouse.no_of_viewings: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.no_of_viewings"} */
drop table if exists "mydb"."dbt_warehouse"."no_of_viewings__dbt_backup" cascade
[0m12:17:36.117986 [debug] [Thread-4  ]: SQL status: DROP TABLE in 0.0 seconds
[0m12:17:36.121826 [debug] [Thread-4  ]: Timing info for model.maker_warehouse.no_of_viewings (execute): 12:17:34.790344 => 12:17:36.121199
[0m12:17:36.124026 [debug] [Thread-4  ]: On model.maker_warehouse.no_of_viewings: Close
[0m12:17:36.126818 [debug] [Thread-4  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '26337f95-5b8b-475d-ba49-efc6dc868b4e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1115f6cd0>]}
[0m12:17:36.128252 [info ] [Thread-4  ]: 4 of 10 OK created sql table model dbt_warehouse.no_of_viewings ................ [[32mSELECT 7925[0m in 1.54s]
[0m12:17:36.130813 [debug] [Thread-4  ]: Finished running node model.maker_warehouse.no_of_viewings
[0m12:17:36.132444 [debug] [Thread-4  ]: Began running node model.maker_warehouse.total_viewing_time
[0m12:17:36.133901 [info ] [Thread-4  ]: 7 of 10 START sql table model dbt_warehouse.total_viewing_time ................. [RUN]
[0m12:17:36.136065 [debug] [Thread-4  ]: Re-using an available connection from the pool (formerly model.maker_warehouse.no_of_viewings, now model.maker_warehouse.total_viewing_time)
[0m12:17:36.137291 [debug] [Thread-4  ]: Began compiling node model.maker_warehouse.total_viewing_time
[0m12:17:36.146424 [debug] [Thread-4  ]: Writing injected SQL for node "model.maker_warehouse.total_viewing_time"
[0m12:17:36.156298 [debug] [Thread-4  ]: Timing info for model.maker_warehouse.total_viewing_time (compile): 12:17:36.137996 => 12:17:36.155646
[0m12:17:36.157798 [debug] [Thread-4  ]: Began executing node model.maker_warehouse.total_viewing_time
[0m12:17:36.173837 [debug] [Thread-4  ]: Writing runtime sql for node "model.maker_warehouse.total_viewing_time"
[0m12:17:36.175524 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.total_viewing_time"
[0m12:17:36.176593 [debug] [Thread-4  ]: On model.maker_warehouse.total_viewing_time: BEGIN
[0m12:17:36.177776 [debug] [Thread-4  ]: Opening a new connection, currently in state closed
[0m12:17:36.237094 [debug] [Thread-4  ]: SQL status: BEGIN in 0.0 seconds
[0m12:17:36.238372 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.total_viewing_time"
[0m12:17:36.239578 [debug] [Thread-4  ]: On model.maker_warehouse.total_viewing_time: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_viewing_time"} */

  
    

  create  table "mydb"."dbt_warehouse"."total_viewing_time__dbt_tmp"
  
  
    as
  
  (
    
SELECT
title,
SUM(duration) as total_duration
FROM mydb.public.raw_netflix
GROUP BY title
ORDER BY total_duration DESC
  );
  
[0m12:17:36.268938 [debug] [Thread-2  ]: SQL status: SELECT 7925 in 1.0 seconds
[0m12:17:36.280212 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.avg_viewing_time"
[0m12:17:36.281462 [debug] [Thread-2  ]: On model.maker_warehouse.avg_viewing_time: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.avg_viewing_time"} */
alter table "mydb"."dbt_warehouse"."avg_viewing_time" rename to "avg_viewing_time__dbt_backup"
[0m12:17:36.286441 [debug] [Thread-2  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:17:36.295898 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.avg_viewing_time"
[0m12:17:36.297425 [debug] [Thread-2  ]: On model.maker_warehouse.avg_viewing_time: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.avg_viewing_time"} */
alter table "mydb"."dbt_warehouse"."avg_viewing_time__dbt_tmp" rename to "avg_viewing_time"
[0m12:17:36.301107 [debug] [Thread-2  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:17:36.308338 [debug] [Thread-2  ]: On model.maker_warehouse.avg_viewing_time: COMMIT
[0m12:17:36.309821 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.avg_viewing_time"
[0m12:17:36.311101 [debug] [Thread-2  ]: On model.maker_warehouse.avg_viewing_time: COMMIT
[0m12:17:36.321750 [debug] [Thread-2  ]: SQL status: COMMIT in 0.0 seconds
[0m12:17:36.330715 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.avg_viewing_time"
[0m12:17:36.332335 [debug] [Thread-2  ]: On model.maker_warehouse.avg_viewing_time: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.avg_viewing_time"} */
drop table if exists "mydb"."dbt_warehouse"."avg_viewing_time__dbt_backup" cascade
[0m12:17:36.352875 [debug] [Thread-2  ]: SQL status: DROP TABLE in 0.0 seconds
[0m12:17:36.356673 [debug] [Thread-2  ]: Timing info for model.maker_warehouse.avg_viewing_time (execute): 12:17:34.649061 => 12:17:36.356315
[0m12:17:36.357451 [debug] [Thread-2  ]: On model.maker_warehouse.avg_viewing_time: Close
[0m12:17:36.359347 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '26337f95-5b8b-475d-ba49-efc6dc868b4e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111663640>]}
[0m12:17:36.360366 [info ] [Thread-2  ]: 2 of 10 OK created sql table model dbt_warehouse.avg_viewing_time .............. [[32mSELECT 7925[0m in 1.77s]
[0m12:17:36.363921 [debug] [Thread-2  ]: Finished running node model.maker_warehouse.avg_viewing_time
[0m12:17:36.365442 [debug] [Thread-2  ]: Began running node model.maker_warehouse.total_viewings_year_month
[0m12:17:36.367384 [info ] [Thread-2  ]: 8 of 10 START sql table model dbt_warehouse.total_viewings_year_month .......... [RUN]
[0m12:17:36.369254 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly model.maker_warehouse.avg_viewing_time, now model.maker_warehouse.total_viewings_year_month)
[0m12:17:36.370308 [debug] [Thread-2  ]: Began compiling node model.maker_warehouse.total_viewings_year_month
[0m12:17:36.378746 [debug] [Thread-2  ]: Writing injected SQL for node "model.maker_warehouse.total_viewings_year_month"
[0m12:17:36.380627 [debug] [Thread-2  ]: Timing info for model.maker_warehouse.total_viewings_year_month (compile): 12:17:36.370971 => 12:17:36.379981
[0m12:17:36.384182 [debug] [Thread-2  ]: Began executing node model.maker_warehouse.total_viewings_year_month
[0m12:17:36.401136 [debug] [Thread-2  ]: Writing runtime sql for node "model.maker_warehouse.total_viewings_year_month"
[0m12:17:36.406556 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.total_viewings_year_month"
[0m12:17:36.408411 [debug] [Thread-2  ]: On model.maker_warehouse.total_viewings_year_month: BEGIN
[0m12:17:36.409510 [debug] [Thread-2  ]: Opening a new connection, currently in state closed
[0m12:17:36.508333 [debug] [Thread-2  ]: SQL status: BEGIN in 0.0 seconds
[0m12:17:36.509488 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.total_viewings_year_month"
[0m12:17:36.510443 [debug] [Thread-2  ]: On model.maker_warehouse.total_viewings_year_month: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_viewings_year_month"} */

  
    

  create  table "mydb"."dbt_warehouse"."total_viewings_year_month__dbt_tmp"
  
  
    as
  
  (
    
CREATE VIEW total_viewings_year_month AS
SELECT
    EXTRACT(YEAR FROM CAST("datetime" AS DATE)) AS "Year",
    EXTRACT(MONTH FROM CAST("datetime" AS DATE)) AS "Month",
    COUNT(*) AS "Total_Views"
FROM mydb.public.raw_netflix
GROUP BY
    EXTRACT(YEAR FROM CAST("datetime" AS DATE)),
    EXTRACT(MONTH FROM CAST("datetime" AS DATE))
ORDER BY
    "Year", "Month"
  );
  
[0m12:17:36.516702 [debug] [Thread-2  ]: Postgres adapter: Postgres error: syntax error at or near "CREATE"
LINE 13: CREATE VIEW total_viewings_year_month AS
         ^

[0m12:17:36.517941 [debug] [Thread-2  ]: On model.maker_warehouse.total_viewings_year_month: ROLLBACK
[0m12:17:36.521677 [debug] [Thread-2  ]: Timing info for model.maker_warehouse.total_viewings_year_month (execute): 12:17:36.384908 => 12:17:36.520963
[0m12:17:36.523378 [debug] [Thread-2  ]: On model.maker_warehouse.total_viewings_year_month: Close
[0m12:17:36.527212 [debug] [Thread-2  ]: Database Error in model total_viewings_year_month (models/summary/total_viewings_year_month.sql)
  syntax error at or near "CREATE"
  LINE 13: CREATE VIEW total_viewings_year_month AS
           ^
  compiled Code at target/run/maker_warehouse/models/summary/total_viewings_year_month.sql
[0m12:17:36.528736 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '26337f95-5b8b-475d-ba49-efc6dc868b4e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1116b1520>]}
[0m12:17:36.530035 [error] [Thread-2  ]: 8 of 10 ERROR creating sql table model dbt_warehouse.total_viewings_year_month . [[31mERROR[0m in 0.16s]
[0m12:17:36.531459 [debug] [Thread-2  ]: Finished running node model.maker_warehouse.total_viewings_year_month
[0m12:17:36.533117 [debug] [Thread-2  ]: Began running node model.maker_warehouse.user_engagement
[0m12:17:36.534736 [info ] [Thread-2  ]: 9 of 10 START sql table model dbt_warehouse.user_engagement .................... [RUN]
[0m12:17:36.536795 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly model.maker_warehouse.total_viewings_year_month, now model.maker_warehouse.user_engagement)
[0m12:17:36.538247 [debug] [Thread-2  ]: Began compiling node model.maker_warehouse.user_engagement
[0m12:17:36.547197 [debug] [Thread-2  ]: Writing injected SQL for node "model.maker_warehouse.user_engagement"
[0m12:17:36.550691 [debug] [Thread-2  ]: Timing info for model.maker_warehouse.user_engagement (compile): 12:17:36.539126 => 12:17:36.549967
[0m12:17:36.551768 [debug] [Thread-2  ]: Began executing node model.maker_warehouse.user_engagement
[0m12:17:36.568663 [debug] [Thread-2  ]: Writing runtime sql for node "model.maker_warehouse.user_engagement"
[0m12:17:36.570778 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.user_engagement"
[0m12:17:36.571968 [debug] [Thread-2  ]: On model.maker_warehouse.user_engagement: BEGIN
[0m12:17:36.572870 [debug] [Thread-2  ]: Opening a new connection, currently in state closed
[0m12:17:36.637190 [debug] [Thread-2  ]: SQL status: BEGIN in 0.0 seconds
[0m12:17:36.638454 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.user_engagement"
[0m12:17:36.640182 [debug] [Thread-2  ]: On model.maker_warehouse.user_engagement: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.user_engagement"} */

  
    

  create  table "mydb"."dbt_warehouse"."user_engagement__dbt_tmp"
  
  
    as
  
  (
    
SELECT 
DISTINCT(user_id),
COUNT(DISTINCT(title)) AS total_titles,
SUM(duration) AS total_duration
FROM mydb.public.raw_netflix
GROUP BY user_id
  );
  
[0m12:17:37.005454 [debug] [Thread-4  ]: SQL status: SELECT 7925 in 1.0 seconds
[0m12:17:37.016031 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.total_viewing_time"
[0m12:17:37.017146 [debug] [Thread-4  ]: On model.maker_warehouse.total_viewing_time: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_viewing_time"} */
alter table "mydb"."dbt_warehouse"."total_viewing_time" rename to "total_viewing_time__dbt_backup"
[0m12:17:37.021492 [debug] [Thread-4  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:17:37.030801 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.total_viewing_time"
[0m12:17:37.032546 [debug] [Thread-4  ]: On model.maker_warehouse.total_viewing_time: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_viewing_time"} */
alter table "mydb"."dbt_warehouse"."total_viewing_time__dbt_tmp" rename to "total_viewing_time"
[0m12:17:37.035837 [debug] [Thread-4  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:17:37.042113 [debug] [Thread-4  ]: On model.maker_warehouse.total_viewing_time: COMMIT
[0m12:17:37.043491 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.total_viewing_time"
[0m12:17:37.045008 [debug] [Thread-4  ]: On model.maker_warehouse.total_viewing_time: COMMIT
[0m12:17:37.051906 [debug] [Thread-4  ]: SQL status: COMMIT in 0.0 seconds
[0m12:17:37.061807 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.total_viewing_time"
[0m12:17:37.062927 [debug] [Thread-4  ]: On model.maker_warehouse.total_viewing_time: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_viewing_time"} */
drop table if exists "mydb"."dbt_warehouse"."total_viewing_time__dbt_backup" cascade
[0m12:17:37.071015 [debug] [Thread-4  ]: SQL status: DROP TABLE in 0.0 seconds
[0m12:17:37.074754 [debug] [Thread-4  ]: Timing info for model.maker_warehouse.total_viewing_time (execute): 12:17:36.158524 => 12:17:37.074223
[0m12:17:37.075836 [debug] [Thread-4  ]: On model.maker_warehouse.total_viewing_time: Close
[0m12:17:37.078107 [debug] [Thread-4  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '26337f95-5b8b-475d-ba49-efc6dc868b4e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1117e79a0>]}
[0m12:17:37.080123 [info ] [Thread-4  ]: 7 of 10 OK created sql table model dbt_warehouse.total_viewing_time ............ [[32mSELECT 7925[0m in 0.94s]
[0m12:17:37.083727 [debug] [Thread-4  ]: Finished running node model.maker_warehouse.total_viewing_time
[0m12:17:37.689899 [debug] [Thread-3  ]: SQL status: SELECT 8472 in 3.0 seconds
[0m12:17:37.695416 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.movies"
[0m12:17:37.696085 [debug] [Thread-3  ]: On model.maker_warehouse.movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.movies"} */
alter table "mydb"."dbt_warehouse"."movies" rename to "movies__dbt_backup"
[0m12:17:37.701005 [debug] [Thread-3  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:17:37.708884 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.movies"
[0m12:17:37.709530 [debug] [Thread-3  ]: On model.maker_warehouse.movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.movies"} */
alter table "mydb"."dbt_warehouse"."movies__dbt_tmp" rename to "movies"
[0m12:17:37.713612 [debug] [Thread-3  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:17:37.720098 [debug] [Thread-3  ]: On model.maker_warehouse.movies: COMMIT
[0m12:17:37.721781 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.movies"
[0m12:17:37.724382 [debug] [Thread-3  ]: On model.maker_warehouse.movies: COMMIT
[0m12:17:37.737358 [debug] [Thread-3  ]: SQL status: COMMIT in 0.0 seconds
[0m12:17:37.746619 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.movies"
[0m12:17:37.747623 [debug] [Thread-3  ]: On model.maker_warehouse.movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.movies"} */
drop table if exists "mydb"."dbt_warehouse"."movies__dbt_backup" cascade
[0m12:17:37.768788 [debug] [Thread-3  ]: SQL status: DROP TABLE in 0.0 seconds
[0m12:17:37.772776 [debug] [Thread-3  ]: Timing info for model.maker_warehouse.movies (execute): 12:17:34.750515 => 12:17:37.772331
[0m12:17:37.773978 [debug] [Thread-3  ]: On model.maker_warehouse.movies: Close
[0m12:17:37.775788 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '26337f95-5b8b-475d-ba49-efc6dc868b4e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1115cec10>]}
[0m12:17:37.777134 [info ] [Thread-3  ]: 3 of 10 OK created sql table model dbt_warehouse.movies ........................ [[32mSELECT 8472[0m in 3.19s]
[0m12:17:37.779918 [debug] [Thread-3  ]: Finished running node model.maker_warehouse.movies
[0m12:17:37.781684 [debug] [Thread-4  ]: Began running node model.maker_warehouse.all_movies
[0m12:17:37.783254 [info ] [Thread-4  ]: 10 of 10 START sql table model dbt_warehouse.all_movies ........................ [RUN]
[0m12:17:37.785495 [debug] [Thread-4  ]: Re-using an available connection from the pool (formerly model.maker_warehouse.total_viewing_time, now model.maker_warehouse.all_movies)
[0m12:17:37.786601 [debug] [Thread-4  ]: Began compiling node model.maker_warehouse.all_movies
[0m12:17:37.793629 [debug] [Thread-4  ]: Writing injected SQL for node "model.maker_warehouse.all_movies"
[0m12:17:37.796301 [debug] [Thread-4  ]: Timing info for model.maker_warehouse.all_movies (compile): 12:17:37.787371 => 12:17:37.795667
[0m12:17:37.797608 [debug] [Thread-4  ]: Began executing node model.maker_warehouse.all_movies
[0m12:17:37.810727 [debug] [Thread-4  ]: Writing runtime sql for node "model.maker_warehouse.all_movies"
[0m12:17:37.813310 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.all_movies"
[0m12:17:37.814527 [debug] [Thread-4  ]: On model.maker_warehouse.all_movies: BEGIN
[0m12:17:37.815655 [debug] [Thread-4  ]: Opening a new connection, currently in state closed
[0m12:17:37.864241 [debug] [Thread-4  ]: SQL status: BEGIN in 0.0 seconds
[0m12:17:37.865946 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.all_movies"
[0m12:17:37.867242 [debug] [Thread-4  ]: On model.maker_warehouse.all_movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.all_movies"} */

  
    

  create  table "mydb"."dbt_warehouse"."all_movies__dbt_tmp"
  
  
    as
  
  (
    
  
SELECT
*
FROM "mydb"."dbt_warehouse"."movies"
  );
  
[0m12:17:37.924294 [debug] [Thread-4  ]: SQL status: SELECT 8472 in 0.0 seconds
[0m12:17:37.938051 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.all_movies"
[0m12:17:37.939534 [debug] [Thread-4  ]: On model.maker_warehouse.all_movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.all_movies"} */
alter table "mydb"."dbt_warehouse"."all_movies" rename to "all_movies__dbt_backup"
[0m12:17:37.947959 [debug] [Thread-4  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:17:37.958611 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.all_movies"
[0m12:17:37.960063 [debug] [Thread-4  ]: On model.maker_warehouse.all_movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.all_movies"} */
alter table "mydb"."dbt_warehouse"."all_movies__dbt_tmp" rename to "all_movies"
[0m12:17:37.964233 [debug] [Thread-4  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:17:37.971224 [debug] [Thread-4  ]: On model.maker_warehouse.all_movies: COMMIT
[0m12:17:37.972044 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.all_movies"
[0m12:17:37.973028 [debug] [Thread-4  ]: On model.maker_warehouse.all_movies: COMMIT
[0m12:17:37.977063 [debug] [Thread-4  ]: SQL status: COMMIT in 0.0 seconds
[0m12:17:37.988737 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.all_movies"
[0m12:17:37.990034 [debug] [Thread-4  ]: On model.maker_warehouse.all_movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.all_movies"} */
drop table if exists "mydb"."dbt_warehouse"."all_movies__dbt_backup" cascade
[0m12:17:38.009488 [debug] [Thread-4  ]: SQL status: DROP TABLE in 0.0 seconds
[0m12:17:38.015467 [debug] [Thread-4  ]: Timing info for model.maker_warehouse.all_movies (execute): 12:17:37.798451 => 12:17:38.014780
[0m12:17:38.016675 [debug] [Thread-4  ]: On model.maker_warehouse.all_movies: Close
[0m12:17:38.019364 [debug] [Thread-4  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '26337f95-5b8b-475d-ba49-efc6dc868b4e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11169cac0>]}
[0m12:17:38.021259 [info ] [Thread-4  ]: 10 of 10 OK created sql table model dbt_warehouse.all_movies ................... [[32mSELECT 8472[0m in 0.23s]
[0m12:17:38.023952 [debug] [Thread-4  ]: Finished running node model.maker_warehouse.all_movies
[0m12:17:40.324351 [debug] [Thread-1  ]: SQL status: SELECT 1 in 5.0 seconds
[0m12:17:40.333839 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.total_unique_users"
[0m12:17:40.335585 [debug] [Thread-1  ]: On model.maker_warehouse.total_unique_users: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_unique_users"} */
alter table "mydb"."dbt_warehouse"."total_unique_users" rename to "total_unique_users__dbt_backup"
[0m12:17:40.340013 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:17:40.353928 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.total_unique_users"
[0m12:17:40.354676 [debug] [Thread-1  ]: On model.maker_warehouse.total_unique_users: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_unique_users"} */
alter table "mydb"."dbt_warehouse"."total_unique_users__dbt_tmp" rename to "total_unique_users"
[0m12:17:40.359264 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:17:40.366710 [debug] [Thread-1  ]: On model.maker_warehouse.total_unique_users: COMMIT
[0m12:17:40.367986 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.total_unique_users"
[0m12:17:40.368754 [debug] [Thread-1  ]: On model.maker_warehouse.total_unique_users: COMMIT
[0m12:17:40.373826 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
[0m12:17:40.381288 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.total_unique_users"
[0m12:17:40.382816 [debug] [Thread-1  ]: On model.maker_warehouse.total_unique_users: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_unique_users"} */
drop table if exists "mydb"."dbt_warehouse"."total_unique_users__dbt_backup" cascade
[0m12:17:40.392868 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
[0m12:17:40.397307 [debug] [Thread-1  ]: Timing info for model.maker_warehouse.total_unique_users (execute): 12:17:35.396337 => 12:17:40.396842
[0m12:17:40.398547 [debug] [Thread-1  ]: On model.maker_warehouse.total_unique_users: Close
[0m12:17:40.400557 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '26337f95-5b8b-475d-ba49-efc6dc868b4e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111689fa0>]}
[0m12:17:40.403640 [info ] [Thread-1  ]: 6 of 10 OK created sql table model dbt_warehouse.total_unique_users ............ [[32mSELECT 1[0m in 5.02s]
[0m12:17:40.408204 [debug] [Thread-1  ]: Finished running node model.maker_warehouse.total_unique_users
[0m12:17:42.627956 [debug] [Thread-2  ]: SQL status: SELECT 161918 in 6.0 seconds
[0m12:17:42.633533 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.user_engagement"
[0m12:17:42.634202 [debug] [Thread-2  ]: On model.maker_warehouse.user_engagement: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.user_engagement"} */
alter table "mydb"."dbt_warehouse"."user_engagement" rename to "user_engagement__dbt_backup"
[0m12:17:42.642898 [debug] [Thread-2  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:17:42.649574 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.user_engagement"
[0m12:17:42.650214 [debug] [Thread-2  ]: On model.maker_warehouse.user_engagement: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.user_engagement"} */
alter table "mydb"."dbt_warehouse"."user_engagement__dbt_tmp" rename to "user_engagement"
[0m12:17:42.652900 [debug] [Thread-2  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:17:42.656781 [debug] [Thread-2  ]: On model.maker_warehouse.user_engagement: COMMIT
[0m12:17:42.657470 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.user_engagement"
[0m12:17:42.658023 [debug] [Thread-2  ]: On model.maker_warehouse.user_engagement: COMMIT
[0m12:17:42.661883 [debug] [Thread-2  ]: SQL status: COMMIT in 0.0 seconds
[0m12:17:42.668735 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.user_engagement"
[0m12:17:42.669482 [debug] [Thread-2  ]: On model.maker_warehouse.user_engagement: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.user_engagement"} */
drop table if exists "mydb"."dbt_warehouse"."user_engagement__dbt_backup" cascade
[0m12:17:42.678729 [debug] [Thread-2  ]: SQL status: DROP TABLE in 0.0 seconds
[0m12:17:42.681487 [debug] [Thread-2  ]: Timing info for model.maker_warehouse.user_engagement (execute): 12:17:36.552503 => 12:17:42.681159
[0m12:17:42.682091 [debug] [Thread-2  ]: On model.maker_warehouse.user_engagement: Close
[0m12:17:42.683853 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '26337f95-5b8b-475d-ba49-efc6dc868b4e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1117b79d0>]}
[0m12:17:42.685583 [info ] [Thread-2  ]: 9 of 10 OK created sql table model dbt_warehouse.user_engagement ............... [[32mSELECT 161918[0m in 6.15s]
[0m12:17:42.688093 [debug] [Thread-2  ]: Finished running node model.maker_warehouse.user_engagement
[0m12:17:42.691828 [debug] [MainThread]: Using postgres connection "master"
[0m12:17:42.692968 [debug] [MainThread]: On master: BEGIN
[0m12:17:42.693564 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m12:17:42.732276 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m12:17:42.733159 [debug] [MainThread]: On master: COMMIT
[0m12:17:42.733677 [debug] [MainThread]: Using postgres connection "master"
[0m12:17:42.734153 [debug] [MainThread]: On master: COMMIT
[0m12:17:42.736548 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m12:17:42.737620 [debug] [MainThread]: On master: Close
[0m12:17:42.739654 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:17:42.740484 [debug] [MainThread]: Connection 'model.maker_warehouse.total_unique_users' was properly closed.
[0m12:17:42.741481 [debug] [MainThread]: Connection 'model.maker_warehouse.user_engagement' was properly closed.
[0m12:17:42.742548 [debug] [MainThread]: Connection 'model.maker_warehouse.movies' was properly closed.
[0m12:17:42.744192 [debug] [MainThread]: Connection 'model.maker_warehouse.all_movies' was properly closed.
[0m12:17:42.745553 [info ] [MainThread]: 
[0m12:17:42.748045 [info ] [MainThread]: Finished running 1 view model, 9 table models in 0 hours 0 minutes and 8.66 seconds (8.66s).
[0m12:17:42.753640 [debug] [MainThread]: Command end result
[0m12:17:42.769704 [info ] [MainThread]: 
[0m12:17:42.770531 [info ] [MainThread]: [31mCompleted with 2 errors and 0 warnings:[0m
[0m12:17:42.771276 [info ] [MainThread]: 
[0m12:17:42.772164 [error] [MainThread]: [33mDatabase Error in model total_duration_year_month (models/summary/total_duration_year_month.sql)[0m
[0m12:17:42.772836 [error] [MainThread]:   syntax error at or near "CREATE"
[0m12:17:42.773424 [error] [MainThread]:   LINE 13: CREATE VIEW total_viewing_time_year_month AS
[0m12:17:42.773980 [error] [MainThread]:            ^
[0m12:17:42.774527 [error] [MainThread]:   compiled Code at target/run/maker_warehouse/models/summary/total_duration_year_month.sql
[0m12:17:42.775090 [info ] [MainThread]: 
[0m12:17:42.775653 [error] [MainThread]: [33mDatabase Error in model total_viewings_year_month (models/summary/total_viewings_year_month.sql)[0m
[0m12:17:42.776203 [error] [MainThread]:   syntax error at or near "CREATE"
[0m12:17:42.776829 [error] [MainThread]:   LINE 13: CREATE VIEW total_viewings_year_month AS
[0m12:17:42.777584 [error] [MainThread]:            ^
[0m12:17:42.779216 [error] [MainThread]:   compiled Code at target/run/maker_warehouse/models/summary/total_viewings_year_month.sql
[0m12:17:42.780027 [info ] [MainThread]: 
[0m12:17:42.780767 [info ] [MainThread]: Done. PASS=8 WARN=0 ERROR=2 SKIP=0 TOTAL=10
[0m12:17:42.781903 [debug] [MainThread]: Command `dbt run` failed at 12:17:42.781731 after 9.38 seconds
[0m12:17:42.782480 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fc6a4f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111269700>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111546dc0>]}
[0m12:17:42.783173 [debug] [MainThread]: Flushing usage events
[0m12:19:59.187119 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105b202b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e92fd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106eb9850>]}


============================== 12:19:59.194953 | 7546e619-3c2b-440a-8c83-4794e575211f ==============================
[0m12:19:59.194953 [info ] [MainThread]: Running with dbt=1.5.4
[0m12:19:59.196745 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/denisechan/Documents/Makers/Data_Engineering/Week_6/dbt_warehouse', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/Users/denisechan/Documents/Makers/Data_Engineering/Week_6/dbt_warehouse/logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'send_anonymous_usage_stats': 'True'}
[0m12:19:59.512709 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '7546e619-3c2b-440a-8c83-4794e575211f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e92fd0>]}
[0m12:19:59.566243 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '7546e619-3c2b-440a-8c83-4794e575211f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10711d550>]}
[0m12:19:59.568534 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m12:19:59.626821 [debug] [MainThread]: checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, vars: {}, profile: , target: , version: 1.5.4
[0m12:19:59.835030 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
[0m12:19:59.836997 [debug] [MainThread]: Partial parsing: updated file: maker_warehouse://models/summary/total_viewings_year_month.sql
[0m12:19:59.838530 [debug] [MainThread]: Partial parsing: updated file: maker_warehouse://models/summary/total_duration_year_month.sql
[0m12:19:59.890886 [debug] [MainThread]: 1699: static parser successfully parsed summary/total_viewings_year_month.sql
[0m12:19:59.921718 [debug] [MainThread]: 1699: static parser successfully parsed summary/total_duration_year_month.sql
[0m12:19:59.950604 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '7546e619-3c2b-440a-8c83-4794e575211f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1073f70d0>]}
[0m12:19:59.965928 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '7546e619-3c2b-440a-8c83-4794e575211f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107336f10>]}
[0m12:19:59.967290 [info ] [MainThread]: Found 10 models, 0 tests, 0 snapshots, 0 analyses, 307 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics, 0 groups
[0m12:19:59.968329 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7546e619-3c2b-440a-8c83-4794e575211f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107336eb0>]}
[0m12:19:59.972206 [info ] [MainThread]: 
[0m12:19:59.974048 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m12:19:59.976430 [debug] [ThreadPool]: Acquiring new postgres connection 'list_mydb'
[0m12:19:59.999011 [debug] [ThreadPool]: Using postgres connection "list_mydb"
[0m12:20:00.013534 [debug] [ThreadPool]: On list_mydb: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "connection_name": "list_mydb"} */

    select distinct nspname from pg_namespace
  
[0m12:20:00.014557 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:20:00.424949 [debug] [ThreadPool]: SQL status: SELECT 5 in 0.0 seconds
[0m12:20:00.435779 [debug] [ThreadPool]: On list_mydb: Close
[0m12:20:00.447585 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_mydb, now list_mydb_dbt_warehouse)
[0m12:20:00.466502 [debug] [ThreadPool]: Using postgres connection "list_mydb_dbt_warehouse"
[0m12:20:00.467571 [debug] [ThreadPool]: On list_mydb_dbt_warehouse: BEGIN
[0m12:20:00.469707 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:20:00.516163 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m12:20:00.517517 [debug] [ThreadPool]: Using postgres connection "list_mydb_dbt_warehouse"
[0m12:20:00.518454 [debug] [ThreadPool]: On list_mydb_dbt_warehouse: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "connection_name": "list_mydb_dbt_warehouse"} */
select
      'mydb' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_warehouse'
    union all
    select
      'mydb' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_warehouse'
  
[0m12:20:00.538566 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.0 seconds
[0m12:20:00.541941 [debug] [ThreadPool]: On list_mydb_dbt_warehouse: ROLLBACK
[0m12:20:00.544185 [debug] [ThreadPool]: On list_mydb_dbt_warehouse: Close
[0m12:20:00.560404 [debug] [MainThread]: Using postgres connection "master"
[0m12:20:00.562430 [debug] [MainThread]: On master: BEGIN
[0m12:20:00.563452 [debug] [MainThread]: Opening a new connection, currently in state init
[0m12:20:00.604228 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m12:20:00.605010 [debug] [MainThread]: Using postgres connection "master"
[0m12:20:00.605708 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m12:20:00.648563 [debug] [MainThread]: SQL status: SELECT 6 in 0.0 seconds
[0m12:20:00.651802 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7546e619-3c2b-440a-8c83-4794e575211f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10740bdc0>]}
[0m12:20:00.653548 [debug] [MainThread]: On master: ROLLBACK
[0m12:20:00.656470 [debug] [MainThread]: Using postgres connection "master"
[0m12:20:00.657305 [debug] [MainThread]: On master: BEGIN
[0m12:20:00.663510 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m12:20:00.664567 [debug] [MainThread]: On master: COMMIT
[0m12:20:00.665545 [debug] [MainThread]: Using postgres connection "master"
[0m12:20:00.668391 [debug] [MainThread]: On master: COMMIT
[0m12:20:00.676554 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m12:20:00.677768 [debug] [MainThread]: On master: Close
[0m12:20:00.679600 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m12:20:00.680981 [info ] [MainThread]: 
[0m12:20:00.758741 [debug] [Thread-1  ]: Began running node model.maker_warehouse.avg_duration_year_month
[0m12:20:00.759452 [debug] [Thread-2  ]: Began running node model.maker_warehouse.avg_viewing_time
[0m12:20:00.760204 [debug] [Thread-3  ]: Began running node model.maker_warehouse.movies
[0m12:20:00.760938 [debug] [Thread-4  ]: Began running node model.maker_warehouse.no_of_viewings
[0m12:20:00.762020 [info ] [Thread-1  ]: 1 of 10 START sql view model dbt_warehouse.avg_duration_year_month ............. [RUN]
[0m12:20:00.763259 [info ] [Thread-2  ]: 2 of 10 START sql table model dbt_warehouse.avg_viewing_time ................... [RUN]
[0m12:20:00.765699 [info ] [Thread-3  ]: 3 of 10 START sql table model dbt_warehouse.movies ............................. [RUN]
[0m12:20:00.768515 [info ] [Thread-4  ]: 4 of 10 START sql table model dbt_warehouse.no_of_viewings ..................... [RUN]
[0m12:20:00.771166 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_mydb_dbt_warehouse, now model.maker_warehouse.avg_duration_year_month)
[0m12:20:00.773962 [debug] [Thread-2  ]: Acquiring new postgres connection 'model.maker_warehouse.avg_viewing_time'
[0m12:20:00.777223 [debug] [Thread-3  ]: Acquiring new postgres connection 'model.maker_warehouse.movies'
[0m12:20:00.780574 [debug] [Thread-4  ]: Acquiring new postgres connection 'model.maker_warehouse.no_of_viewings'
[0m12:20:00.782299 [debug] [Thread-1  ]: Began compiling node model.maker_warehouse.avg_duration_year_month
[0m12:20:00.783686 [debug] [Thread-2  ]: Began compiling node model.maker_warehouse.avg_viewing_time
[0m12:20:00.785080 [debug] [Thread-3  ]: Began compiling node model.maker_warehouse.movies
[0m12:20:00.789536 [debug] [Thread-4  ]: Began compiling node model.maker_warehouse.no_of_viewings
[0m12:20:00.822481 [debug] [Thread-2  ]: Writing injected SQL for node "model.maker_warehouse.avg_viewing_time"
[0m12:20:00.826537 [debug] [Thread-1  ]: Writing injected SQL for node "model.maker_warehouse.avg_duration_year_month"
[0m12:20:00.833991 [debug] [Thread-3  ]: Writing injected SQL for node "model.maker_warehouse.movies"
[0m12:20:00.840589 [debug] [Thread-4  ]: Writing injected SQL for node "model.maker_warehouse.no_of_viewings"
[0m12:20:00.854679 [debug] [Thread-3  ]: Timing info for model.maker_warehouse.movies (compile): 12:20:00.828091 => 12:20:00.853513
[0m12:20:00.855662 [debug] [Thread-2  ]: Timing info for model.maker_warehouse.avg_viewing_time (compile): 12:20:00.809337 => 12:20:00.855144
[0m12:20:00.856476 [debug] [Thread-3  ]: Began executing node model.maker_warehouse.movies
[0m12:20:00.857180 [debug] [Thread-2  ]: Began executing node model.maker_warehouse.avg_viewing_time
[0m12:20:00.870842 [debug] [Thread-1  ]: Timing info for model.maker_warehouse.avg_duration_year_month (compile): 12:20:00.790679 => 12:20:00.868795
[0m12:20:00.935515 [debug] [Thread-1  ]: Began executing node model.maker_warehouse.avg_duration_year_month
[0m12:20:00.880117 [debug] [Thread-4  ]: Timing info for model.maker_warehouse.no_of_viewings (compile): 12:20:00.834537 => 12:20:00.879353
[0m12:20:00.984165 [debug] [Thread-4  ]: Began executing node model.maker_warehouse.no_of_viewings
[0m12:20:01.366047 [debug] [Thread-4  ]: Writing runtime sql for node "model.maker_warehouse.no_of_viewings"
[0m12:20:01.369713 [debug] [Thread-2  ]: Writing runtime sql for node "model.maker_warehouse.avg_viewing_time"
[0m12:20:01.373902 [debug] [Thread-3  ]: Writing runtime sql for node "model.maker_warehouse.movies"
[0m12:20:01.382074 [debug] [Thread-1  ]: Writing runtime sql for node "model.maker_warehouse.avg_duration_year_month"
[0m12:20:01.389573 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.avg_duration_year_month"
[0m12:20:01.390701 [debug] [Thread-1  ]: On model.maker_warehouse.avg_duration_year_month: BEGIN
[0m12:20:01.391621 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m12:20:01.393239 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.avg_viewing_time"
[0m12:20:01.394580 [debug] [Thread-2  ]: On model.maker_warehouse.avg_viewing_time: BEGIN
[0m12:20:01.397035 [debug] [Thread-2  ]: Opening a new connection, currently in state init
[0m12:20:01.406724 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.no_of_viewings"
[0m12:20:01.408007 [debug] [Thread-4  ]: On model.maker_warehouse.no_of_viewings: BEGIN
[0m12:20:01.409824 [debug] [Thread-4  ]: Opening a new connection, currently in state init
[0m12:20:01.424664 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.movies"
[0m12:20:01.426176 [debug] [Thread-3  ]: On model.maker_warehouse.movies: BEGIN
[0m12:20:01.430046 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m12:20:01.477329 [debug] [Thread-2  ]: SQL status: BEGIN in 0.0 seconds
[0m12:20:01.479891 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.avg_viewing_time"
[0m12:20:01.484907 [debug] [Thread-2  ]: On model.maker_warehouse.avg_viewing_time: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.avg_viewing_time"} */

  
    

  create  table "mydb"."dbt_warehouse"."avg_viewing_time__dbt_tmp"
  
  
    as
  
  (
    
SELECT
title,
ROUND(CAST(AVG(duration) AS NUMERIC), 2) as avg_duration
FROM mydb.public.raw_netflix
GROUP BY title
ORDER BY avg_duration DESC
  );
  
[0m12:20:01.498678 [debug] [Thread-4  ]: SQL status: BEGIN in 0.0 seconds
[0m12:20:01.499720 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.no_of_viewings"
[0m12:20:01.500722 [debug] [Thread-4  ]: On model.maker_warehouse.no_of_viewings: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.no_of_viewings"} */

  
    

  create  table "mydb"."dbt_warehouse"."no_of_viewings__dbt_tmp"
  
  
    as
  
  (
    
SELECT
  title,
  COUNT(*) as total_views
FROM mydb.public.raw_netflix
GROUP BY title
ORDER BY total_views DESC
  );
  
[0m12:20:01.521451 [debug] [Thread-3  ]: SQL status: BEGIN in 0.0 seconds
[0m12:20:01.523605 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.movies"
[0m12:20:01.524842 [debug] [Thread-3  ]: On model.maker_warehouse.movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.movies"} */

  
    

  create  table "mydb"."dbt_warehouse"."movies__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    DISTINCT
    title,
    genres,
    release_date,
    movie_id
FROM mydb.public.raw_netflix
  );
  
[0m12:20:01.535750 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
[0m12:20:01.537992 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.avg_duration_year_month"
[0m12:20:01.539254 [debug] [Thread-1  ]: On model.maker_warehouse.avg_duration_year_month: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.avg_duration_year_month"} */

  create view "mydb"."dbt_warehouse"."avg_duration_year_month__dbt_tmp"
    
    
  as (
    
SELECT
    EXTRACT(YEAR FROM CAST("datetime" AS DATE)) AS "Year",
    EXTRACT(MONTH FROM CAST("datetime" AS DATE)) AS "Month",
    ROUND(CAST(AVG(duration) AS NUMERIC), 2) AS "Average_Duration"
FROM
    mydb.public.raw_netflix
GROUP BY
    EXTRACT(YEAR FROM CAST("datetime" AS DATE)),
    EXTRACT(MONTH FROM CAST("datetime" AS DATE))
ORDER BY
    "Year", "Month"
  );
[0m12:20:01.581945 [debug] [Thread-1  ]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:20:01.617880 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.avg_duration_year_month"
[0m12:20:01.620166 [debug] [Thread-1  ]: On model.maker_warehouse.avg_duration_year_month: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.avg_duration_year_month"} */
alter table "mydb"."dbt_warehouse"."avg_duration_year_month" rename to "avg_duration_year_month__dbt_backup"
[0m12:20:01.676766 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:20:01.689471 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.avg_duration_year_month"
[0m12:20:01.690856 [debug] [Thread-1  ]: On model.maker_warehouse.avg_duration_year_month: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.avg_duration_year_month"} */
alter table "mydb"."dbt_warehouse"."avg_duration_year_month__dbt_tmp" rename to "avg_duration_year_month"
[0m12:20:01.839101 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:20:01.914678 [debug] [Thread-1  ]: On model.maker_warehouse.avg_duration_year_month: COMMIT
[0m12:20:01.915964 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.avg_duration_year_month"
[0m12:20:01.916957 [debug] [Thread-1  ]: On model.maker_warehouse.avg_duration_year_month: COMMIT
[0m12:20:01.924506 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
[0m12:20:01.957759 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.avg_duration_year_month"
[0m12:20:01.959069 [debug] [Thread-1  ]: On model.maker_warehouse.avg_duration_year_month: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.avg_duration_year_month"} */
drop view if exists "mydb"."dbt_warehouse"."avg_duration_year_month__dbt_backup" cascade
[0m12:20:01.992374 [debug] [Thread-1  ]: SQL status: DROP VIEW in 0.0 seconds
[0m12:20:01.997741 [debug] [Thread-1  ]: Timing info for model.maker_warehouse.avg_duration_year_month (execute): 12:20:00.938072 => 12:20:01.996946
[0m12:20:01.999162 [debug] [Thread-1  ]: On model.maker_warehouse.avg_duration_year_month: Close
[0m12:20:02.001189 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7546e619-3c2b-440a-8c83-4794e575211f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107408820>]}
[0m12:20:02.005899 [info ] [Thread-1  ]: 1 of 10 OK created sql view model dbt_warehouse.avg_duration_year_month ........ [[32mCREATE VIEW[0m in 1.23s]
[0m12:20:02.011064 [debug] [Thread-1  ]: Finished running node model.maker_warehouse.avg_duration_year_month
[0m12:20:02.012603 [debug] [Thread-1  ]: Began running node model.maker_warehouse.total_duration_year_month
[0m12:20:02.015759 [info ] [Thread-1  ]: 5 of 10 START sql view model dbt_warehouse.total_duration_year_month ........... [RUN]
[0m12:20:02.019323 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.maker_warehouse.avg_duration_year_month, now model.maker_warehouse.total_duration_year_month)
[0m12:20:02.020879 [debug] [Thread-1  ]: Began compiling node model.maker_warehouse.total_duration_year_month
[0m12:20:02.032761 [debug] [Thread-1  ]: Writing injected SQL for node "model.maker_warehouse.total_duration_year_month"
[0m12:20:02.036967 [debug] [Thread-1  ]: Timing info for model.maker_warehouse.total_duration_year_month (compile): 12:20:02.022040 => 12:20:02.035568
[0m12:20:02.038476 [debug] [Thread-1  ]: Began executing node model.maker_warehouse.total_duration_year_month
[0m12:20:02.067689 [debug] [Thread-1  ]: Writing runtime sql for node "model.maker_warehouse.total_duration_year_month"
[0m12:20:02.070351 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.total_duration_year_month"
[0m12:20:02.072064 [debug] [Thread-1  ]: On model.maker_warehouse.total_duration_year_month: BEGIN
[0m12:20:02.073206 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m12:20:02.188143 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
[0m12:20:02.189621 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.total_duration_year_month"
[0m12:20:02.190698 [debug] [Thread-1  ]: On model.maker_warehouse.total_duration_year_month: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_duration_year_month"} */

  create view "mydb"."dbt_warehouse"."total_duration_year_month__dbt_tmp"
    
    
  as (
    
SELECT
    EXTRACT(YEAR FROM CAST("datetime" AS DATE)) AS "Year",
    EXTRACT(MONTH FROM CAST("datetime" AS DATE)) AS "Month",
    SUM(duration) AS "Total_Duration"
FROM
    mydb.public.raw_netflix
GROUP BY
    EXTRACT(YEAR FROM CAST("datetime" AS DATE)),
    EXTRACT(MONTH FROM CAST("datetime" AS DATE))
ORDER BY
    "Year", "Month"
  );
[0m12:20:02.238253 [debug] [Thread-1  ]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:20:02.245354 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.total_duration_year_month"
[0m12:20:02.247341 [debug] [Thread-1  ]: On model.maker_warehouse.total_duration_year_month: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_duration_year_month"} */
alter table "mydb"."dbt_warehouse"."total_duration_year_month__dbt_tmp" rename to "total_duration_year_month"
[0m12:20:02.252077 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:20:02.257958 [debug] [Thread-1  ]: On model.maker_warehouse.total_duration_year_month: COMMIT
[0m12:20:02.260025 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.total_duration_year_month"
[0m12:20:02.262026 [debug] [Thread-1  ]: On model.maker_warehouse.total_duration_year_month: COMMIT
[0m12:20:02.267023 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
[0m12:20:02.274526 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.total_duration_year_month"
[0m12:20:02.275320 [debug] [Thread-1  ]: On model.maker_warehouse.total_duration_year_month: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_duration_year_month"} */
drop view if exists "mydb"."dbt_warehouse"."total_duration_year_month__dbt_backup" cascade
[0m12:20:02.278009 [debug] [Thread-1  ]: SQL status: DROP VIEW in 0.0 seconds
[0m12:20:02.282051 [debug] [Thread-1  ]: Timing info for model.maker_warehouse.total_duration_year_month (execute): 12:20:02.040016 => 12:20:02.281296
[0m12:20:02.283122 [debug] [Thread-1  ]: On model.maker_warehouse.total_duration_year_month: Close
[0m12:20:02.285441 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7546e619-3c2b-440a-8c83-4794e575211f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1075ade20>]}
[0m12:20:02.287391 [info ] [Thread-1  ]: 5 of 10 OK created sql view model dbt_warehouse.total_duration_year_month ...... [[32mCREATE VIEW[0m in 0.27s]
[0m12:20:02.289936 [debug] [Thread-1  ]: Finished running node model.maker_warehouse.total_duration_year_month
[0m12:20:02.291240 [debug] [Thread-1  ]: Began running node model.maker_warehouse.total_unique_users
[0m12:20:02.292135 [info ] [Thread-1  ]: 6 of 10 START sql table model dbt_warehouse.total_unique_users ................. [RUN]
[0m12:20:02.294345 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.maker_warehouse.total_duration_year_month, now model.maker_warehouse.total_unique_users)
[0m12:20:02.295522 [debug] [Thread-1  ]: Began compiling node model.maker_warehouse.total_unique_users
[0m12:20:02.301248 [debug] [Thread-1  ]: Writing injected SQL for node "model.maker_warehouse.total_unique_users"
[0m12:20:02.304550 [debug] [Thread-1  ]: Timing info for model.maker_warehouse.total_unique_users (compile): 12:20:02.296273 => 12:20:02.303303
[0m12:20:02.305730 [debug] [Thread-1  ]: Began executing node model.maker_warehouse.total_unique_users
[0m12:20:02.321168 [debug] [Thread-1  ]: Writing runtime sql for node "model.maker_warehouse.total_unique_users"
[0m12:20:02.323389 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.total_unique_users"
[0m12:20:02.324625 [debug] [Thread-1  ]: On model.maker_warehouse.total_unique_users: BEGIN
[0m12:20:02.325995 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m12:20:02.391968 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
[0m12:20:02.393305 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.total_unique_users"
[0m12:20:02.394511 [debug] [Thread-1  ]: On model.maker_warehouse.total_unique_users: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_unique_users"} */

  
    

  create  table "mydb"."dbt_warehouse"."total_unique_users__dbt_tmp"
  
  
    as
  
  (
    
SELECT 
COUNT(DISTINCT(user_id)) AS total_unique_users
FROM mydb.public.raw_netflix
  );
  
[0m12:20:02.827027 [debug] [Thread-4  ]: SQL status: SELECT 7925 in 1.0 seconds
[0m12:20:02.837089 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.no_of_viewings"
[0m12:20:02.838362 [debug] [Thread-4  ]: On model.maker_warehouse.no_of_viewings: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.no_of_viewings"} */
alter table "mydb"."dbt_warehouse"."no_of_viewings" rename to "no_of_viewings__dbt_backup"
[0m12:20:02.842595 [debug] [Thread-4  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:20:02.851783 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.no_of_viewings"
[0m12:20:02.853053 [debug] [Thread-4  ]: On model.maker_warehouse.no_of_viewings: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.no_of_viewings"} */
alter table "mydb"."dbt_warehouse"."no_of_viewings__dbt_tmp" rename to "no_of_viewings"
[0m12:20:02.856140 [debug] [Thread-4  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:20:02.873523 [debug] [Thread-4  ]: On model.maker_warehouse.no_of_viewings: COMMIT
[0m12:20:02.874542 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.no_of_viewings"
[0m12:20:02.875444 [debug] [Thread-4  ]: On model.maker_warehouse.no_of_viewings: COMMIT
[0m12:20:02.881540 [debug] [Thread-4  ]: SQL status: COMMIT in 0.0 seconds
[0m12:20:02.889461 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.no_of_viewings"
[0m12:20:02.890637 [debug] [Thread-4  ]: On model.maker_warehouse.no_of_viewings: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.no_of_viewings"} */
drop table if exists "mydb"."dbt_warehouse"."no_of_viewings__dbt_backup" cascade
[0m12:20:02.913823 [debug] [Thread-4  ]: SQL status: DROP TABLE in 0.0 seconds
[0m12:20:02.917522 [debug] [Thread-4  ]: Timing info for model.maker_warehouse.no_of_viewings (execute): 12:20:00.985142 => 12:20:02.916992
[0m12:20:02.918623 [debug] [Thread-4  ]: On model.maker_warehouse.no_of_viewings: Close
[0m12:20:02.920551 [debug] [Thread-4  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7546e619-3c2b-440a-8c83-4794e575211f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10751aa30>]}
[0m12:20:02.921995 [info ] [Thread-4  ]: 4 of 10 OK created sql table model dbt_warehouse.no_of_viewings ................ [[32mSELECT 7925[0m in 2.14s]
[0m12:20:02.924412 [debug] [Thread-4  ]: Finished running node model.maker_warehouse.no_of_viewings
[0m12:20:02.926142 [debug] [Thread-4  ]: Began running node model.maker_warehouse.total_viewing_time
[0m12:20:02.928000 [info ] [Thread-4  ]: 7 of 10 START sql table model dbt_warehouse.total_viewing_time ................. [RUN]
[0m12:20:02.930849 [debug] [Thread-4  ]: Re-using an available connection from the pool (formerly model.maker_warehouse.no_of_viewings, now model.maker_warehouse.total_viewing_time)
[0m12:20:02.932166 [debug] [Thread-4  ]: Began compiling node model.maker_warehouse.total_viewing_time
[0m12:20:02.941058 [debug] [Thread-4  ]: Writing injected SQL for node "model.maker_warehouse.total_viewing_time"
[0m12:20:02.943741 [debug] [Thread-4  ]: Timing info for model.maker_warehouse.total_viewing_time (compile): 12:20:02.932974 => 12:20:02.943068
[0m12:20:02.945276 [debug] [Thread-4  ]: Began executing node model.maker_warehouse.total_viewing_time
[0m12:20:02.966273 [debug] [Thread-4  ]: Writing runtime sql for node "model.maker_warehouse.total_viewing_time"
[0m12:20:02.969061 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.total_viewing_time"
[0m12:20:02.970580 [debug] [Thread-4  ]: On model.maker_warehouse.total_viewing_time: BEGIN
[0m12:20:02.971914 [debug] [Thread-4  ]: Opening a new connection, currently in state closed
[0m12:20:03.067187 [debug] [Thread-4  ]: SQL status: BEGIN in 0.0 seconds
[0m12:20:03.068986 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.total_viewing_time"
[0m12:20:03.070124 [debug] [Thread-4  ]: On model.maker_warehouse.total_viewing_time: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_viewing_time"} */

  
    

  create  table "mydb"."dbt_warehouse"."total_viewing_time__dbt_tmp"
  
  
    as
  
  (
    
SELECT
title,
SUM(duration) as total_duration
FROM mydb.public.raw_netflix
GROUP BY title
ORDER BY total_duration DESC
  );
  
[0m12:20:03.370169 [debug] [Thread-2  ]: SQL status: SELECT 7925 in 2.0 seconds
[0m12:20:03.379860 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.avg_viewing_time"
[0m12:20:03.381277 [debug] [Thread-2  ]: On model.maker_warehouse.avg_viewing_time: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.avg_viewing_time"} */
alter table "mydb"."dbt_warehouse"."avg_viewing_time" rename to "avg_viewing_time__dbt_backup"
[0m12:20:03.391638 [debug] [Thread-2  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:20:03.400917 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.avg_viewing_time"
[0m12:20:03.402108 [debug] [Thread-2  ]: On model.maker_warehouse.avg_viewing_time: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.avg_viewing_time"} */
alter table "mydb"."dbt_warehouse"."avg_viewing_time__dbt_tmp" rename to "avg_viewing_time"
[0m12:20:03.409881 [debug] [Thread-2  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:20:03.419929 [debug] [Thread-2  ]: On model.maker_warehouse.avg_viewing_time: COMMIT
[0m12:20:03.421017 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.avg_viewing_time"
[0m12:20:03.422073 [debug] [Thread-2  ]: On model.maker_warehouse.avg_viewing_time: COMMIT
[0m12:20:03.445615 [debug] [Thread-2  ]: SQL status: COMMIT in 0.0 seconds
[0m12:20:03.457256 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.avg_viewing_time"
[0m12:20:03.460268 [debug] [Thread-2  ]: On model.maker_warehouse.avg_viewing_time: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.avg_viewing_time"} */
drop table if exists "mydb"."dbt_warehouse"."avg_viewing_time__dbt_backup" cascade
[0m12:20:03.485924 [debug] [Thread-2  ]: SQL status: DROP TABLE in 0.0 seconds
[0m12:20:03.494378 [debug] [Thread-2  ]: Timing info for model.maker_warehouse.avg_viewing_time (execute): 12:20:00.887082 => 12:20:03.493326
[0m12:20:03.495970 [debug] [Thread-2  ]: On model.maker_warehouse.avg_viewing_time: Close
[0m12:20:03.498840 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7546e619-3c2b-440a-8c83-4794e575211f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10753cb80>]}
[0m12:20:03.500811 [info ] [Thread-2  ]: 2 of 10 OK created sql table model dbt_warehouse.avg_viewing_time .............. [[32mSELECT 7925[0m in 2.73s]
[0m12:20:03.505964 [debug] [Thread-2  ]: Finished running node model.maker_warehouse.avg_viewing_time
[0m12:20:03.509971 [debug] [Thread-2  ]: Began running node model.maker_warehouse.total_viewings_year_month
[0m12:20:03.511493 [info ] [Thread-2  ]: 8 of 10 START sql view model dbt_warehouse.total_viewings_year_month ........... [RUN]
[0m12:20:03.513655 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly model.maker_warehouse.avg_viewing_time, now model.maker_warehouse.total_viewings_year_month)
[0m12:20:03.514875 [debug] [Thread-2  ]: Began compiling node model.maker_warehouse.total_viewings_year_month
[0m12:20:03.530177 [debug] [Thread-2  ]: Writing injected SQL for node "model.maker_warehouse.total_viewings_year_month"
[0m12:20:03.533456 [debug] [Thread-2  ]: Timing info for model.maker_warehouse.total_viewings_year_month (compile): 12:20:03.515677 => 12:20:03.532363
[0m12:20:03.536821 [debug] [Thread-2  ]: Began executing node model.maker_warehouse.total_viewings_year_month
[0m12:20:03.560160 [debug] [Thread-2  ]: Writing runtime sql for node "model.maker_warehouse.total_viewings_year_month"
[0m12:20:03.563488 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.total_viewings_year_month"
[0m12:20:03.565096 [debug] [Thread-2  ]: On model.maker_warehouse.total_viewings_year_month: BEGIN
[0m12:20:03.566107 [debug] [Thread-2  ]: Opening a new connection, currently in state closed
[0m12:20:03.637757 [debug] [Thread-2  ]: SQL status: BEGIN in 0.0 seconds
[0m12:20:03.639961 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.total_viewings_year_month"
[0m12:20:03.640928 [debug] [Thread-2  ]: On model.maker_warehouse.total_viewings_year_month: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_viewings_year_month"} */

  create view "mydb"."dbt_warehouse"."total_viewings_year_month__dbt_tmp"
    
    
  as (
    
SELECT
    EXTRACT(YEAR FROM CAST("datetime" AS DATE)) AS "Year",
    EXTRACT(MONTH FROM CAST("datetime" AS DATE)) AS "Month",
    COUNT(*) AS "Total_Views"
FROM mydb.public.raw_netflix
GROUP BY
    EXTRACT(YEAR FROM CAST("datetime" AS DATE)),
    EXTRACT(MONTH FROM CAST("datetime" AS DATE))
ORDER BY
    "Year", "Month"
  );
[0m12:20:03.676613 [debug] [Thread-2  ]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:20:03.688526 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.total_viewings_year_month"
[0m12:20:03.690838 [debug] [Thread-2  ]: On model.maker_warehouse.total_viewings_year_month: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_viewings_year_month"} */
alter table "mydb"."dbt_warehouse"."total_viewings_year_month__dbt_tmp" rename to "total_viewings_year_month"
[0m12:20:03.698659 [debug] [Thread-2  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:20:03.705770 [debug] [Thread-2  ]: On model.maker_warehouse.total_viewings_year_month: COMMIT
[0m12:20:03.707879 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.total_viewings_year_month"
[0m12:20:03.708919 [debug] [Thread-2  ]: On model.maker_warehouse.total_viewings_year_month: COMMIT
[0m12:20:03.717369 [debug] [Thread-2  ]: SQL status: COMMIT in 0.0 seconds
[0m12:20:03.729664 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.total_viewings_year_month"
[0m12:20:03.731680 [debug] [Thread-2  ]: On model.maker_warehouse.total_viewings_year_month: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_viewings_year_month"} */
drop view if exists "mydb"."dbt_warehouse"."total_viewings_year_month__dbt_backup" cascade
[0m12:20:03.736058 [debug] [Thread-2  ]: SQL status: DROP VIEW in 0.0 seconds
[0m12:20:03.740689 [debug] [Thread-2  ]: Timing info for model.maker_warehouse.total_viewings_year_month (execute): 12:20:03.539154 => 12:20:03.740031
[0m12:20:03.742021 [debug] [Thread-2  ]: On model.maker_warehouse.total_viewings_year_month: Close
[0m12:20:03.744454 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7546e619-3c2b-440a-8c83-4794e575211f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1075d2550>]}
[0m12:20:03.746023 [info ] [Thread-2  ]: 8 of 10 OK created sql view model dbt_warehouse.total_viewings_year_month ...... [[32mCREATE VIEW[0m in 0.23s]
[0m12:20:03.748892 [debug] [Thread-2  ]: Finished running node model.maker_warehouse.total_viewings_year_month
[0m12:20:03.750407 [debug] [Thread-2  ]: Began running node model.maker_warehouse.user_engagement
[0m12:20:03.751581 [info ] [Thread-2  ]: 9 of 10 START sql table model dbt_warehouse.user_engagement .................... [RUN]
[0m12:20:03.755213 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly model.maker_warehouse.total_viewings_year_month, now model.maker_warehouse.user_engagement)
[0m12:20:03.756444 [debug] [Thread-2  ]: Began compiling node model.maker_warehouse.user_engagement
[0m12:20:03.763597 [debug] [Thread-2  ]: Writing injected SQL for node "model.maker_warehouse.user_engagement"
[0m12:20:03.766162 [debug] [Thread-2  ]: Timing info for model.maker_warehouse.user_engagement (compile): 12:20:03.757153 => 12:20:03.765531
[0m12:20:03.767689 [debug] [Thread-2  ]: Began executing node model.maker_warehouse.user_engagement
[0m12:20:03.801026 [debug] [Thread-2  ]: Writing runtime sql for node "model.maker_warehouse.user_engagement"
[0m12:20:03.803408 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.user_engagement"
[0m12:20:03.806081 [debug] [Thread-2  ]: On model.maker_warehouse.user_engagement: BEGIN
[0m12:20:03.809053 [debug] [Thread-2  ]: Opening a new connection, currently in state closed
[0m12:20:03.879539 [debug] [Thread-2  ]: SQL status: BEGIN in 0.0 seconds
[0m12:20:03.881377 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.user_engagement"
[0m12:20:03.883069 [debug] [Thread-2  ]: On model.maker_warehouse.user_engagement: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.user_engagement"} */

  
    

  create  table "mydb"."dbt_warehouse"."user_engagement__dbt_tmp"
  
  
    as
  
  (
    
SELECT 
DISTINCT(user_id),
COUNT(DISTINCT(title)) AS total_titles,
SUM(duration) AS total_duration
FROM mydb.public.raw_netflix
GROUP BY user_id
  );
  
[0m12:20:04.308572 [debug] [Thread-4  ]: SQL status: SELECT 7925 in 1.0 seconds
[0m12:20:04.319486 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.total_viewing_time"
[0m12:20:04.321539 [debug] [Thread-4  ]: On model.maker_warehouse.total_viewing_time: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_viewing_time"} */
alter table "mydb"."dbt_warehouse"."total_viewing_time" rename to "total_viewing_time__dbt_backup"
[0m12:20:04.326109 [debug] [Thread-4  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:20:04.340885 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.total_viewing_time"
[0m12:20:04.344582 [debug] [Thread-4  ]: On model.maker_warehouse.total_viewing_time: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_viewing_time"} */
alter table "mydb"."dbt_warehouse"."total_viewing_time__dbt_tmp" rename to "total_viewing_time"
[0m12:20:04.354804 [debug] [Thread-4  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:20:04.363111 [debug] [Thread-4  ]: On model.maker_warehouse.total_viewing_time: COMMIT
[0m12:20:04.365968 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.total_viewing_time"
[0m12:20:04.368252 [debug] [Thread-4  ]: On model.maker_warehouse.total_viewing_time: COMMIT
[0m12:20:04.379028 [debug] [Thread-4  ]: SQL status: COMMIT in 0.0 seconds
[0m12:20:04.391752 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.total_viewing_time"
[0m12:20:04.392959 [debug] [Thread-4  ]: On model.maker_warehouse.total_viewing_time: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_viewing_time"} */
drop table if exists "mydb"."dbt_warehouse"."total_viewing_time__dbt_backup" cascade
[0m12:20:04.419643 [debug] [Thread-4  ]: SQL status: DROP TABLE in 0.0 seconds
[0m12:20:04.424884 [debug] [Thread-4  ]: Timing info for model.maker_warehouse.total_viewing_time (execute): 12:20:02.945967 => 12:20:04.423743
[0m12:20:04.425981 [debug] [Thread-4  ]: On model.maker_warehouse.total_viewing_time: Close
[0m12:20:04.428858 [debug] [Thread-4  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7546e619-3c2b-440a-8c83-4794e575211f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107404f40>]}
[0m12:20:04.430593 [info ] [Thread-4  ]: 7 of 10 OK created sql table model dbt_warehouse.total_viewing_time ............ [[32mSELECT 7925[0m in 1.50s]
[0m12:20:04.433691 [debug] [Thread-4  ]: Finished running node model.maker_warehouse.total_viewing_time
[0m12:20:04.943542 [debug] [Thread-3  ]: SQL status: SELECT 8472 in 3.0 seconds
[0m12:20:04.950312 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.movies"
[0m12:20:04.951132 [debug] [Thread-3  ]: On model.maker_warehouse.movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.movies"} */
alter table "mydb"."dbt_warehouse"."movies" rename to "movies__dbt_backup"
[0m12:20:04.955598 [debug] [Thread-3  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:20:04.961285 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.movies"
[0m12:20:04.961951 [debug] [Thread-3  ]: On model.maker_warehouse.movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.movies"} */
alter table "mydb"."dbt_warehouse"."movies__dbt_tmp" rename to "movies"
[0m12:20:04.965497 [debug] [Thread-3  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:20:04.972156 [debug] [Thread-3  ]: On model.maker_warehouse.movies: COMMIT
[0m12:20:04.972833 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.movies"
[0m12:20:04.973719 [debug] [Thread-3  ]: On model.maker_warehouse.movies: COMMIT
[0m12:20:04.980381 [debug] [Thread-3  ]: SQL status: COMMIT in 0.0 seconds
[0m12:20:04.984971 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.movies"
[0m12:20:04.985626 [debug] [Thread-3  ]: On model.maker_warehouse.movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.movies"} */
drop table if exists "mydb"."dbt_warehouse"."movies__dbt_backup" cascade
[0m12:20:05.000180 [debug] [Thread-3  ]: SQL status: DROP TABLE in 0.0 seconds
[0m12:20:05.004450 [debug] [Thread-3  ]: Timing info for model.maker_warehouse.movies (execute): 12:20:00.857630 => 12:20:05.003612
[0m12:20:05.005365 [debug] [Thread-3  ]: On model.maker_warehouse.movies: Close
[0m12:20:05.007180 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7546e619-3c2b-440a-8c83-4794e575211f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10756d430>]}
[0m12:20:05.009529 [info ] [Thread-3  ]: 3 of 10 OK created sql table model dbt_warehouse.movies ........................ [[32mSELECT 8472[0m in 4.23s]
[0m12:20:05.011900 [debug] [Thread-3  ]: Finished running node model.maker_warehouse.movies
[0m12:20:05.013408 [debug] [Thread-4  ]: Began running node model.maker_warehouse.all_movies
[0m12:20:05.014695 [info ] [Thread-4  ]: 10 of 10 START sql table model dbt_warehouse.all_movies ........................ [RUN]
[0m12:20:05.016746 [debug] [Thread-4  ]: Re-using an available connection from the pool (formerly model.maker_warehouse.total_viewing_time, now model.maker_warehouse.all_movies)
[0m12:20:05.017863 [debug] [Thread-4  ]: Began compiling node model.maker_warehouse.all_movies
[0m12:20:05.026051 [debug] [Thread-4  ]: Writing injected SQL for node "model.maker_warehouse.all_movies"
[0m12:20:05.030719 [debug] [Thread-4  ]: Timing info for model.maker_warehouse.all_movies (compile): 12:20:05.018715 => 12:20:05.029997
[0m12:20:05.032000 [debug] [Thread-4  ]: Began executing node model.maker_warehouse.all_movies
[0m12:20:05.049791 [debug] [Thread-4  ]: Writing runtime sql for node "model.maker_warehouse.all_movies"
[0m12:20:05.051887 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.all_movies"
[0m12:20:05.052867 [debug] [Thread-4  ]: On model.maker_warehouse.all_movies: BEGIN
[0m12:20:05.053911 [debug] [Thread-4  ]: Opening a new connection, currently in state closed
[0m12:20:05.100092 [debug] [Thread-4  ]: SQL status: BEGIN in 0.0 seconds
[0m12:20:05.101388 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.all_movies"
[0m12:20:05.102636 [debug] [Thread-4  ]: On model.maker_warehouse.all_movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.all_movies"} */

  
    

  create  table "mydb"."dbt_warehouse"."all_movies__dbt_tmp"
  
  
    as
  
  (
    
  
SELECT
*
FROM "mydb"."dbt_warehouse"."movies"
  );
  
[0m12:20:05.150874 [debug] [Thread-4  ]: SQL status: SELECT 8472 in 0.0 seconds
[0m12:20:05.163782 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.all_movies"
[0m12:20:05.164465 [debug] [Thread-4  ]: On model.maker_warehouse.all_movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.all_movies"} */
alter table "mydb"."dbt_warehouse"."all_movies" rename to "all_movies__dbt_backup"
[0m12:20:05.169055 [debug] [Thread-4  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:20:05.178354 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.all_movies"
[0m12:20:05.183056 [debug] [Thread-4  ]: On model.maker_warehouse.all_movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.all_movies"} */
alter table "mydb"."dbt_warehouse"."all_movies__dbt_tmp" rename to "all_movies"
[0m12:20:05.187645 [debug] [Thread-4  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:20:05.196012 [debug] [Thread-4  ]: On model.maker_warehouse.all_movies: COMMIT
[0m12:20:05.197329 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.all_movies"
[0m12:20:05.198451 [debug] [Thread-4  ]: On model.maker_warehouse.all_movies: COMMIT
[0m12:20:05.204792 [debug] [Thread-4  ]: SQL status: COMMIT in 0.0 seconds
[0m12:20:05.212544 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.all_movies"
[0m12:20:05.213436 [debug] [Thread-4  ]: On model.maker_warehouse.all_movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.all_movies"} */
drop table if exists "mydb"."dbt_warehouse"."all_movies__dbt_backup" cascade
[0m12:20:05.232836 [debug] [Thread-4  ]: SQL status: DROP TABLE in 0.0 seconds
[0m12:20:05.235432 [debug] [Thread-4  ]: Timing info for model.maker_warehouse.all_movies (execute): 12:20:05.032965 => 12:20:05.235100
[0m12:20:05.236696 [debug] [Thread-4  ]: On model.maker_warehouse.all_movies: Close
[0m12:20:05.238617 [debug] [Thread-4  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7546e619-3c2b-440a-8c83-4794e575211f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1075ee730>]}
[0m12:20:05.240246 [info ] [Thread-4  ]: 10 of 10 OK created sql table model dbt_warehouse.all_movies ................... [[32mSELECT 8472[0m in 0.22s]
[0m12:20:05.243530 [debug] [Thread-4  ]: Finished running node model.maker_warehouse.all_movies
[0m12:20:07.506566 [debug] [Thread-1  ]: SQL status: SELECT 1 in 5.0 seconds
[0m12:20:07.513679 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.total_unique_users"
[0m12:20:07.514389 [debug] [Thread-1  ]: On model.maker_warehouse.total_unique_users: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_unique_users"} */
alter table "mydb"."dbt_warehouse"."total_unique_users" rename to "total_unique_users__dbt_backup"
[0m12:20:07.518630 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:20:07.526052 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.total_unique_users"
[0m12:20:07.527092 [debug] [Thread-1  ]: On model.maker_warehouse.total_unique_users: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_unique_users"} */
alter table "mydb"."dbt_warehouse"."total_unique_users__dbt_tmp" rename to "total_unique_users"
[0m12:20:07.531162 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:20:07.535210 [debug] [Thread-1  ]: On model.maker_warehouse.total_unique_users: COMMIT
[0m12:20:07.535870 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.total_unique_users"
[0m12:20:07.536439 [debug] [Thread-1  ]: On model.maker_warehouse.total_unique_users: COMMIT
[0m12:20:07.539908 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
[0m12:20:07.545995 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.total_unique_users"
[0m12:20:07.547427 [debug] [Thread-1  ]: On model.maker_warehouse.total_unique_users: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_unique_users"} */
drop table if exists "mydb"."dbt_warehouse"."total_unique_users__dbt_backup" cascade
[0m12:20:07.554433 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
[0m12:20:07.556924 [debug] [Thread-1  ]: Timing info for model.maker_warehouse.total_unique_users (execute): 12:20:02.307130 => 12:20:07.556597
[0m12:20:07.557616 [debug] [Thread-1  ]: On model.maker_warehouse.total_unique_users: Close
[0m12:20:07.559116 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7546e619-3c2b-440a-8c83-4794e575211f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1074f1490>]}
[0m12:20:07.560356 [info ] [Thread-1  ]: 6 of 10 OK created sql table model dbt_warehouse.total_unique_users ............ [[32mSELECT 1[0m in 5.27s]
[0m12:20:07.562449 [debug] [Thread-1  ]: Finished running node model.maker_warehouse.total_unique_users
[0m12:20:10.068528 [debug] [Thread-2  ]: SQL status: SELECT 161918 in 6.0 seconds
[0m12:20:10.074517 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.user_engagement"
[0m12:20:10.075181 [debug] [Thread-2  ]: On model.maker_warehouse.user_engagement: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.user_engagement"} */
alter table "mydb"."dbt_warehouse"."user_engagement" rename to "user_engagement__dbt_backup"
[0m12:20:10.078871 [debug] [Thread-2  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:20:10.085194 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.user_engagement"
[0m12:20:10.086048 [debug] [Thread-2  ]: On model.maker_warehouse.user_engagement: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.user_engagement"} */
alter table "mydb"."dbt_warehouse"."user_engagement__dbt_tmp" rename to "user_engagement"
[0m12:20:10.090407 [debug] [Thread-2  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:20:10.096481 [debug] [Thread-2  ]: On model.maker_warehouse.user_engagement: COMMIT
[0m12:20:10.097155 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.user_engagement"
[0m12:20:10.097742 [debug] [Thread-2  ]: On model.maker_warehouse.user_engagement: COMMIT
[0m12:20:10.108131 [debug] [Thread-2  ]: SQL status: COMMIT in 0.0 seconds
[0m12:20:10.112942 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.user_engagement"
[0m12:20:10.113613 [debug] [Thread-2  ]: On model.maker_warehouse.user_engagement: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.user_engagement"} */
drop table if exists "mydb"."dbt_warehouse"."user_engagement__dbt_backup" cascade
[0m12:20:10.125463 [debug] [Thread-2  ]: SQL status: DROP TABLE in 0.0 seconds
[0m12:20:10.129091 [debug] [Thread-2  ]: Timing info for model.maker_warehouse.user_engagement (execute): 12:20:03.769122 => 12:20:10.128329
[0m12:20:10.130432 [debug] [Thread-2  ]: On model.maker_warehouse.user_engagement: Close
[0m12:20:10.132430 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7546e619-3c2b-440a-8c83-4794e575211f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10761d610>]}
[0m12:20:10.134187 [info ] [Thread-2  ]: 9 of 10 OK created sql table model dbt_warehouse.user_engagement ............... [[32mSELECT 161918[0m in 6.38s]
[0m12:20:10.136551 [debug] [Thread-2  ]: Finished running node model.maker_warehouse.user_engagement
[0m12:20:10.141118 [debug] [MainThread]: Using postgres connection "master"
[0m12:20:10.142547 [debug] [MainThread]: On master: BEGIN
[0m12:20:10.143415 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m12:20:10.192049 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m12:20:10.193364 [debug] [MainThread]: On master: COMMIT
[0m12:20:10.195040 [debug] [MainThread]: Using postgres connection "master"
[0m12:20:10.195608 [debug] [MainThread]: On master: COMMIT
[0m12:20:10.197609 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m12:20:10.198236 [debug] [MainThread]: On master: Close
[0m12:20:10.199622 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:20:10.200188 [debug] [MainThread]: Connection 'model.maker_warehouse.total_unique_users' was properly closed.
[0m12:20:10.200660 [debug] [MainThread]: Connection 'model.maker_warehouse.user_engagement' was properly closed.
[0m12:20:10.201111 [debug] [MainThread]: Connection 'model.maker_warehouse.movies' was properly closed.
[0m12:20:10.201567 [debug] [MainThread]: Connection 'model.maker_warehouse.all_movies' was properly closed.
[0m12:20:10.202222 [info ] [MainThread]: 
[0m12:20:10.203667 [info ] [MainThread]: Finished running 3 view models, 7 table models in 0 hours 0 minutes and 10.23 seconds (10.23s).
[0m12:20:10.210512 [debug] [MainThread]: Command end result
[0m12:20:10.223504 [info ] [MainThread]: 
[0m12:20:10.224445 [info ] [MainThread]: [32mCompleted successfully[0m
[0m12:20:10.225117 [info ] [MainThread]: 
[0m12:20:10.225790 [info ] [MainThread]: Done. PASS=10 WARN=0 ERROR=0 SKIP=0 TOTAL=10
[0m12:20:10.227268 [debug] [MainThread]: Command `dbt run` succeeded at 12:20:10.227016 after 11.08 seconds
[0m12:20:10.228459 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105b202b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1074ea310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107363700>]}
[0m12:20:10.229571 [debug] [MainThread]: Flushing usage events
[0m12:29:30.836613 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e678e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fa14940>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c203b20>]}


============================== 12:29:30.847157 | bcc5688e-15f4-4218-b9fe-397e21edc6aa ==============================
[0m12:29:30.847157 [info ] [MainThread]: Running with dbt=1.5.4
[0m12:29:30.849528 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/Users/denisechan/Documents/Makers/Data_Engineering/Week_6/dbt_warehouse', 'log_path': '/Users/denisechan/Documents/Makers/Data_Engineering/Week_6/dbt_warehouse/logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'send_anonymous_usage_stats': 'True'}
[0m12:29:31.328256 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'bcc5688e-15f4-4218-b9fe-397e21edc6aa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c203b20>]}
[0m12:29:31.462908 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'bcc5688e-15f4-4218-b9fe-397e21edc6aa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fc77610>]}
[0m12:29:31.469516 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m12:29:31.873330 [debug] [MainThread]: checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, vars: {}, profile: , target: , version: 1.5.4
[0m12:29:32.333565 [debug] [MainThread]: Partial parsing enabled: 2 files deleted, 1 files added, 0 files changed.
[0m12:29:32.334410 [debug] [MainThread]: Partial parsing: added file: maker_warehouse://models/dimensions/movies.sql
[0m12:29:32.334969 [debug] [MainThread]: Partial parsing: deleted file: maker_warehouse://models/facts/movies.sql
[0m12:29:32.335639 [debug] [MainThread]: Partial parsing: deleted file: maker_warehouse://models/facts/all_movies.sql
[0m12:29:32.403585 [debug] [MainThread]: 1699: static parser successfully parsed dimensions/movies.sql
[0m12:29:32.444658 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'bcc5688e-15f4-4218-b9fe-397e21edc6aa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ff4aee0>]}
[0m12:29:32.461168 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'bcc5688e-15f4-4218-b9fe-397e21edc6aa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fe41bb0>]}
[0m12:29:32.462392 [info ] [MainThread]: Found 9 models, 0 tests, 0 snapshots, 0 analyses, 307 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics, 0 groups
[0m12:29:32.463481 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'bcc5688e-15f4-4218-b9fe-397e21edc6aa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fe41b20>]}
[0m12:29:32.466430 [info ] [MainThread]: 
[0m12:29:32.468050 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m12:29:32.470396 [debug] [ThreadPool]: Acquiring new postgres connection 'list_mydb'
[0m12:29:32.491990 [debug] [ThreadPool]: Using postgres connection "list_mydb"
[0m12:29:32.492648 [debug] [ThreadPool]: On list_mydb: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "connection_name": "list_mydb"} */

    select distinct nspname from pg_namespace
  
[0m12:29:32.493579 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:29:32.724041 [debug] [ThreadPool]: SQL status: SELECT 5 in 0.0 seconds
[0m12:29:32.727750 [debug] [ThreadPool]: On list_mydb: Close
[0m12:29:32.768471 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_mydb, now list_mydb_dbt_warehouse)
[0m12:29:32.785044 [debug] [ThreadPool]: Using postgres connection "list_mydb_dbt_warehouse"
[0m12:29:32.785982 [debug] [ThreadPool]: On list_mydb_dbt_warehouse: BEGIN
[0m12:29:32.787937 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:29:32.856887 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m12:29:32.857999 [debug] [ThreadPool]: Using postgres connection "list_mydb_dbt_warehouse"
[0m12:29:32.859002 [debug] [ThreadPool]: On list_mydb_dbt_warehouse: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "connection_name": "list_mydb_dbt_warehouse"} */
select
      'mydb' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_warehouse'
    union all
    select
      'mydb' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_warehouse'
  
[0m12:29:32.879168 [debug] [ThreadPool]: SQL status: SELECT 10 in 0.0 seconds
[0m12:29:32.883240 [debug] [ThreadPool]: On list_mydb_dbt_warehouse: ROLLBACK
[0m12:29:32.885738 [debug] [ThreadPool]: On list_mydb_dbt_warehouse: Close
[0m12:29:32.907732 [debug] [MainThread]: Using postgres connection "master"
[0m12:29:32.908504 [debug] [MainThread]: On master: BEGIN
[0m12:29:32.909346 [debug] [MainThread]: Opening a new connection, currently in state init
[0m12:29:33.048200 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m12:29:33.049465 [debug] [MainThread]: Using postgres connection "master"
[0m12:29:33.050294 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m12:29:33.088005 [debug] [MainThread]: SQL status: SELECT 8 in 0.0 seconds
[0m12:29:33.090635 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'bcc5688e-15f4-4218-b9fe-397e21edc6aa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ffe35e0>]}
[0m12:29:33.091400 [debug] [MainThread]: On master: ROLLBACK
[0m12:29:33.093721 [debug] [MainThread]: Using postgres connection "master"
[0m12:29:33.094331 [debug] [MainThread]: On master: BEGIN
[0m12:29:33.107506 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m12:29:33.108475 [debug] [MainThread]: On master: COMMIT
[0m12:29:33.109110 [debug] [MainThread]: Using postgres connection "master"
[0m12:29:33.115257 [debug] [MainThread]: On master: COMMIT
[0m12:29:33.118286 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m12:29:33.119182 [debug] [MainThread]: On master: Close
[0m12:29:33.120800 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m12:29:33.122783 [info ] [MainThread]: 
[0m12:29:33.156874 [debug] [Thread-1  ]: Began running node model.maker_warehouse.avg_duration_year_month
[0m12:29:33.158034 [debug] [Thread-2  ]: Began running node model.maker_warehouse.avg_viewing_time
[0m12:29:33.158881 [debug] [Thread-3  ]: Began running node model.maker_warehouse.movies
[0m12:29:33.159866 [debug] [Thread-4  ]: Began running node model.maker_warehouse.no_of_viewings
[0m12:29:33.160882 [info ] [Thread-1  ]: 1 of 9 START sql view model dbt_warehouse.avg_duration_year_month .............. [RUN]
[0m12:29:33.162861 [info ] [Thread-2  ]: 2 of 9 START sql table model dbt_warehouse.avg_viewing_time .................... [RUN]
[0m12:29:33.164160 [info ] [Thread-3  ]: 3 of 9 START sql table model dbt_warehouse.movies .............................. [RUN]
[0m12:29:33.166019 [info ] [Thread-4  ]: 4 of 9 START sql table model dbt_warehouse.no_of_viewings ...................... [RUN]
[0m12:29:33.167958 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_mydb_dbt_warehouse, now model.maker_warehouse.avg_duration_year_month)
[0m12:29:33.169352 [debug] [Thread-2  ]: Acquiring new postgres connection 'model.maker_warehouse.avg_viewing_time'
[0m12:29:33.171958 [debug] [Thread-3  ]: Acquiring new postgres connection 'model.maker_warehouse.movies'
[0m12:29:33.174826 [debug] [Thread-4  ]: Acquiring new postgres connection 'model.maker_warehouse.no_of_viewings'
[0m12:29:33.175586 [debug] [Thread-1  ]: Began compiling node model.maker_warehouse.avg_duration_year_month
[0m12:29:33.176638 [debug] [Thread-2  ]: Began compiling node model.maker_warehouse.avg_viewing_time
[0m12:29:33.177377 [debug] [Thread-3  ]: Began compiling node model.maker_warehouse.movies
[0m12:29:33.178564 [debug] [Thread-4  ]: Began compiling node model.maker_warehouse.no_of_viewings
[0m12:29:33.199547 [debug] [Thread-1  ]: Writing injected SQL for node "model.maker_warehouse.avg_duration_year_month"
[0m12:29:33.213513 [debug] [Thread-3  ]: Writing injected SQL for node "model.maker_warehouse.movies"
[0m12:29:33.217833 [debug] [Thread-2  ]: Writing injected SQL for node "model.maker_warehouse.avg_viewing_time"
[0m12:29:33.226097 [debug] [Thread-4  ]: Writing injected SQL for node "model.maker_warehouse.no_of_viewings"
[0m12:29:33.235056 [debug] [Thread-1  ]: Timing info for model.maker_warehouse.avg_duration_year_month (compile): 12:29:33.181520 => 12:29:33.234583
[0m12:29:33.236365 [debug] [Thread-3  ]: Timing info for model.maker_warehouse.movies (compile): 12:29:33.205698 => 12:29:33.235696
[0m12:29:33.237251 [debug] [Thread-2  ]: Timing info for model.maker_warehouse.avg_viewing_time (compile): 12:29:33.200239 => 12:29:33.236911
[0m12:29:33.238917 [debug] [Thread-1  ]: Began executing node model.maker_warehouse.avg_duration_year_month
[0m12:29:33.240469 [debug] [Thread-3  ]: Began executing node model.maker_warehouse.movies
[0m12:29:33.242062 [debug] [Thread-4  ]: Timing info for model.maker_warehouse.no_of_viewings (compile): 12:29:33.218626 => 12:29:33.241372
[0m12:29:33.243280 [debug] [Thread-2  ]: Began executing node model.maker_warehouse.avg_viewing_time
[0m12:29:33.327315 [debug] [Thread-4  ]: Began executing node model.maker_warehouse.no_of_viewings
[0m12:29:33.405734 [debug] [Thread-1  ]: Writing runtime sql for node "model.maker_warehouse.avg_duration_year_month"
[0m12:29:33.423597 [debug] [Thread-2  ]: Writing runtime sql for node "model.maker_warehouse.avg_viewing_time"
[0m12:29:33.427406 [debug] [Thread-3  ]: Writing runtime sql for node "model.maker_warehouse.movies"
[0m12:29:33.434937 [debug] [Thread-4  ]: Writing runtime sql for node "model.maker_warehouse.no_of_viewings"
[0m12:29:33.438210 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.avg_duration_year_month"
[0m12:29:33.439237 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.avg_viewing_time"
[0m12:29:33.440000 [debug] [Thread-1  ]: On model.maker_warehouse.avg_duration_year_month: BEGIN
[0m12:29:33.440906 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.movies"
[0m12:29:33.441834 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.no_of_viewings"
[0m12:29:33.442462 [debug] [Thread-2  ]: On model.maker_warehouse.avg_viewing_time: BEGIN
[0m12:29:33.445105 [debug] [Thread-2  ]: Opening a new connection, currently in state init
[0m12:29:33.443178 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m12:29:33.444389 [debug] [Thread-4  ]: On model.maker_warehouse.no_of_viewings: BEGIN
[0m12:29:33.447597 [debug] [Thread-4  ]: Opening a new connection, currently in state init
[0m12:29:33.443761 [debug] [Thread-3  ]: On model.maker_warehouse.movies: BEGIN
[0m12:29:33.448858 [debug] [Thread-3  ]: Opening a new connection, currently in state init
[0m12:29:33.510526 [debug] [Thread-3  ]: SQL status: BEGIN in 0.0 seconds
[0m12:29:33.511918 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.movies"
[0m12:29:33.512670 [debug] [Thread-3  ]: On model.maker_warehouse.movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.movies"} */

  
    

  create  table "mydb"."dbt_warehouse"."movies__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    DISTINCT
    title,
    genres,
    release_date,
    movie_id
FROM mydb.public.raw_netflix
  );
  
[0m12:29:33.513854 [debug] [Thread-2  ]: SQL status: BEGIN in 0.0 seconds
[0m12:29:33.515168 [debug] [Thread-4  ]: SQL status: BEGIN in 0.0 seconds
[0m12:29:33.517054 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.avg_viewing_time"
[0m12:29:33.518175 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.no_of_viewings"
[0m12:29:33.522294 [debug] [Thread-2  ]: On model.maker_warehouse.avg_viewing_time: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.avg_viewing_time"} */

  
    

  create  table "mydb"."dbt_warehouse"."avg_viewing_time__dbt_tmp"
  
  
    as
  
  (
    
SELECT
title,
ROUND(CAST(AVG(duration) AS NUMERIC), 2) as avg_duration
FROM mydb.public.raw_netflix
GROUP BY title
ORDER BY avg_duration DESC
  );
  
[0m12:29:33.523488 [debug] [Thread-4  ]: On model.maker_warehouse.no_of_viewings: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.no_of_viewings"} */

  
    

  create  table "mydb"."dbt_warehouse"."no_of_viewings__dbt_tmp"
  
  
    as
  
  (
    
SELECT
  title,
  COUNT(*) as total_views
FROM mydb.public.raw_netflix
GROUP BY title
ORDER BY total_views DESC
  );
  
[0m12:29:33.525591 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
[0m12:29:33.526871 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.avg_duration_year_month"
[0m12:29:33.530456 [debug] [Thread-1  ]: On model.maker_warehouse.avg_duration_year_month: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.avg_duration_year_month"} */

  create view "mydb"."dbt_warehouse"."avg_duration_year_month__dbt_tmp"
    
    
  as (
    
SELECT
    EXTRACT(YEAR FROM CAST("datetime" AS DATE)) AS "Year",
    EXTRACT(MONTH FROM CAST("datetime" AS DATE)) AS "Month",
    ROUND(CAST(AVG(duration) AS NUMERIC), 2) AS "Average_Duration"
FROM
    mydb.public.raw_netflix
GROUP BY
    EXTRACT(YEAR FROM CAST("datetime" AS DATE)),
    EXTRACT(MONTH FROM CAST("datetime" AS DATE))
ORDER BY
    "Year", "Month"
  );
[0m12:29:33.557924 [debug] [Thread-1  ]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:29:33.577952 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.avg_duration_year_month"
[0m12:29:33.579181 [debug] [Thread-1  ]: On model.maker_warehouse.avg_duration_year_month: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.avg_duration_year_month"} */
alter table "mydb"."dbt_warehouse"."avg_duration_year_month" rename to "avg_duration_year_month__dbt_backup"
[0m12:29:33.588442 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:29:33.644707 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.avg_duration_year_month"
[0m12:29:33.646178 [debug] [Thread-1  ]: On model.maker_warehouse.avg_duration_year_month: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.avg_duration_year_month"} */
alter table "mydb"."dbt_warehouse"."avg_duration_year_month__dbt_tmp" rename to "avg_duration_year_month"
[0m12:29:33.651675 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:29:33.725810 [debug] [Thread-1  ]: On model.maker_warehouse.avg_duration_year_month: COMMIT
[0m12:29:33.727259 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.avg_duration_year_month"
[0m12:29:33.728705 [debug] [Thread-1  ]: On model.maker_warehouse.avg_duration_year_month: COMMIT
[0m12:29:33.733100 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
[0m12:29:33.753696 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.avg_duration_year_month"
[0m12:29:33.754556 [debug] [Thread-1  ]: On model.maker_warehouse.avg_duration_year_month: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.avg_duration_year_month"} */
drop view if exists "mydb"."dbt_warehouse"."avg_duration_year_month__dbt_backup" cascade
[0m12:29:33.773078 [debug] [Thread-1  ]: SQL status: DROP VIEW in 0.0 seconds
[0m12:29:33.777490 [debug] [Thread-1  ]: Timing info for model.maker_warehouse.avg_duration_year_month (execute): 12:29:33.243886 => 12:29:33.777008
[0m12:29:33.778485 [debug] [Thread-1  ]: On model.maker_warehouse.avg_duration_year_month: Close
[0m12:29:33.781079 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bcc5688e-15f4-4218-b9fe-397e21edc6aa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1100885b0>]}
[0m12:29:33.783885 [info ] [Thread-1  ]: 1 of 9 OK created sql view model dbt_warehouse.avg_duration_year_month ......... [[32mCREATE VIEW[0m in 0.61s]
[0m12:29:33.786445 [debug] [Thread-1  ]: Finished running node model.maker_warehouse.avg_duration_year_month
[0m12:29:33.787505 [debug] [Thread-1  ]: Began running node model.maker_warehouse.total_duration_year_month
[0m12:29:33.788512 [info ] [Thread-1  ]: 5 of 9 START sql view model dbt_warehouse.total_duration_year_month ............ [RUN]
[0m12:29:33.792013 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.maker_warehouse.avg_duration_year_month, now model.maker_warehouse.total_duration_year_month)
[0m12:29:33.793575 [debug] [Thread-1  ]: Began compiling node model.maker_warehouse.total_duration_year_month
[0m12:29:33.826076 [debug] [Thread-1  ]: Writing injected SQL for node "model.maker_warehouse.total_duration_year_month"
[0m12:29:33.829947 [debug] [Thread-1  ]: Timing info for model.maker_warehouse.total_duration_year_month (compile): 12:29:33.794892 => 12:29:33.828083
[0m12:29:33.833643 [debug] [Thread-1  ]: Began executing node model.maker_warehouse.total_duration_year_month
[0m12:29:33.865708 [debug] [Thread-1  ]: Writing runtime sql for node "model.maker_warehouse.total_duration_year_month"
[0m12:29:33.867918 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.total_duration_year_month"
[0m12:29:33.869579 [debug] [Thread-1  ]: On model.maker_warehouse.total_duration_year_month: BEGIN
[0m12:29:33.870621 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m12:29:33.945708 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
[0m12:29:33.948339 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.total_duration_year_month"
[0m12:29:33.949616 [debug] [Thread-1  ]: On model.maker_warehouse.total_duration_year_month: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_duration_year_month"} */

  create view "mydb"."dbt_warehouse"."total_duration_year_month__dbt_tmp"
    
    
  as (
    
SELECT
    EXTRACT(YEAR FROM CAST("datetime" AS DATE)) AS "Year",
    EXTRACT(MONTH FROM CAST("datetime" AS DATE)) AS "Month",
    SUM(duration) AS "Total_Duration"
FROM
    mydb.public.raw_netflix
GROUP BY
    EXTRACT(YEAR FROM CAST("datetime" AS DATE)),
    EXTRACT(MONTH FROM CAST("datetime" AS DATE))
ORDER BY
    "Year", "Month"
  );
[0m12:29:34.009515 [debug] [Thread-1  ]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:29:34.024132 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.total_duration_year_month"
[0m12:29:34.025420 [debug] [Thread-1  ]: On model.maker_warehouse.total_duration_year_month: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_duration_year_month"} */
alter table "mydb"."dbt_warehouse"."total_duration_year_month" rename to "total_duration_year_month__dbt_backup"
[0m12:29:34.029769 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:29:34.040802 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.total_duration_year_month"
[0m12:29:34.042537 [debug] [Thread-1  ]: On model.maker_warehouse.total_duration_year_month: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_duration_year_month"} */
alter table "mydb"."dbt_warehouse"."total_duration_year_month__dbt_tmp" rename to "total_duration_year_month"
[0m12:29:34.046277 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:29:34.053520 [debug] [Thread-1  ]: On model.maker_warehouse.total_duration_year_month: COMMIT
[0m12:29:34.054736 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.total_duration_year_month"
[0m12:29:34.056214 [debug] [Thread-1  ]: On model.maker_warehouse.total_duration_year_month: COMMIT
[0m12:29:34.060072 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
[0m12:29:34.069329 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.total_duration_year_month"
[0m12:29:34.070700 [debug] [Thread-1  ]: On model.maker_warehouse.total_duration_year_month: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_duration_year_month"} */
drop view if exists "mydb"."dbt_warehouse"."total_duration_year_month__dbt_backup" cascade
[0m12:29:34.084350 [debug] [Thread-1  ]: SQL status: DROP VIEW in 0.0 seconds
[0m12:29:34.088582 [debug] [Thread-1  ]: Timing info for model.maker_warehouse.total_duration_year_month (execute): 12:29:33.834678 => 12:29:34.088015
[0m12:29:34.089776 [debug] [Thread-1  ]: On model.maker_warehouse.total_duration_year_month: Close
[0m12:29:34.091495 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bcc5688e-15f4-4218-b9fe-397e21edc6aa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fe90970>]}
[0m12:29:34.093222 [info ] [Thread-1  ]: 5 of 9 OK created sql view model dbt_warehouse.total_duration_year_month ....... [[32mCREATE VIEW[0m in 0.30s]
[0m12:29:34.095600 [debug] [Thread-1  ]: Finished running node model.maker_warehouse.total_duration_year_month
[0m12:29:34.097243 [debug] [Thread-1  ]: Began running node model.maker_warehouse.total_unique_users
[0m12:29:34.099280 [info ] [Thread-1  ]: 6 of 9 START sql table model dbt_warehouse.total_unique_users .................. [RUN]
[0m12:29:34.104574 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.maker_warehouse.total_duration_year_month, now model.maker_warehouse.total_unique_users)
[0m12:29:34.105974 [debug] [Thread-1  ]: Began compiling node model.maker_warehouse.total_unique_users
[0m12:29:34.117258 [debug] [Thread-1  ]: Writing injected SQL for node "model.maker_warehouse.total_unique_users"
[0m12:29:34.122004 [debug] [Thread-1  ]: Timing info for model.maker_warehouse.total_unique_users (compile): 12:29:34.106694 => 12:29:34.118929
[0m12:29:34.123787 [debug] [Thread-1  ]: Began executing node model.maker_warehouse.total_unique_users
[0m12:29:34.159101 [debug] [Thread-1  ]: Writing runtime sql for node "model.maker_warehouse.total_unique_users"
[0m12:29:34.161854 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.total_unique_users"
[0m12:29:34.163625 [debug] [Thread-1  ]: On model.maker_warehouse.total_unique_users: BEGIN
[0m12:29:34.164889 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m12:29:34.332716 [debug] [Thread-1  ]: SQL status: BEGIN in 0.0 seconds
[0m12:29:34.334274 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.total_unique_users"
[0m12:29:34.334929 [debug] [Thread-1  ]: On model.maker_warehouse.total_unique_users: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_unique_users"} */

  
    

  create  table "mydb"."dbt_warehouse"."total_unique_users__dbt_tmp"
  
  
    as
  
  (
    
SELECT 
COUNT(DISTINCT(user_id)) AS total_unique_users
FROM mydb.public.raw_netflix
  );
  
[0m12:29:35.787964 [debug] [Thread-4  ]: SQL status: SELECT 7925 in 2.0 seconds
[0m12:29:35.798682 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.no_of_viewings"
[0m12:29:35.799529 [debug] [Thread-4  ]: On model.maker_warehouse.no_of_viewings: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.no_of_viewings"} */
alter table "mydb"."dbt_warehouse"."no_of_viewings" rename to "no_of_viewings__dbt_backup"
[0m12:29:35.809744 [debug] [Thread-4  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:29:35.823838 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.no_of_viewings"
[0m12:29:35.825556 [debug] [Thread-4  ]: On model.maker_warehouse.no_of_viewings: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.no_of_viewings"} */
alter table "mydb"."dbt_warehouse"."no_of_viewings__dbt_tmp" rename to "no_of_viewings"
[0m12:29:35.836827 [debug] [Thread-4  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:29:35.857582 [debug] [Thread-4  ]: On model.maker_warehouse.no_of_viewings: COMMIT
[0m12:29:35.863673 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.no_of_viewings"
[0m12:29:35.865442 [debug] [Thread-4  ]: On model.maker_warehouse.no_of_viewings: COMMIT
[0m12:29:35.870095 [debug] [Thread-4  ]: SQL status: COMMIT in 0.0 seconds
[0m12:29:35.883472 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.no_of_viewings"
[0m12:29:35.884276 [debug] [Thread-4  ]: On model.maker_warehouse.no_of_viewings: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.no_of_viewings"} */
drop table if exists "mydb"."dbt_warehouse"."no_of_viewings__dbt_backup" cascade
[0m12:29:36.225097 [debug] [Thread-4  ]: SQL status: DROP TABLE in 0.0 seconds
[0m12:29:36.230071 [debug] [Thread-4  ]: Timing info for model.maker_warehouse.no_of_viewings (execute): 12:29:33.427877 => 12:29:36.229319
[0m12:29:36.232790 [debug] [Thread-4  ]: On model.maker_warehouse.no_of_viewings: Close
[0m12:29:36.235770 [debug] [Thread-4  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bcc5688e-15f4-4218-b9fe-397e21edc6aa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1100e5c40>]}
[0m12:29:36.238138 [info ] [Thread-4  ]: 4 of 9 OK created sql table model dbt_warehouse.no_of_viewings ................. [[32mSELECT 7925[0m in 3.06s]
[0m12:29:36.241731 [debug] [Thread-4  ]: Finished running node model.maker_warehouse.no_of_viewings
[0m12:29:36.243905 [debug] [Thread-4  ]: Began running node model.maker_warehouse.total_viewing_time
[0m12:29:36.245250 [info ] [Thread-4  ]: 7 of 9 START sql table model dbt_warehouse.total_viewing_time .................. [RUN]
[0m12:29:36.247424 [debug] [Thread-4  ]: Re-using an available connection from the pool (formerly model.maker_warehouse.no_of_viewings, now model.maker_warehouse.total_viewing_time)
[0m12:29:36.248989 [debug] [Thread-4  ]: Began compiling node model.maker_warehouse.total_viewing_time
[0m12:29:36.259731 [debug] [Thread-4  ]: Writing injected SQL for node "model.maker_warehouse.total_viewing_time"
[0m12:29:36.263623 [debug] [Thread-4  ]: Timing info for model.maker_warehouse.total_viewing_time (compile): 12:29:36.249794 => 12:29:36.263057
[0m12:29:36.264337 [debug] [Thread-4  ]: Began executing node model.maker_warehouse.total_viewing_time
[0m12:29:36.283299 [debug] [Thread-4  ]: Writing runtime sql for node "model.maker_warehouse.total_viewing_time"
[0m12:29:36.290558 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.total_viewing_time"
[0m12:29:36.292369 [debug] [Thread-4  ]: On model.maker_warehouse.total_viewing_time: BEGIN
[0m12:29:36.293491 [debug] [Thread-4  ]: Opening a new connection, currently in state closed
[0m12:29:36.421307 [debug] [Thread-4  ]: SQL status: BEGIN in 0.0 seconds
[0m12:29:36.423106 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.total_viewing_time"
[0m12:29:36.424726 [debug] [Thread-4  ]: On model.maker_warehouse.total_viewing_time: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_viewing_time"} */

  
    

  create  table "mydb"."dbt_warehouse"."total_viewing_time__dbt_tmp"
  
  
    as
  
  (
    
SELECT
title,
SUM(duration) as total_duration
FROM mydb.public.raw_netflix
GROUP BY title
ORDER BY total_duration DESC
  );
  
[0m12:29:36.665624 [debug] [Thread-2  ]: SQL status: SELECT 7925 in 3.0 seconds
[0m12:29:36.675306 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.avg_viewing_time"
[0m12:29:36.676532 [debug] [Thread-2  ]: On model.maker_warehouse.avg_viewing_time: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.avg_viewing_time"} */
alter table "mydb"."dbt_warehouse"."avg_viewing_time" rename to "avg_viewing_time__dbt_backup"
[0m12:29:36.686995 [debug] [Thread-2  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:29:36.695097 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.avg_viewing_time"
[0m12:29:36.696755 [debug] [Thread-2  ]: On model.maker_warehouse.avg_viewing_time: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.avg_viewing_time"} */
alter table "mydb"."dbt_warehouse"."avg_viewing_time__dbt_tmp" rename to "avg_viewing_time"
[0m12:29:36.700878 [debug] [Thread-2  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:29:36.708505 [debug] [Thread-2  ]: On model.maker_warehouse.avg_viewing_time: COMMIT
[0m12:29:36.709227 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.avg_viewing_time"
[0m12:29:36.710272 [debug] [Thread-2  ]: On model.maker_warehouse.avg_viewing_time: COMMIT
[0m12:29:36.716756 [debug] [Thread-2  ]: SQL status: COMMIT in 0.0 seconds
[0m12:29:36.725405 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.avg_viewing_time"
[0m12:29:36.726816 [debug] [Thread-2  ]: On model.maker_warehouse.avg_viewing_time: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.avg_viewing_time"} */
drop table if exists "mydb"."dbt_warehouse"."avg_viewing_time__dbt_backup" cascade
[0m12:29:36.850521 [debug] [Thread-2  ]: SQL status: DROP TABLE in 0.0 seconds
[0m12:29:36.854886 [debug] [Thread-2  ]: Timing info for model.maker_warehouse.avg_viewing_time (execute): 12:29:33.375226 => 12:29:36.854230
[0m12:29:36.856087 [debug] [Thread-2  ]: On model.maker_warehouse.avg_viewing_time: Close
[0m12:29:36.858795 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bcc5688e-15f4-4218-b9fe-397e21edc6aa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11006e3d0>]}
[0m12:29:36.864093 [info ] [Thread-2  ]: 2 of 9 OK created sql table model dbt_warehouse.avg_viewing_time ............... [[32mSELECT 7925[0m in 3.69s]
[0m12:29:36.866605 [debug] [Thread-2  ]: Finished running node model.maker_warehouse.avg_viewing_time
[0m12:29:36.868132 [debug] [Thread-2  ]: Began running node model.maker_warehouse.total_viewings_year_month
[0m12:29:36.870994 [info ] [Thread-2  ]: 8 of 9 START sql view model dbt_warehouse.total_viewings_year_month ............ [RUN]
[0m12:29:36.874960 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly model.maker_warehouse.avg_viewing_time, now model.maker_warehouse.total_viewings_year_month)
[0m12:29:36.877064 [debug] [Thread-2  ]: Began compiling node model.maker_warehouse.total_viewings_year_month
[0m12:29:36.888862 [debug] [Thread-2  ]: Writing injected SQL for node "model.maker_warehouse.total_viewings_year_month"
[0m12:29:36.892884 [debug] [Thread-2  ]: Timing info for model.maker_warehouse.total_viewings_year_month (compile): 12:29:36.878128 => 12:29:36.892270
[0m12:29:36.894114 [debug] [Thread-2  ]: Began executing node model.maker_warehouse.total_viewings_year_month
[0m12:29:36.912648 [debug] [Thread-2  ]: Writing runtime sql for node "model.maker_warehouse.total_viewings_year_month"
[0m12:29:36.917091 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.total_viewings_year_month"
[0m12:29:36.918453 [debug] [Thread-2  ]: On model.maker_warehouse.total_viewings_year_month: BEGIN
[0m12:29:36.919494 [debug] [Thread-2  ]: Opening a new connection, currently in state closed
[0m12:29:37.079829 [debug] [Thread-2  ]: SQL status: BEGIN in 0.0 seconds
[0m12:29:37.082330 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.total_viewings_year_month"
[0m12:29:37.083504 [debug] [Thread-2  ]: On model.maker_warehouse.total_viewings_year_month: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_viewings_year_month"} */

  create view "mydb"."dbt_warehouse"."total_viewings_year_month__dbt_tmp"
    
    
  as (
    
SELECT
    EXTRACT(YEAR FROM CAST("datetime" AS DATE)) AS "Year",
    EXTRACT(MONTH FROM CAST("datetime" AS DATE)) AS "Month",
    COUNT(*) AS "Total_Views"
FROM mydb.public.raw_netflix
GROUP BY
    EXTRACT(YEAR FROM CAST("datetime" AS DATE)),
    EXTRACT(MONTH FROM CAST("datetime" AS DATE))
ORDER BY
    "Year", "Month"
  );
[0m12:29:37.167562 [debug] [Thread-2  ]: SQL status: CREATE VIEW in 0.0 seconds
[0m12:29:37.179824 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.total_viewings_year_month"
[0m12:29:37.181857 [debug] [Thread-2  ]: On model.maker_warehouse.total_viewings_year_month: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_viewings_year_month"} */
alter table "mydb"."dbt_warehouse"."total_viewings_year_month" rename to "total_viewings_year_month__dbt_backup"
[0m12:29:37.275687 [debug] [Thread-2  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:29:37.289633 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.total_viewings_year_month"
[0m12:29:37.291490 [debug] [Thread-2  ]: On model.maker_warehouse.total_viewings_year_month: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_viewings_year_month"} */
alter table "mydb"."dbt_warehouse"."total_viewings_year_month__dbt_tmp" rename to "total_viewings_year_month"
[0m12:29:37.299479 [debug] [Thread-2  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:29:37.306492 [debug] [Thread-2  ]: On model.maker_warehouse.total_viewings_year_month: COMMIT
[0m12:29:37.307897 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.total_viewings_year_month"
[0m12:29:37.309309 [debug] [Thread-2  ]: On model.maker_warehouse.total_viewings_year_month: COMMIT
[0m12:29:37.314317 [debug] [Thread-2  ]: SQL status: COMMIT in 0.0 seconds
[0m12:29:37.325706 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.total_viewings_year_month"
[0m12:29:37.327208 [debug] [Thread-2  ]: On model.maker_warehouse.total_viewings_year_month: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_viewings_year_month"} */
drop view if exists "mydb"."dbt_warehouse"."total_viewings_year_month__dbt_backup" cascade
[0m12:29:37.403860 [debug] [Thread-2  ]: SQL status: DROP VIEW in 0.0 seconds
[0m12:29:37.407515 [debug] [Thread-2  ]: Timing info for model.maker_warehouse.total_viewings_year_month (execute): 12:29:36.894866 => 12:29:37.407152
[0m12:29:37.408229 [debug] [Thread-2  ]: On model.maker_warehouse.total_viewings_year_month: Close
[0m12:29:37.410379 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bcc5688e-15f4-4218-b9fe-397e21edc6aa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11018dfa0>]}
[0m12:29:37.412104 [info ] [Thread-2  ]: 8 of 9 OK created sql view model dbt_warehouse.total_viewings_year_month ....... [[32mCREATE VIEW[0m in 0.54s]
[0m12:29:37.414459 [debug] [Thread-2  ]: Finished running node model.maker_warehouse.total_viewings_year_month
[0m12:29:37.416341 [debug] [Thread-2  ]: Began running node model.maker_warehouse.user_engagement
[0m12:29:37.419759 [info ] [Thread-2  ]: 9 of 9 START sql table model dbt_warehouse.user_engagement ..................... [RUN]
[0m12:29:37.424733 [debug] [Thread-2  ]: Re-using an available connection from the pool (formerly model.maker_warehouse.total_viewings_year_month, now model.maker_warehouse.user_engagement)
[0m12:29:37.425674 [debug] [Thread-2  ]: Began compiling node model.maker_warehouse.user_engagement
[0m12:29:37.485063 [debug] [Thread-2  ]: Writing injected SQL for node "model.maker_warehouse.user_engagement"
[0m12:29:37.503672 [debug] [Thread-2  ]: Timing info for model.maker_warehouse.user_engagement (compile): 12:29:37.426263 => 12:29:37.502824
[0m12:29:37.509208 [debug] [Thread-2  ]: Began executing node model.maker_warehouse.user_engagement
[0m12:29:37.531281 [debug] [Thread-2  ]: Writing runtime sql for node "model.maker_warehouse.user_engagement"
[0m12:29:37.532943 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.user_engagement"
[0m12:29:37.534301 [debug] [Thread-2  ]: On model.maker_warehouse.user_engagement: BEGIN
[0m12:29:37.535769 [debug] [Thread-2  ]: Opening a new connection, currently in state closed
[0m12:29:37.651584 [debug] [Thread-2  ]: SQL status: BEGIN in 0.0 seconds
[0m12:29:37.652876 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.user_engagement"
[0m12:29:37.654204 [debug] [Thread-2  ]: On model.maker_warehouse.user_engagement: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.user_engagement"} */

  
    

  create  table "mydb"."dbt_warehouse"."user_engagement__dbt_tmp"
  
  
    as
  
  (
    
SELECT 
DISTINCT(user_id),
COUNT(DISTINCT(title)) AS total_titles,
SUM(duration) AS total_duration
FROM mydb.public.raw_netflix
GROUP BY user_id
  );
  
[0m12:29:38.112639 [debug] [Thread-4  ]: SQL status: SELECT 7925 in 2.0 seconds
[0m12:29:38.122767 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.total_viewing_time"
[0m12:29:38.125313 [debug] [Thread-4  ]: On model.maker_warehouse.total_viewing_time: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_viewing_time"} */
alter table "mydb"."dbt_warehouse"."total_viewing_time" rename to "total_viewing_time__dbt_backup"
[0m12:29:38.138300 [debug] [Thread-4  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:29:38.147111 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.total_viewing_time"
[0m12:29:38.147801 [debug] [Thread-4  ]: On model.maker_warehouse.total_viewing_time: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_viewing_time"} */
alter table "mydb"."dbt_warehouse"."total_viewing_time__dbt_tmp" rename to "total_viewing_time"
[0m12:29:38.158213 [debug] [Thread-4  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:29:38.166334 [debug] [Thread-4  ]: On model.maker_warehouse.total_viewing_time: COMMIT
[0m12:29:38.167173 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.total_viewing_time"
[0m12:29:38.167762 [debug] [Thread-4  ]: On model.maker_warehouse.total_viewing_time: COMMIT
[0m12:29:38.188126 [debug] [Thread-4  ]: SQL status: COMMIT in 0.0 seconds
[0m12:29:38.195560 [debug] [Thread-4  ]: Using postgres connection "model.maker_warehouse.total_viewing_time"
[0m12:29:38.196576 [debug] [Thread-4  ]: On model.maker_warehouse.total_viewing_time: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_viewing_time"} */
drop table if exists "mydb"."dbt_warehouse"."total_viewing_time__dbt_backup" cascade
[0m12:29:38.212230 [debug] [Thread-4  ]: SQL status: DROP TABLE in 0.0 seconds
[0m12:29:38.216532 [debug] [Thread-4  ]: Timing info for model.maker_warehouse.total_viewing_time (execute): 12:29:36.264887 => 12:29:38.215977
[0m12:29:38.217207 [debug] [Thread-4  ]: On model.maker_warehouse.total_viewing_time: Close
[0m12:29:38.218849 [debug] [Thread-4  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bcc5688e-15f4-4218-b9fe-397e21edc6aa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11012ac10>]}
[0m12:29:38.220434 [info ] [Thread-4  ]: 7 of 9 OK created sql table model dbt_warehouse.total_viewing_time ............. [[32mSELECT 7925[0m in 1.97s]
[0m12:29:38.222419 [debug] [Thread-4  ]: Finished running node model.maker_warehouse.total_viewing_time
[0m12:29:39.261924 [debug] [Thread-3  ]: SQL status: SELECT 8472 in 6.0 seconds
[0m12:29:39.272700 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.movies"
[0m12:29:39.273530 [debug] [Thread-3  ]: On model.maker_warehouse.movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.movies"} */
alter table "mydb"."dbt_warehouse"."movies" rename to "movies__dbt_backup"
[0m12:29:39.277938 [debug] [Thread-3  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:29:39.286900 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.movies"
[0m12:29:39.288317 [debug] [Thread-3  ]: On model.maker_warehouse.movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.movies"} */
alter table "mydb"."dbt_warehouse"."movies__dbt_tmp" rename to "movies"
[0m12:29:39.295624 [debug] [Thread-3  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:29:39.302899 [debug] [Thread-3  ]: On model.maker_warehouse.movies: COMMIT
[0m12:29:39.304028 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.movies"
[0m12:29:39.305027 [debug] [Thread-3  ]: On model.maker_warehouse.movies: COMMIT
[0m12:29:39.309859 [debug] [Thread-3  ]: SQL status: COMMIT in 0.0 seconds
[0m12:29:39.336708 [debug] [Thread-3  ]: Using postgres connection "model.maker_warehouse.movies"
[0m12:29:39.337678 [debug] [Thread-3  ]: On model.maker_warehouse.movies: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.movies"} */
drop table if exists "mydb"."dbt_warehouse"."movies__dbt_backup" cascade
[0m12:29:39.367035 [debug] [Thread-3  ]: SQL status: DROP TABLE in 0.0 seconds
[0m12:29:39.370681 [debug] [Thread-3  ]: Timing info for model.maker_warehouse.movies (execute): 12:29:33.272586 => 12:29:39.370318
[0m12:29:39.371729 [debug] [Thread-3  ]: On model.maker_warehouse.movies: Close
[0m12:29:39.374195 [debug] [Thread-3  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bcc5688e-15f4-4218-b9fe-397e21edc6aa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11005e970>]}
[0m12:29:39.375877 [info ] [Thread-3  ]: 3 of 9 OK created sql table model dbt_warehouse.movies ......................... [[32mSELECT 8472[0m in 6.20s]
[0m12:29:39.379300 [debug] [Thread-3  ]: Finished running node model.maker_warehouse.movies
[0m12:29:43.851908 [debug] [Thread-1  ]: SQL status: SELECT 1 in 10.0 seconds
[0m12:29:43.859718 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.total_unique_users"
[0m12:29:43.860806 [debug] [Thread-1  ]: On model.maker_warehouse.total_unique_users: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_unique_users"} */
alter table "mydb"."dbt_warehouse"."total_unique_users" rename to "total_unique_users__dbt_backup"
[0m12:29:43.865693 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:29:43.872145 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.total_unique_users"
[0m12:29:43.872953 [debug] [Thread-1  ]: On model.maker_warehouse.total_unique_users: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_unique_users"} */
alter table "mydb"."dbt_warehouse"."total_unique_users__dbt_tmp" rename to "total_unique_users"
[0m12:29:43.875701 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:29:43.880092 [debug] [Thread-1  ]: On model.maker_warehouse.total_unique_users: COMMIT
[0m12:29:43.881447 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.total_unique_users"
[0m12:29:43.882541 [debug] [Thread-1  ]: On model.maker_warehouse.total_unique_users: COMMIT
[0m12:29:43.899686 [debug] [Thread-1  ]: SQL status: COMMIT in 0.0 seconds
[0m12:29:43.907727 [debug] [Thread-1  ]: Using postgres connection "model.maker_warehouse.total_unique_users"
[0m12:29:43.910073 [debug] [Thread-1  ]: On model.maker_warehouse.total_unique_users: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.total_unique_users"} */
drop table if exists "mydb"."dbt_warehouse"."total_unique_users__dbt_backup" cascade
[0m12:29:44.139354 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.0 seconds
[0m12:29:44.144688 [debug] [Thread-1  ]: Timing info for model.maker_warehouse.total_unique_users (execute): 12:29:34.124620 => 12:29:44.143672
[0m12:29:44.145509 [debug] [Thread-1  ]: On model.maker_warehouse.total_unique_users: Close
[0m12:29:44.147392 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bcc5688e-15f4-4218-b9fe-397e21edc6aa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11001b040>]}
[0m12:29:44.149099 [info ] [Thread-1  ]: 6 of 9 OK created sql table model dbt_warehouse.total_unique_users ............. [[32mSELECT 1[0m in 10.04s]
[0m12:29:44.151233 [debug] [Thread-1  ]: Finished running node model.maker_warehouse.total_unique_users
[0m12:29:47.630683 [debug] [Thread-2  ]: SQL status: SELECT 161918 in 10.0 seconds
[0m12:29:47.636790 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.user_engagement"
[0m12:29:47.637479 [debug] [Thread-2  ]: On model.maker_warehouse.user_engagement: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.user_engagement"} */
alter table "mydb"."dbt_warehouse"."user_engagement" rename to "user_engagement__dbt_backup"
[0m12:29:47.640843 [debug] [Thread-2  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:29:47.648633 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.user_engagement"
[0m12:29:47.649334 [debug] [Thread-2  ]: On model.maker_warehouse.user_engagement: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.user_engagement"} */
alter table "mydb"."dbt_warehouse"."user_engagement__dbt_tmp" rename to "user_engagement"
[0m12:29:47.652644 [debug] [Thread-2  ]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:29:47.656791 [debug] [Thread-2  ]: On model.maker_warehouse.user_engagement: COMMIT
[0m12:29:47.657937 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.user_engagement"
[0m12:29:47.658863 [debug] [Thread-2  ]: On model.maker_warehouse.user_engagement: COMMIT
[0m12:29:47.761473 [debug] [Thread-2  ]: SQL status: COMMIT in 0.0 seconds
[0m12:29:47.769465 [debug] [Thread-2  ]: Using postgres connection "model.maker_warehouse.user_engagement"
[0m12:29:47.770198 [debug] [Thread-2  ]: On model.maker_warehouse.user_engagement: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "maker_warehouse", "target_name": "dev", "node_id": "model.maker_warehouse.user_engagement"} */
drop table if exists "mydb"."dbt_warehouse"."user_engagement__dbt_backup" cascade
[0m12:29:47.839986 [debug] [Thread-2  ]: SQL status: DROP TABLE in 0.0 seconds
[0m12:29:47.844722 [debug] [Thread-2  ]: Timing info for model.maker_warehouse.user_engagement (execute): 12:29:37.513863 => 12:29:47.844108
[0m12:29:47.847017 [debug] [Thread-2  ]: On model.maker_warehouse.user_engagement: Close
[0m12:29:47.849759 [debug] [Thread-2  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bcc5688e-15f4-4218-b9fe-397e21edc6aa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11018aac0>]}
[0m12:29:47.851359 [info ] [Thread-2  ]: 9 of 9 OK created sql table model dbt_warehouse.user_engagement ................ [[32mSELECT 161918[0m in 10.43s]
[0m12:29:47.853777 [debug] [Thread-2  ]: Finished running node model.maker_warehouse.user_engagement
[0m12:29:47.858044 [debug] [MainThread]: Using postgres connection "master"
[0m12:29:47.858677 [debug] [MainThread]: On master: BEGIN
[0m12:29:47.859301 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m12:29:48.028850 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m12:29:48.030764 [debug] [MainThread]: On master: COMMIT
[0m12:29:48.032796 [debug] [MainThread]: Using postgres connection "master"
[0m12:29:48.034071 [debug] [MainThread]: On master: COMMIT
[0m12:29:48.045952 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m12:29:48.046627 [debug] [MainThread]: On master: Close
[0m12:29:48.048441 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:29:48.049952 [debug] [MainThread]: Connection 'model.maker_warehouse.total_unique_users' was properly closed.
[0m12:29:48.051370 [debug] [MainThread]: Connection 'model.maker_warehouse.user_engagement' was properly closed.
[0m12:29:48.052528 [debug] [MainThread]: Connection 'model.maker_warehouse.movies' was properly closed.
[0m12:29:48.054812 [debug] [MainThread]: Connection 'model.maker_warehouse.total_viewing_time' was properly closed.
[0m12:29:48.057755 [info ] [MainThread]: 
[0m12:29:48.059995 [info ] [MainThread]: Finished running 3 view models, 6 table models in 0 hours 0 minutes and 15.59 seconds (15.59s).
[0m12:29:48.075329 [debug] [MainThread]: Command end result
[0m12:29:48.100085 [info ] [MainThread]: 
[0m12:29:48.103866 [info ] [MainThread]: [32mCompleted successfully[0m
[0m12:29:48.105386 [info ] [MainThread]: 
[0m12:29:48.106768 [info ] [MainThread]: Done. PASS=9 WARN=0 ERROR=0 SKIP=0 TOTAL=9
[0m12:29:48.109212 [debug] [MainThread]: Command `dbt run` succeeded at 12:29:48.108931 after 17.36 seconds
[0m12:29:48.112815 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e678e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110142af0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fbe0190>]}
[0m12:29:48.113835 [debug] [MainThread]: Flushing usage events
